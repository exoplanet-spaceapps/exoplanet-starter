# ğŸ§ª å¿«é€Ÿæµ‹è¯•æŒ‡å—ï¼šä¸¤æ­¥èµ°æ–¹æ¡ˆï¼ˆæµ‹è¯• â†’ å…¨é‡ï¼‰

## ğŸ“‹ æµ‹è¯•é˜¶æ®µæµç¨‹ï¼ˆ15-20 åˆ†é’Ÿï¼‰

### âœ… Step 1: é…ç½®æµ‹è¯•æ¨¡å¼

æ‰“å¼€ `notebooks/02a_download_lightcurves.ipynb`

**ä¿®æ”¹ Cell 4 é…ç½®**ï¼š
```python
CONFIG = {
    'max_workers': 4,        # æµ‹è¯•é˜¶æ®µä¿æŒ 4 å³å¯
    'max_retries': 3,
    'timeout': 60,
    'batch_size': 100,
    'save_interval': 20,     # æ”¹ä¸º 20ï¼ˆæ›´é¢‘ç¹ä¿å­˜ï¼‰
    'test_mode': True,       # âš ï¸ é‡ç‚¹ï¼šæ”¹ä¸º True
}
```

**æ£€æŸ¥ç‚¹**ï¼š
```python
# Cell 4 æ‰§è¡Œååº”è¯¥çœ‹åˆ°ï¼š
âš ï¸ TEST MODE: Only processing 100 samples
âœ… Dataset loaded: 100 samples
   Positive: 70
   Negative: 30
```

---

### âœ… Step 2: æ‰§è¡Œä¸‹è½½æµ‹è¯•

åœ¨ Jupyter Notebook ä¸­ï¼š
1. ç‚¹å‡» **Cell â†’ Run All**
2. è§‚å¯Ÿè¿›åº¦æ¡ï¼ˆåº”æ˜¾ç¤º 100/100ï¼‰
3. é¢„è®¡æ—¶é—´ï¼š**15-20 åˆ†é’Ÿ**

**å®æ—¶ç›‘æ§**ï¼š
```bash
# åœ¨å¦ä¸€ä¸ªç»ˆç«¯æŸ¥çœ‹è¿›åº¦
watch -n 30 'ls data/lightcurves/*.pkl | wc -l'
```

**æˆåŠŸæ ‡å¿—**ï¼ˆCell 6 è¾“å‡ºï¼‰ï¼š
```
ğŸ‰ Download complete!
   Total time: 0.25 hours (15 åˆ†é’Ÿ)
   Average: 9.0 sec/sample

ğŸ“Š Final Statistics:
   success: 85-95 (æ­£å¸¸èŒƒå›´)
   failed: 5-15 (éƒ¨åˆ†æ ·æœ¬å¯èƒ½æ— æ•°æ®)
   Success rate: 85-95%
```

---

### âœ… Step 3: éªŒè¯ä¸‹è½½æ•°æ®

**æŸ¥çœ‹ Cell 7 è¾“å‡º**ï¼š
```
âœ… SAMPLE_000012_TIC88863718.pkl
   TIC ID: 88863718
   Sectors: 3 ([13, 26, 40])
   Data points: 18,315
   Time span: 27.4 days

ğŸ“¦ Storage:
   Total files: 87
   Total size: 0.35 GB
   Average size: 4.1 MB/file
```

**æ‰‹åŠ¨æ£€æŸ¥**ï¼ˆå¯é€‰ï¼‰ï¼š
```python
import joblib
from pathlib import Path

# éšæœºè¯»å–ä¸€ä¸ªæ–‡ä»¶
test_file = list(Path('data/lightcurves').glob('*.pkl'))[0]
data = joblib.load(test_file)

print(f"Sample ID: {data['sample_id']}")
print(f"TIC ID: {data['tic_id']}")
print(f"Sectors: {data['n_sectors']}")
print(f"Light curves: {len(data['lc_collection'])}")

# æŸ¥çœ‹ç¬¬ä¸€ä¸ªå…‰æ›²çº¿
lc = data['lc_collection'][0]
print(f"Time points: {len(lc.time)}")
print(f"Time range: {lc.time[0]} - {lc.time[-1]}")
```

---

### âœ… Step 4: æµ‹è¯•ç‰¹å¾æå–

æ‰“å¼€ `notebooks/02b_extract_features.ipynb`

**é…ç½®å·²ç»é€‚ç”¨äºæµ‹è¯•**ï¼ˆæ— éœ€ä¿®æ”¹ï¼‰ï¼š
```python
CONFIG = {
    'max_workers': 4,
    'bls_periods': 2000,     # æµ‹è¯•ç”¨æ ‡å‡†é…ç½®
    'period_max': 15.0,
}
```

**æ‰§è¡Œ**ï¼š
1. ç‚¹å‡» **Cell â†’ Run All**
2. é¢„è®¡æ—¶é—´ï¼š**2-3 åˆ†é’Ÿ**ï¼ˆ100ä¸ªæ ·æœ¬ï¼‰

**æˆåŠŸæ ‡å¿—**ï¼ˆCell 6 è¾“å‡ºï¼‰ï¼š
```
âœ… Feature extraction complete
   Total features: 87
   Feature columns: 14
   Features: ['flux_mean', 'flux_std', 'bls_power', ...]
```

---

### âœ… Step 5: éªŒè¯ç‰¹å¾è´¨é‡

**æŸ¥çœ‹ Cell 7 æ•°æ®è´¨é‡æŠ¥å‘Š**ï¼š
```
ğŸ“Š Missing values:
   âœ… No missing values!

ğŸ“Š Label distribution:
   Positive (1): 62 (71.3%)
   Negative (0): 25 (28.7%)

ğŸ“Š Feature statistics:
              flux_mean    flux_std  bls_power  ...
count            87.00       87.00      87.00
mean              1.00        0.02       0.15
std               0.00        0.01       0.08
min               0.99        0.00       0.05
max               1.01        0.05       0.42

ğŸ” Checking for infinities:
   âœ… No infinities or extreme values
```

**å¦‚æœæœ‰é—®é¢˜**ï¼š
```python
# æ£€æŸ¥å¼‚å¸¸ç‰¹å¾
import pandas as pd
features_df = pd.read_parquet('checkpoints/features_checkpoint.parquet')

# æŸ¥çœ‹ç¼ºå¤±å€¼
print(features_df.isnull().sum())

# æŸ¥çœ‹æå€¼
print(features_df.describe())

# æ£€æŸ¥ BLS å¤±è´¥æ ·æœ¬
failed_bls = features_df[features_df['bls_power'] == 0.0]
print(f"BLS å¤±è´¥æ ·æœ¬: {len(failed_bls)}")
```

---

## âœ… æµ‹è¯•é€šè¿‡æ ‡å‡†

**å¿…é¡»æ»¡è¶³**ï¼š
- [x] æˆåŠŸä¸‹è½½ >80 ä¸ªæ ·æœ¬ï¼ˆ85%+ æˆåŠŸç‡ï¼‰
- [x] æ–‡ä»¶å¤§å°æ­£å¸¸ï¼ˆ3-6 MB/æ–‡ä»¶ï¼‰
- [x] ç‰¹å¾æå–æ— é”™è¯¯
- [x] æ— ç¼ºå¤±å€¼æˆ–æ— ç©·å€¼
- [x] BLS ç‰¹å¾åˆç†ï¼ˆpower > 0ï¼‰

**å¦‚æœæµ‹è¯•å¤±è´¥**ï¼š
1. æ£€æŸ¥ç½‘ç»œè¿æ¥
2. æ£€æŸ¥ MAST æœåŠ¡çŠ¶æ€: https://mast.stsci.edu/
3. æŸ¥çœ‹é”™è¯¯æ—¥å¿—ï¼š`checkpoints/download_report.json`
4. åœ¨ GitHub Issues æŠ¥å‘Šé—®é¢˜

---

## ğŸš€ æµ‹è¯•é€šè¿‡åï¼šå…¨é‡ä¸‹è½½

### Step 6: é…ç½®å…¨é‡ä¸‹è½½

**ä¿®æ”¹ `02a_download_lightcurves.ipynb` Cell 4**ï¼š
```python
CONFIG = {
    'max_workers': 6,        # â¬†ï¸ æé«˜åˆ° 6ï¼ˆæœ¬åœ°ç½‘ç»œç¨³å®šï¼‰
    'max_retries': 3,
    'timeout': 60,
    'batch_size': 100,
    'save_interval': 50,
    'test_mode': False,      # â¬‡ï¸ æ”¹ä¸º Falseï¼ˆå…¨é‡ä¸‹è½½ï¼‰
}
```

**æ¸…ç†æµ‹è¯•æ•°æ®ï¼ˆå¯é€‰ï¼‰**ï¼š
```bash
# å¦‚æœè¦é‡æ–°å¼€å§‹ï¼ˆåˆ é™¤æµ‹è¯•æ–‡ä»¶ï¼‰
rm -rf data/lightcurves/*.pkl
rm -f checkpoints/download_progress.parquet
rm -f checkpoints/download_report.json
```

**æˆ–è€…ä¿ç•™æµ‹è¯•æ•°æ®**ï¼š
```python
# 02a ä¼šè‡ªåŠ¨è·³è¿‡å·²ä¸‹è½½çš„æ–‡ä»¶
# æµ‹è¯•çš„ 100 ä¸ªæ ·æœ¬ä¸ä¼šé‡å¤ä¸‹è½½
```

---

### Step 7: å¯åŠ¨å…¨é‡ä¸‹è½½

**æœ€ä½³æ—¶æœº**ï¼š
```
å»ºè®®æ—¶é—´ï¼šæ™šä¸Š 10:00 PM å¯åŠ¨
å®Œæˆæ—¶é—´ï¼šæ¬¡æ—¥æ—©ä¸Š 6:00 AM
```

**æ‰§è¡Œ**ï¼š
```python
# åœ¨ Jupyter Notebook
1. ç¡®è®¤ Cell 4 é…ç½®æ­£ç¡®
2. Cell â†’ Run All
3. æ£€æŸ¥è¿›åº¦æ¡å¯åŠ¨
4. å…³é—­ç¬”è®°æœ¬å±å¹•ï¼ˆä¸è¦å…³æœºï¼‰
```

**é¢„è®¡ç»Ÿè®¡**ï¼š
```
ğŸš€ Starting download for 11,879 samples
   Workers: 6
   Estimated time: 5.5 hours
```

**ç›‘æ§è„šæœ¬**ï¼ˆå¯é€‰åå°è¿è¡Œï¼‰ï¼š
```bash
# monitor_download.sh
#!/bin/bash
while true; do
    count=$(ls data/lightcurves/*.pkl 2>/dev/null | wc -l)
    echo "[$(date +%H:%M)] Downloaded: $count / 11979"
    sleep 300  # æ¯ 5 åˆ†é’Ÿæ£€æŸ¥
done
```

---

### Step 8: å…¨é‡ç‰¹å¾æå–

**æ¬¡æ—¥æ—©ä¸Šæ£€æŸ¥ä¸‹è½½å®Œæˆå**ï¼š

1. æ‰“å¼€ `02b_extract_features.ipynb`
2. æ— éœ€ä¿®æ”¹é…ç½®
3. Run Allï¼ˆé¢„è®¡ 15-20 åˆ†é’Ÿï¼‰

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
âœ… Feature extraction complete
   Total features: 10,234
   Feature columns: 14
   Success rate: 85.6%
```

---

### Step 9: å¼€å§‹è®­ç»ƒ

**ä¿®æ”¹ `03_injection_train_PRODUCTION.ipynb`**ï¼š

æ‰¾åˆ° **Cell 6**ï¼Œæ›¿æ¢ä¸ºï¼š
```python
# ä»æ–‡ä»¶åŠ è½½ç‰¹å¾ï¼ˆä¸å†ä¸‹è½½ï¼‰
features_path = MODEL_DIR / 'features_20250104_080000.parquet'  # ä½¿ç”¨å®é™…æ–‡ä»¶å
features_df = pd.read_parquet(features_path)

print(f"âœ… Loaded {len(features_df):,} features from disk")
print(f"   Positive: {features_df['label'].sum():,}")
print(f"   Negative: {(~features_df['label'].astype(bool)).sum():,}")

# å®šä¹‰ç‰¹å¾åˆ—
feature_cols = [col for col in features_df.columns
                if col not in ['sample_id', 'tic_id', 'label', 'n_sectors']]

print(f"   Features: {len(feature_cols)}")
```

**ç„¶åç›´æ¥è·³åˆ° Cell 7 è®­ç»ƒæ¨¡å‹**

---

## ğŸ“Š æ—¶é—´çº¿æ€»ç»“

| é˜¶æ®µ | æ—¶é—´ | æè¿° |
|------|------|------|
| æµ‹è¯•ä¸‹è½½ | 15-20 min | 100 æ ·æœ¬éªŒè¯æµç¨‹ |
| æµ‹è¯•ç‰¹å¾æå– | 2-3 min | éªŒè¯ç‰¹å¾è´¨é‡ |
| **æµ‹è¯•æ€»è®¡** | **~20 min** | **ç¡®ä¿æµç¨‹å¯è¡Œ** |
| å…¨é‡ä¸‹è½½ | 5-7 hours | 11,979 æ ·æœ¬ï¼ˆæ™šä¸Šè¿è¡Œï¼‰ |
| å…¨é‡ç‰¹å¾æå– | 15-20 min | æå–æ‰€æœ‰ç‰¹å¾ |
| **å…¨é‡æ€»è®¡** | **~6 hours** | **ä¸€æ¬¡æ€§æŠ•èµ„** |

---

## ğŸ†˜ å¸¸è§é—®é¢˜

### Q1: ä¸‹è½½é€Ÿåº¦æ…¢æ€ä¹ˆåŠï¼Ÿ
```python
# é™ä½å¹¶å‘æ•°ï¼ˆé¿å…è¢«é™é€Ÿï¼‰
CONFIG = {'max_workers': 2}  # æ”¹ä¸º 2

# æˆ–å¢åŠ è¶…æ—¶æ—¶é—´
CONFIG = {'timeout': 120}  # æ”¹ä¸º 120 ç§’
```

### Q2: æŸäº›æ ·æœ¬æ‰¾ä¸åˆ°æ•°æ®ï¼Ÿ
```
æ­£å¸¸ç°è±¡ï¼å¹¶éæ‰€æœ‰ TOI éƒ½æœ‰ SPOC å…‰æ›²çº¿
é¢„æœŸæˆåŠŸç‡ï¼š85-90%
å¤±è´¥åŸå› ï¼šno_data_found, download_failed
```

### Q3: ç¡¬ç›˜ç©ºé—´ä¸å¤Ÿï¼Ÿ
```bash
# æ£€æŸ¥å½“å‰ä½¿ç”¨
du -sh data/lightcurves/

# é¢„è®¡å…¨é‡å¤§å°ï¼š
# 100 æ ·æœ¬  â‰ˆ 400 MB
# 11,979 æ ·æœ¬ â‰ˆ 48 GB

# å¦‚æœç©ºé—´ä¸è¶³ï¼Œåˆ é™¤æµ‹è¯•æ–‡ä»¶
rm data/lightcurves/SAMPLE_0000*.pkl
```

### Q4: ä¸­é€”åœæ­¢äº†æ€ä¹ˆåŠï¼Ÿ
```python
# é‡æ–°è¿è¡Œ 02a Cell 6
# è‡ªåŠ¨ä» checkpoint æ¢å¤
# å·²ä¸‹è½½çš„æ ·æœ¬ä¼šè·³è¿‡
```

---

## âœ… æ£€æŸ¥æ¸…å•

**æµ‹è¯•é˜¶æ®µï¼ˆä»Šå¤©ï¼‰**ï¼š
- [ ] ä¿®æ”¹ 02a Cell 4 ä¸º test_mode=True
- [ ] æˆåŠŸä¸‹è½½ >80 ä¸ªæ ·æœ¬
- [ ] éªŒè¯æ–‡ä»¶å®Œæ•´æ€§ï¼ˆCell 7ï¼‰
- [ ] æˆåŠŸæå–æµ‹è¯•ç‰¹å¾ï¼ˆ02bï¼‰
- [ ] æ£€æŸ¥ç‰¹å¾è´¨é‡æ— å¼‚å¸¸

**å…¨é‡é˜¶æ®µï¼ˆæ˜å¤©ï¼‰**ï¼š
- [ ] ä¿®æ”¹ 02a Cell 4 ä¸º test_mode=False, max_workers=6
- [ ] æ™šä¸Šå¯åŠ¨å…¨é‡ä¸‹è½½
- [ ] æ¬¡æ—¥æ—©ä¸Šæ£€æŸ¥å®Œæˆï¼ˆ>10,000 æ–‡ä»¶ï¼‰
- [ ] è¿è¡Œ 02b æå–å…¨é‡ç‰¹å¾
- [ ] å¼€å§‹è®­ç»ƒæ¨¡å‹

---

## ğŸ“ éœ€è¦å¸®åŠ©ï¼Ÿ

- æŸ¥çœ‹æ—¥å¿—ï¼š`checkpoints/download_report.json`
- æ£€æŸ¥é”™è¯¯ï¼š`progress_df[progress_df['status']=='failed']`
- GitHub Issues: https://github.com/exoplanet-spaceapps/exoplanet-starter/issues

**ç¥æµ‹è¯•é¡ºåˆ©ï¼ğŸš€**
