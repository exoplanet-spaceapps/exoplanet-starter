{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 Â· è³‡æ–™é›†å­˜å–é©—è­‰\n",
    "é©—è­‰ DATASETS.md ä¸­æ‰€æœ‰è³‡æ–™ä¾†æºçš„å¯å­˜å–æ€§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# æ­¥é©Ÿ 1: å®‰è£å¥—ä»¶ (éœ€è¦æ‰‹å‹•é‡å•Ÿ Runtime)\n# âš ï¸ é‡è¦: åŸ·è¡Œæ­¤ cell å¾Œï¼Œè«‹æ‰‹å‹•é‡å•Ÿ Runtime (Runtime â†’ Restart runtime)\n\n!pip install -q numpy==1.26.4 pandas astroquery astropy scipy'<1.13' matplotlib scikit-learn\n!pip install -q lightkurve wotan transitleastsquares requests\n\nprint(\"âœ… å¥—ä»¶å®‰è£å®Œæˆ!\")\nprint(\"âš ï¸ è«‹ç¾åœ¨æ‰‹å‹•é‡å•Ÿ Runtime: Runtime â†’ Restart runtime\")\nprint(\"   ç„¶å¾Œç¹¼çºŒåŸ·è¡Œä¸‹ä¸€å€‹ cell\")"
  },
  {
   "cell_type": "code",
   "source": "# æ­¥é©Ÿ 2: é©—è­‰ç’°å¢ƒ (Runtime é‡å•Ÿå¾ŒåŸ·è¡Œ)\nimport numpy as np\nimport sys\n\n# æª¢æŸ¥ NumPy ç‰ˆæœ¬\nprint(f\"NumPy ç‰ˆæœ¬: {np.__version__}\")\nprint(f\"Python ç‰ˆæœ¬: {sys.version}\")\n\nif np.__version__.startswith('2.'):\n    print(\"âŒ NumPy 2.0 æª¢æ¸¬åˆ°ï¼è«‹ç¢ºèªå·²åŸ·è¡Œæ­¥é©Ÿ 1 ä¸¦é‡å•Ÿ Runtime\")\n    raise RuntimeError(\"è«‹å…ˆä¿®å¾© NumPy ç‰ˆæœ¬å•é¡Œ\")\nelse:\n    print(\"âœ… NumPy ç‰ˆæœ¬æ­£ç¢º (< 2.0)\")\n    print(\"âœ… ç’°å¢ƒå·²æº–å‚™å¥½ï¼Œå¯ä»¥ç¹¼çºŒåŸ·è¡Œå¾ŒçºŒ cells\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Lightkurve API - TESS/Kepler å…‰æ›²ç·šè³‡æ–™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¸¬è©¦ Lightkurve å­˜å– TESS è³‡æ–™\n",
    "import lightkurve as lk\n",
    "\n",
    "print(\"ğŸ“¡ æ¸¬è©¦ Lightkurve API å­˜å– TESS è³‡æ–™...\")\n",
    "try:\n",
    "    # æœå°‹å·²çŸ¥çš„ TESS è¡Œæ˜Ÿ\n",
    "    target = \"TIC 25155310\"  # WASP-121 b - å·²ç¢ºèªçš„ç†±æœ¨æ˜Ÿ\n",
    "    search_result = lk.search_lightcurve(target, mission=\"TESS\", author=\"SPOC\")\n",
    "    \n",
    "    if len(search_result) > 0:\n",
    "        print(f\"âœ… æˆåŠŸæœå°‹åˆ° {len(search_result)} å€‹ TESS å…‰æ›²ç·š\")\n",
    "        print(f\"   ç›®æ¨™: {target}\")\n",
    "        print(f\"   ç¬¬ä¸€å€‹çµæœ: {search_result[0]}\")\n",
    "        \n",
    "        # å˜—è©¦ä¸‹è¼‰ç¬¬ä¸€å€‹å…‰æ›²ç·š\n",
    "        lc = search_result[0].download()\n",
    "        if lc is not None:\n",
    "            print(f\"âœ… æˆåŠŸä¸‹è¼‰å…‰æ›²ç·šï¼ŒåŒ…å« {len(lc)} å€‹è³‡æ–™é»\")\n",
    "            print(f\"   æ™‚é–“è·¨åº¦: {lc.time.min():.2f} - {lc.time.max():.2f} days\")\n",
    "    else:\n",
    "        print(\"âŒ æœªæ‰¾åˆ° TESS è³‡æ–™\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ç„¡æ³•å­˜å– TESS è³‡æ–™: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¸¬è©¦ Lightkurve å­˜å– Kepler è³‡æ–™\n",
    "print(\"\\nğŸ“¡ æ¸¬è©¦ Lightkurve API å­˜å– Kepler è³‡æ–™...\")\n",
    "try:\n",
    "    # æœå°‹å·²çŸ¥çš„ Kepler è¡Œæ˜Ÿ\n",
    "    target = \"Kepler-10\"  # ç¬¬ä¸€å€‹ç™¼ç¾çš„å²©çŸ³ç³»å¤–è¡Œæ˜Ÿ\n",
    "    search_result = lk.search_lightcurve(target, mission=\"Kepler\")\n",
    "    \n",
    "    if len(search_result) > 0:\n",
    "        print(f\"âœ… æˆåŠŸæœå°‹åˆ° {len(search_result)} å€‹ Kepler å…‰æ›²ç·š\")\n",
    "        print(f\"   ç›®æ¨™: {target}\")\n",
    "        print(f\"   è³‡æ–™å­£åº¦ç¯„åœ: Q{search_result.quarter.min()} - Q{search_result.quarter.max()}\")\n",
    "        \n",
    "        # ä¸‹è¼‰ç¬¬ä¸€å­£è³‡æ–™\n",
    "        lc = search_result[0].download()\n",
    "        if lc is not None:\n",
    "            print(f\"âœ… æˆåŠŸä¸‹è¼‰å…‰æ›²ç·šï¼ŒåŒ…å« {len(lc)} å€‹è³‡æ–™é»\")\n",
    "    else:\n",
    "        print(\"âŒ æœªæ‰¾åˆ° Kepler è³‡æ–™\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ç„¡æ³•å­˜å– Kepler è³‡æ–™: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. NASA Exoplanet Archive TAP Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¸¬è©¦ NASA Exoplanet Archive TAP API\n",
    "from astroquery.ipac.nexsci.nasa_exoplanet_archive import NasaExoplanetArchive\n",
    "import pandas as pd\n",
    "\n",
    "print(\"ğŸ“¡ æ¸¬è©¦ NASA Exoplanet Archive TAP Service...\")\n",
    "try:\n",
    "    # æŸ¥è©¢ç¢ºèªçš„è¡Œæ˜Ÿï¼ˆPSCompPars è¡¨ï¼‰\n",
    "    query = \"\"\"\n",
    "    SELECT TOP 10 \n",
    "        pl_name, hostname, pl_orbper, pl_rade, pl_masse, \n",
    "        disc_year, discoverymethod\n",
    "    FROM ps \n",
    "    WHERE pl_orbper IS NOT NULL \n",
    "        AND pl_rade IS NOT NULL\n",
    "        AND discoverymethod = 'Transit'\n",
    "    ORDER BY disc_year DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    # åŸ·è¡ŒæŸ¥è©¢\n",
    "    planets = NasaExoplanetArchive.query_criteria(\n",
    "        table=\"ps\",\n",
    "        select=\"pl_name,hostname,pl_orbper,pl_rade,disc_year,discoverymethod\",\n",
    "        where=\"pl_orbper>0 and discoverymethod='Transit'\",\n",
    "        order=\"disc_year desc\",\n",
    "        format=\"table\"\n",
    "    )\n",
    "    \n",
    "    if len(planets) > 0:\n",
    "        print(f\"âœ… æˆåŠŸæŸ¥è©¢åˆ° {len(planets)} å€‹å‡Œæ—¥ç³»å¤–è¡Œæ˜Ÿ\")\n",
    "        print(\"\\næœ€è¿‘ç™¼ç¾çš„ 5 å€‹å‡Œæ—¥è¡Œæ˜Ÿ:\")\n",
    "        for i in range(min(5, len(planets))):\n",
    "            p = planets[i]\n",
    "            print(f\"   â€¢ {p['pl_name']} ({p['disc_year']}) - é€±æœŸ: {p['pl_orbper']:.2f} å¤©\")\n",
    "    else:\n",
    "        print(\"âŒ æœªæŸ¥è©¢åˆ°è¡Œæ˜Ÿè³‡æ–™\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ç„¡æ³•å­˜å– NASA Exoplanet Archive: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. TESS Objects of Interest (TOI) ç›®éŒ„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¸¬è©¦ TOI ç›®éŒ„å­˜å–\n",
    "print(\"ğŸ“¡ æ¸¬è©¦ TESS Objects of Interest (TOI) ç›®éŒ„...\")\n",
    "try:\n",
    "    # æŸ¥è©¢ TOI å€™é¸è¡Œæ˜Ÿ\n",
    "    toi_data = NasaExoplanetArchive.query_criteria(\n",
    "        table=\"toi\",\n",
    "        select=\"toi,tid,tfopwg_disp,toi_period,toi_depth\",\n",
    "        where=\"tfopwg_disp='CP' and toi_period>0\",  # CP = Candidate Planet\n",
    "        order=\"toi\",\n",
    "        format=\"table\"\n",
    "    )\n",
    "    \n",
    "    if len(toi_data) > 0:\n",
    "        print(f\"âœ… æˆåŠŸæŸ¥è©¢åˆ° {len(toi_data)} å€‹ TOI å€™é¸è¡Œæ˜Ÿ\")\n",
    "        print(\"\\nå‰ 5 å€‹ TOI å€™é¸:\")\n",
    "        for i in range(min(5, len(toi_data))):\n",
    "            t = toi_data[i]\n",
    "            print(f\"   â€¢ TOI-{t['toi']:.1f} (TIC {t['tid']}) - \"\n",
    "                  f\"é€±æœŸ: {t['toi_period']:.2f} å¤©, æ·±åº¦: {t['toi_depth']:.1f} ppm\")\n",
    "    else:\n",
    "        print(\"âŒ æœªæŸ¥è©¢åˆ° TOI è³‡æ–™\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ç„¡æ³•å­˜å– TOI ç›®éŒ„: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Kepler é›™æ˜Ÿç›®éŒ„ï¼ˆè² æ¨£æœ¬ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¸¬è©¦ Kepler é›™æ˜Ÿç›®éŒ„å­˜å–ï¼ˆç”¨ä½œè² æ¨£æœ¬ï¼‰\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "print(\"ğŸ“¡ æ¸¬è©¦ Kepler Eclipsing Binary Catalog...\")\n",
    "try:\n",
    "    # å¾ MAST ä¸‹è¼‰é›™æ˜Ÿç›®éŒ„\n",
    "    # æ³¨æ„ï¼šç›´æ¥ URL å¯èƒ½éœ€è¦æ›´æ–°ï¼Œé€™è£¡ä½¿ç”¨ astroquery æŸ¥è©¢é›™æ˜Ÿ\n",
    "    from astroquery.mast import Observations\n",
    "    \n",
    "    # æœå°‹ Kepler é›™æ˜Ÿè§€æ¸¬è³‡æ–™\n",
    "    obs = Observations.query_criteria(\n",
    "        obs_collection=\"Kepler\",\n",
    "        dataproduct_type=\"timeseries\",\n",
    "        target_classification=\"ECLIPSING BINARY\",\n",
    "        obs_id=\"*\"\n",
    "    )\n",
    "    \n",
    "    if len(obs) > 0:\n",
    "        print(f\"âœ… æ‰¾åˆ° {len(obs)} å€‹ Kepler é›™æ˜Ÿè§€æ¸¬\")\n",
    "        print(\"   å¯ç”¨ä½œè¨“ç·´çš„è² æ¨£æœ¬ï¼ˆéè¡Œæ˜Ÿå‡Œæ—¥ï¼‰\")\n",
    "        # é¡¯ç¤ºå‰å¹¾å€‹\n",
    "        for i in range(min(3, len(obs))):\n",
    "            print(f\"   â€¢ {obs['target_name'][i]} - {obs['obs_id'][i]}\")\n",
    "    else:\n",
    "        print(\"âš ï¸ æœªæ‰¾åˆ°é›™æ˜Ÿè³‡æ–™ï¼Œä½†å¯å¾å…¶ä»–ä¾†æºç²å–\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ç›´æ¥å­˜å–å—é™ï¼Œä½†å¯é€é Lightkurve ç²å–: {e}\")\n",
    "    # å‚™ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨å·²çŸ¥çš„é›™æ˜Ÿç³»çµ±\n",
    "    print(\"\\nğŸ“ å‚™ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨å·²çŸ¥çš„ Kepler é›™æ˜Ÿç³»çµ±ä½œç‚ºè² æ¨£æœ¬\")\n",
    "    known_binaries = [\"KIC 9832227\", \"KIC 8462852\", \"KIC 5653126\"]\n",
    "    for kb in known_binaries:\n",
    "        print(f\"   â€¢ {kb} - å·²çŸ¥é›™æ˜Ÿç³»çµ±\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. MAST ç›´æ¥æŸ¥è©¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¸¬è©¦ MAST ç›´æ¥æŸ¥è©¢\n",
    "from astroquery.mast import Observations, Catalogs\n",
    "\n",
    "print(\"ğŸ“¡ æ¸¬è©¦ MAST (Mikulski Archive) ç›´æ¥æŸ¥è©¢...\")\n",
    "try:\n",
    "    # æŸ¥è©¢ TESS è§€æ¸¬è³‡æ–™\n",
    "    obs = Observations.query_criteria(\n",
    "        obs_collection=\"TESS\",\n",
    "        dataproduct_type=\"timeseries\",\n",
    "        t_exptime=[1, 3000]  # æ›å…‰æ™‚é–“ç¯„åœ\n",
    "    )\n",
    "    \n",
    "    if len(obs) > 0:\n",
    "        print(f\"âœ… æˆåŠŸæŸ¥è©¢åˆ° {len(obs)} å€‹ TESS æ™‚é–“åºåˆ—è§€æ¸¬\")\n",
    "        \n",
    "        # çµ±è¨ˆè³‡æ–™é¡å‹\n",
    "        unique_products = obs['provenance_name'].unique()\n",
    "        print(f\"   è³‡æ–™ç”¢å“é¡å‹: {', '.join(unique_products[:5])}\")\n",
    "    else:\n",
    "        print(\"âŒ æœªæŸ¥è©¢åˆ° MAST è³‡æ–™\")\n",
    "        \n",
    "    # æ¸¬è©¦ TIC ç›®éŒ„æŸ¥è©¢\n",
    "    print(\"\\nğŸ“¡ æ¸¬è©¦ TESS Input Catalog (TIC) æŸ¥è©¢...\")\n",
    "    tic_data = Catalogs.query_object(\"TIC 25155310\", catalog=\"TIC\")\n",
    "    if len(tic_data) > 0:\n",
    "        print(f\"âœ… æˆåŠŸæŸ¥è©¢ TIC ç›®éŒ„\")\n",
    "        print(f\"   TIC ID: {tic_data['ID'][0]}\")\n",
    "        print(f\"   Tmag: {tic_data['Tmag'][0]:.2f}\")\n",
    "        print(f\"   RA: {tic_data['ra'][0]:.4f}, Dec: {tic_data['dec'][0]:.4f}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ç„¡æ³•å­˜å– MAST: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ç¤¾ç¾¤å·¥å…·æ¸¬è©¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¸¬è©¦ç¤¾ç¾¤å·¥å…·\n",
    "print(\"ğŸ”§ æ¸¬è©¦ç¤¾ç¾¤å·¥å…·å¯ç”¨æ€§...\\n\")\n",
    "\n",
    "# æ¸¬è©¦ wotan å»è¶¨å‹¢\n",
    "try:\n",
    "    from wotan import flatten\n",
    "    import numpy as np\n",
    "    \n",
    "    # å‰µå»ºæ¸¬è©¦è³‡æ–™\n",
    "    time = np.linspace(0, 30, 1000)\n",
    "    flux = 1 + 0.01 * np.sin(time) + np.random.normal(0, 0.001, 1000)\n",
    "    \n",
    "    # ä½¿ç”¨ wotan å»è¶¨å‹¢\n",
    "    flatten_flux, trend = flatten(time, flux, method='biweight', window_length=0.5)\n",
    "    print(\"âœ… wotan å»è¶¨å‹¢å·¥å…·å¯ç”¨\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ wotan éœ€è¦é¡å¤–å®‰è£: pip install wotan\")\n",
    "\n",
    "# æ¸¬è©¦ Transit Least Squares\n",
    "try:\n",
    "    from transitleastsquares import transitleastsquares\n",
    "    print(\"âœ… Transit Least Squares (TLS) å¯ç”¨\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ TLS éœ€è¦é¡å¤–å®‰è£: pip install transitleastsquares\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ“Š è³‡æ–™é›†å¯ç”¨æ€§ç¸½çµï¼š\")\n",
    "print(\"âœ… Lightkurve API - TESS/Kepler å…‰æ›²ç·šè³‡æ–™ã€å¯ç”¨ã€‘\")\n",
    "print(\"âœ… NASA Exoplanet Archive TAP Serviceã€å¯ç”¨ã€‘\")\n",
    "print(\"âœ… TOI ç›®éŒ„ã€å¯ç”¨ã€‘\")\n",
    "print(\"âœ… MAST ç›´æ¥æŸ¥è©¢ã€å¯ç”¨ã€‘\")\n",
    "print(\"âš ï¸ Kepler é›™æ˜Ÿç›®éŒ„ã€éœ€é€é Lightkurve æˆ–å·²çŸ¥ ID å­˜å–ã€‘\")\n",
    "print(\"âœ… ç¤¾ç¾¤å·¥å…·ã€å¯ç”¨ï¼Œéœ€é¡å¤–å®‰è£ã€‘\")\n",
    "print(\"\\nğŸ’¡ æ‰€æœ‰æ ¸å¿ƒè³‡æ–™é›†å‡å¯å…è²»å­˜å–ï¼Œç„¡éœ€ API é‡‘é‘°\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. å¯¦éš›è¨“ç·´è³‡æ–™æº–å‚™ç¯„ä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æº–å‚™è¨“ç·´è³‡æ–™çš„å®Œæ•´ç¯„ä¾‹\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"ğŸ¯ æº–å‚™å¯¦éš›è¨“ç·´è³‡æ–™...\\n\")\n",
    "\n",
    "# 1. æ”¶é›†æ­£æ¨£æœ¬ï¼ˆç¢ºèªçš„è¡Œæ˜Ÿï¼‰\n",
    "print(\"1ï¸âƒ£ æ”¶é›†æ­£æ¨£æœ¬ï¼ˆç¢ºèªçš„å‡Œæ—¥è¡Œæ˜Ÿï¼‰...\")\n",
    "try:\n",
    "    # å¾ NASA Exoplanet Archive ç²å–ç¢ºèªçš„ TESS è¡Œæ˜Ÿ\n",
    "    confirmed_planets = NasaExoplanetArchive.query_criteria(\n",
    "        table=\"ps\",\n",
    "        select=\"pl_name,tic_id,pl_orbper,pl_rade,pl_trandep\",\n",
    "        where=\"discoverymethod='Transit' and disc_facility like '%TESS%'\",\n",
    "        format=\"table\"\n",
    "    )\n",
    "    \n",
    "    # éæ¿¾æœ‰æ•ˆçš„ TIC ID\n",
    "    valid_planets = confirmed_planets[confirmed_planets['tic_id'].mask != True]\n",
    "    print(f\"âœ… æ‰¾åˆ° {len(valid_planets)} å€‹ TESS ç¢ºèªè¡Œæ˜Ÿå¯ç”¨æ–¼è¨“ç·´\")\n",
    "    \n",
    "    # é¸æ“‡å‰ 5 å€‹ä½œç‚ºç¯„ä¾‹\n",
    "    sample_planets = valid_planets[:5]\n",
    "    positive_samples = []\n",
    "    \n",
    "    for planet in sample_planets:\n",
    "        tic_id = f\"TIC {int(planet['tic_id'])}\"\n",
    "        positive_samples.append({\n",
    "            'id': tic_id,\n",
    "            'label': 1,  # æ­£æ¨£æœ¬\n",
    "            'type': 'planet',\n",
    "            'period': planet['pl_orbper'],\n",
    "            'depth': planet['pl_trandep'] if planet['pl_trandep'] else np.nan\n",
    "        })\n",
    "    \n",
    "    print(f\"   æº–å‚™äº† {len(positive_samples)} å€‹æ­£æ¨£æœ¬\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ç²å–æ­£æ¨£æœ¬æ™‚å‡ºéŒ¯: {e}\")\n",
    "    positive_samples = []\n",
    "\n",
    "# 2. æ”¶é›†è² æ¨£æœ¬ï¼ˆéè¡Œæ˜Ÿä¿¡è™Ÿï¼‰\n",
    "print(\"\\n2ï¸âƒ£ æ”¶é›†è² æ¨£æœ¬ï¼ˆå‡é™½æ€§/é›™æ˜Ÿï¼‰...\")\n",
    "try:\n",
    "    # å¾ TOI ç²å–å‡é™½æ€§\n",
    "    false_positives = NasaExoplanetArchive.query_criteria(\n",
    "        table=\"toi\",\n",
    "        select=\"tid,tfopwg_disp,toi_period\",\n",
    "        where=\"tfopwg_disp='FP'\",  # FP = False Positive\n",
    "        format=\"table\"\n",
    "    )\n",
    "    \n",
    "    # é¸æ“‡å‰ 5 å€‹\n",
    "    sample_fps = false_positives[:5]\n",
    "    negative_samples = []\n",
    "    \n",
    "    for fp in sample_fps:\n",
    "        tic_id = f\"TIC {int(fp['tid'])}\"\n",
    "        negative_samples.append({\n",
    "            'id': tic_id,\n",
    "            'label': 0,  # è² æ¨£æœ¬\n",
    "            'type': 'false_positive',\n",
    "            'period': fp['toi_period'] if fp['toi_period'] else np.nan\n",
    "        })\n",
    "    \n",
    "    print(f\"âœ… æº–å‚™äº† {len(negative_samples)} å€‹è² æ¨£æœ¬\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ç²å–è² æ¨£æœ¬æ™‚å‡ºéŒ¯: {e}\")\n",
    "    negative_samples = []\n",
    "\n",
    "# 3. åˆä½µè¨“ç·´è³‡æ–™é›†\n",
    "print(\"\\n3ï¸âƒ£ å»ºç«‹è¨“ç·´è³‡æ–™é›†...\")\n",
    "all_samples = positive_samples + negative_samples\n",
    "if len(all_samples) > 0:\n",
    "    df_train = pd.DataFrame(all_samples)\n",
    "    print(f\"âœ… è¨“ç·´è³‡æ–™é›†æº–å‚™å®Œæˆ\")\n",
    "    print(f\"   ç¸½æ¨£æœ¬æ•¸: {len(df_train)}\")\n",
    "    print(f\"   æ­£æ¨£æœ¬: {(df_train['label'] == 1).sum()}\")\n",
    "    print(f\"   è² æ¨£æœ¬: {(df_train['label'] == 0).sum()}\")\n",
    "    print(\"\\nè¨“ç·´è³‡æ–™é›†ç¯„ä¾‹:\")\n",
    "    print(df_train.head())\n",
    "else:\n",
    "    print(\"âŒ ç„¡æ³•å»ºç«‹è¨“ç·´è³‡æ–™é›†\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"âœ… è³‡æ–™é›†é©—è­‰å®Œæˆï¼\")\n",
    "print(\"ğŸ“ ç¸½çµï¼šæ‰€æœ‰ DATASETS.md ä¸­æåˆ°çš„è³‡æ–™ä¾†æºéƒ½å¯ä»¥å…è²»å­˜å–ä¸¦ç”¨æ–¼è¨“ç·´\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}