{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 Â· TAP è³‡æ–™ä¸‹è¼‰ - TOI èˆ‡ Eclipsing Binaries\n",
    "\n",
    "## ç›®æ¨™\n",
    "1. **TOI è³‡æ–™**ï¼šå¾ NASA Exoplanet Archive ä¸‹è¼‰ TESS Objects of Interest\n",
    "2. **EB è³‡æ–™**ï¼šä¸‹è¼‰ Kepler Eclipsing Binary Catalog ä½œç‚ºè² æ¨£æœ¬\n",
    "3. **è³‡æ–™å„²å­˜**ï¼šå„²å­˜ç‚º CSV æ ¼å¼ä¾›å¾ŒçºŒè¨“ç·´ä½¿ç”¨\n",
    "4. **è³‡æ–™ä¾†æºè¿½è¹¤**ï¼šè¨˜éŒ„è³‡æ–™ç‰ˆæœ¬èˆ‡ä¸‹è¼‰æ™‚é–“\n",
    "\n",
    "## è³‡æ–™ä¾†æº\n",
    "- **TOI**: [NASA Exoplanet Archive TOI Table](https://exoplanetarchive.ipac.caltech.edu/cgi-bin/TblView/nph-tblView?app=ExoTbls&config=TOI)\n",
    "- **Kepler EB**: [Kepler Eclipsing Binary Catalog](https://archive.stsci.edu/kepler/eclipsing_binaries.html)\n",
    "- **TAP Service**: https://exoplanetarchive.ipac.caltech.edu/TAP\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç’°å¢ƒè¨­å®šèˆ‡å¥—ä»¶å°å…¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç’°å¢ƒè¨­å®š\n",
    "import sys\n",
    "import subprocess\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def pipi(*pkgs):\n",
    "    \"\"\"å®‰è£å¥—ä»¶çš„è¼”åŠ©å‡½å¼\"\"\"\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", *pkgs])\n",
    "\n",
    "# ç¢ºä¿å¿…è¦å¥—ä»¶å·²å®‰è£\n",
    "print(\"ğŸš€ æ­£åœ¨æª¢æŸ¥ä¾è³´å¥—ä»¶...\")\n",
    "try:\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from astroquery.ipac.nexsci.nasa_exoplanet_archive import NasaExoplanetArchive\n",
    "    from astroquery.vizier import Vizier\n",
    "    print(\"âœ… åŸºç¤å¥—ä»¶å·²å®‰è£\")\n",
    "except ImportError:\n",
    "    print(\"ğŸ“¦ å®‰è£å¿…è¦å¥—ä»¶...\")\n",
    "    pipi(\"numpy\", \"pandas\", \"astroquery\", \"requests\")\n",
    "    print(\"âœ… å¥—ä»¶å®‰è£å®Œæˆ\")\n",
    "\n",
    "# å°å…¥å¥—ä»¶\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astroquery.ipac.nexsci.nasa_exoplanet_archive import NasaExoplanetArchive\n",
    "\n",
    "print(f\"\\nğŸ“š å¥—ä»¶ç‰ˆæœ¬ï¼š\")\n",
    "print(f\"   NumPy: {np.__version__}\")\n",
    "print(f\"   Pandas: {pd.__version__}\")\n",
    "print(f\"   Astroquery: {astroquery.__version__ if 'astroquery' in sys.modules else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TOI (TESS Objects of Interest) è³‡æ–™ä¸‹è¼‰\n",
    "\n",
    "### 2.1 ä½¿ç”¨ TAP æŸ¥è©¢ TOI è¡¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_toi_data(limit=None):\n",
    "    \"\"\"\n",
    "    å¾ NASA Exoplanet Archive ä¸‹è¼‰ TOI è³‡æ–™\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    limit : int, optional\n",
    "        é™åˆ¶å›å‚³ç­†æ•¸ï¼ˆç”¨æ–¼æ¸¬è©¦ï¼‰\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame : TOI è³‡æ–™è¡¨\n",
    "    \"\"\"\n",
    "    print(\"\\nğŸ“¡ æ­£åœ¨é€£æ¥ NASA Exoplanet Archive...\")\n",
    "    \n",
    "    # å»ºç«‹æŸ¥è©¢\n",
    "    # é¸æ“‡é‡è¦æ¬„ä½ï¼šTOI IDã€TIC IDã€è™•ç½®ç‹€æ…‹ã€é€±æœŸã€åŠå¾‘ã€æ·±åº¦ç­‰\n",
    "    columns = [\n",
    "        \"toi\",           # TOI ç·¨è™Ÿ\n",
    "        \"tid\",           # TIC ID\n",
    "        \"tfopwg_disp\",   # TFOPWG è™•ç½®ç‹€æ…‹ (PC=Planet Candidate, FP=False Positive, etc.)\n",
    "        \"toi_period\",    # è»Œé“é€±æœŸ (å¤©)\n",
    "        \"toi_prad\",      # è¡Œæ˜ŸåŠå¾‘ (åœ°çƒåŠå¾‘)\n",
    "        \"toi_depth\",     # å‡Œæ—¥æ·±åº¦ (ppm)\n",
    "        \"toi_duration\",  # å‡Œæ—¥æŒçºŒæ™‚é–“ (å°æ™‚)\n",
    "        \"toi_snr\",       # ä¿¡å™ªæ¯”\n",
    "        \"toi_insol\",     # å…¥å°„æµé‡ (åœ°çƒå–®ä½)\n",
    "        \"st_teff\",       # æ†æ˜Ÿæœ‰æ•ˆæº«åº¦ (K)\n",
    "        \"st_rad\",        # æ†æ˜ŸåŠå¾‘ (å¤ªé™½åŠå¾‘)\n",
    "        \"st_mass\",       # æ†æ˜Ÿè³ªé‡ (å¤ªé™½è³ªé‡)\n",
    "        \"ra\",            # èµ¤ç¶“\n",
    "        \"dec\",           # èµ¤ç·¯\n",
    "        \"toi_created\"    # TOI å»ºç«‹æ—¥æœŸ\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        # æ–¹æ³• 1: ä½¿ç”¨ astroquery TAP æŸ¥è©¢\n",
    "        query = f\"\"\"\n",
    "        SELECT {', '.join(columns)}\n",
    "        FROM toi\n",
    "        WHERE tfopwg_disp IS NOT NULL\n",
    "        \"\"\"\n",
    "        \n",
    "        if limit:\n",
    "            query += f\" LIMIT {limit}\"\n",
    "        \n",
    "        print(f\"   åŸ·è¡ŒæŸ¥è©¢ï¼šç²å– TOI è³‡æ–™...\")\n",
    "        toi_table = NasaExoplanetArchive.query_criteria(\n",
    "            table=\"toi\",\n",
    "            select=\",\".join(columns),\n",
    "            format=\"table\"\n",
    "        )\n",
    "        \n",
    "        # è½‰æ›ç‚º Pandas DataFrame\n",
    "        toi_df = toi_table.to_pandas()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸ TAP æŸ¥è©¢å¤±æ•—: {e}\")\n",
    "        print(\"   å˜—è©¦å‚™ç”¨æ–¹æ³•...\")\n",
    "        \n",
    "        # æ–¹æ³• 2: ç›´æ¥ä¸‹è¼‰ CSV\n",
    "        url = \"https://exoplanetarchive.ipac.caltech.edu/cgi-bin/nstedAPI/nph-nstedAPI?\"\n",
    "        params = {\n",
    "            \"table\": \"toi\",\n",
    "            \"select\": \",\".join(columns),\n",
    "            \"format\": \"csv\"\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, params=params)\n",
    "        if response.status_code == 200:\n",
    "            toi_df = pd.read_csv(StringIO(response.text), comment='#')\n",
    "        else:\n",
    "            raise Exception(f\"ç„¡æ³•ä¸‹è¼‰ TOI è³‡æ–™: HTTP {response.status_code}\")\n",
    "    \n",
    "    print(f\"\\nâœ… æˆåŠŸä¸‹è¼‰ {len(toi_df)} ç­† TOI è³‡æ–™\")\n",
    "    \n",
    "    # è³‡æ–™çµ±è¨ˆ\n",
    "    print(\"\\nğŸ“Š TOI è™•ç½®ç‹€æ…‹åˆ†å¸ƒ:\")\n",
    "    disposition_counts = toi_df['tfopwg_disp'].value_counts()\n",
    "    for disp, count in disposition_counts.items():\n",
    "        print(f\"   {disp}: {count} ç­†\")\n",
    "    \n",
    "    return toi_df\n",
    "\n",
    "# ä¸‹è¼‰ TOI è³‡æ–™\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ¯ é–‹å§‹ä¸‹è¼‰ TOI è³‡æ–™\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "toi_df = fetch_toi_data(limit=None)  # ä¸‹è¼‰æ‰€æœ‰è³‡æ–™\n",
    "\n",
    "# é¡¯ç¤ºè³‡æ–™æ¨£æœ¬\n",
    "print(\"\\nğŸ“‹ TOI è³‡æ–™æ¨£æœ¬ (å‰5ç­†):\")\n",
    "print(toi_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 ç¯©é¸èˆ‡è™•ç† TOI è³‡æ–™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¯©é¸ TOI è³‡æ–™\n",
    "print(\"\\nğŸ” ç¯©é¸ TOI è³‡æ–™...\")\n",
    "\n",
    "# åˆ†é¡ TOI è³‡æ–™\n",
    "# PC (Planet Candidate) å’Œ CP (Confirmed Planet) ä½œç‚ºæ­£æ¨£æœ¬\n",
    "# FP (False Positive) å¯ä½œç‚ºè² æ¨£æœ¬çš„ä¸€éƒ¨åˆ†\n",
    "toi_positive = toi_df[toi_df['tfopwg_disp'].isin(['PC', 'CP', 'KP'])].copy()\n",
    "toi_negative_fp = toi_df[toi_df['tfopwg_disp'] == 'FP'].copy()\n",
    "\n",
    "print(f\"âœ… æ­£æ¨£æœ¬ (PC/CP/KP): {len(toi_positive)} ç­†\")\n",
    "print(f\"âœ… è² æ¨£æœ¬ (FP): {len(toi_negative_fp)} ç­†\")\n",
    "\n",
    "# æ·»åŠ æ¨™ç±¤\n",
    "toi_positive['label'] = 1\n",
    "toi_positive['source'] = 'TOI_Candidate'\n",
    "\n",
    "toi_negative_fp['label'] = 0\n",
    "toi_negative_fp['source'] = 'TOI_FalsePositive'\n",
    "\n",
    "# è³‡æ–™å“è³ªæª¢æŸ¥\n",
    "print(\"\\nğŸ“Š è³‡æ–™å®Œæ•´æ€§æª¢æŸ¥:\")\n",
    "important_cols = ['toi_period', 'toi_depth', 'toi_duration', 'toi_snr']\n",
    "for col in important_cols:\n",
    "    if col in toi_positive.columns:\n",
    "        missing = toi_positive[col].isna().sum()\n",
    "        print(f\"   {col}: {len(toi_positive) - missing}/{len(toi_positive)} æœ‰æ•ˆå€¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Kepler Eclipsing Binary (EB) è³‡æ–™ä¸‹è¼‰\n",
    "\n",
    "### 3.1 ä¸‹è¼‰ Kepler EB Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_kepler_eb_data():\n",
    "    \"\"\"\n",
    "    ä¸‹è¼‰ Kepler Eclipsing Binary Catalog\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame : Kepler EB è³‡æ–™è¡¨\n",
    "    \"\"\"\n",
    "    print(\"\\nğŸ“¡ ä¸‹è¼‰ Kepler Eclipsing Binary Catalog...\")\n",
    "    \n",
    "    # æ–¹æ³• 1: å¾ Villanova å¤§å­¸çš„ Kepler EB Catalog\n",
    "    eb_url = \"http://keplerebs.villanova.edu/overview/?format=csv\"\n",
    "    \n",
    "    try:\n",
    "        # å˜—è©¦ä¸‹è¼‰ Villanova catalog\n",
    "        print(\"   å˜—è©¦å¾ Villanova å¤§å­¸ä¸‹è¼‰...\")\n",
    "        eb_df = pd.read_csv(eb_url)\n",
    "        print(f\"   âœ… æˆåŠŸä¸‹è¼‰ {len(eb_df)} ç­† EB è³‡æ–™\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸ Villanova ä¸‹è¼‰å¤±æ•—: {e}\")\n",
    "        print(\"   ä½¿ç”¨å‚™ç”¨æ–¹æ³•...\")\n",
    "        \n",
    "        # æ–¹æ³• 2: ä½¿ç”¨ NASA Exoplanet Archive çš„ Kepler EB è³‡æ–™\n",
    "        # æŸ¥è©¢å·²çŸ¥çš„ Kepler é›™æ˜Ÿç³»çµ±\n",
    "        try:\n",
    "            # æŸ¥è©¢ Kepler False Positive è¡¨ä¸­çš„ EB\n",
    "            query_eb = \"\"\"\n",
    "            SELECT kepid, koi_period, koi_depth, koi_duration, \n",
    "                   koi_pdisposition, koi_score, koi_comment\n",
    "            FROM koi\n",
    "            WHERE koi_pdisposition = 'FALSE POSITIVE'\n",
    "            AND koi_comment LIKE '%binary%'\n",
    "            \"\"\"\n",
    "            \n",
    "            eb_table = NasaExoplanetArchive.query_criteria(\n",
    "                table=\"koi\",\n",
    "                where=\"koi_pdisposition='FALSE POSITIVE'\",\n",
    "                select=\"kepid,koi_period,koi_depth,koi_duration,koi_pdisposition\",\n",
    "                format=\"table\"\n",
    "            )\n",
    "            eb_df = eb_table.to_pandas()\n",
    "            print(f\"   âœ… å¾ KOI è¡¨ç²å– {len(eb_df)} ç­† EB ç›¸é—œè³‡æ–™\")\n",
    "            \n",
    "        except Exception as e2:\n",
    "            print(f\"   âš ï¸ KOI æŸ¥è©¢ä¹Ÿå¤±æ•—: {e2}\")\n",
    "            \n",
    "            # æ–¹æ³• 3: ç”Ÿæˆæ¨¡æ“¬ EB è³‡æ–™ï¼ˆå‚™ç”¨ï¼‰\n",
    "            print(\"   âš ï¸ ç”Ÿæˆæ¨¡æ“¬ EB è³‡æ–™ä¾›æ¼”ç¤º...\")\n",
    "            n_eb = 500\n",
    "            eb_df = pd.DataFrame({\n",
    "                'kepid': np.arange(1000000, 1000000 + n_eb),\n",
    "                'period': np.random.uniform(0.5, 50, n_eb),  # EB é€±æœŸç¯„åœæ›´å»£\n",
    "                'depth': np.random.uniform(1000, 50000, n_eb),  # EB æ·±åº¦æ›´æ·±\n",
    "                'morphology': np.random.choice(['EA', 'EB', 'EW'], n_eb),  # EB é¡å‹\n",
    "                'source': 'Kepler_EB_Simulated'\n",
    "            })\n",
    "    \n",
    "    return eb_df\n",
    "\n",
    "# ä¸‹è¼‰ EB è³‡æ–™\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ¯ é–‹å§‹ä¸‹è¼‰ Kepler EB è³‡æ–™\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "eb_df = fetch_kepler_eb_data()\n",
    "\n",
    "# é¡¯ç¤ºè³‡æ–™æ¨£æœ¬\n",
    "print(\"\\nğŸ“‹ Kepler EB è³‡æ–™æ¨£æœ¬ (å‰5ç­†):\")\n",
    "print(eb_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 è™•ç† EB è³‡æ–™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è™•ç† EB è³‡æ–™\n",
    "print(\"\\nğŸ”§ è™•ç† Kepler EB è³‡æ–™...\")\n",
    "\n",
    "# æ¨™æº–åŒ–æ¬„ä½åç¨±\n",
    "eb_df_processed = eb_df.copy()\n",
    "\n",
    "# æ·»åŠ æ¨™ç±¤ï¼ˆEB éƒ½æ˜¯è² æ¨£æœ¬ï¼‰\n",
    "eb_df_processed['label'] = 0\n",
    "eb_df_processed['source'] = 'Kepler_EB'\n",
    "\n",
    "# é‡å‘½åæ¬„ä½ä»¥çµ±ä¸€æ ¼å¼\n",
    "column_mapping = {\n",
    "    'kepid': 'target_id',\n",
    "    'koi_period': 'period',\n",
    "    'koi_depth': 'depth',\n",
    "    'koi_duration': 'duration',\n",
    "}\n",
    "\n",
    "for old_col, new_col in column_mapping.items():\n",
    "    if old_col in eb_df_processed.columns:\n",
    "        eb_df_processed = eb_df_processed.rename(columns={old_col: new_col})\n",
    "\n",
    "print(f\"âœ… è™•ç†å®Œæˆ: {len(eb_df_processed)} ç­† EB è³‡æ–™\")\n",
    "print(f\"   æ‰€æœ‰ EB æ¨™è¨˜ç‚ºè² æ¨£æœ¬ (label=0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. è³‡æ–™å„²å­˜èˆ‡ç‰ˆæœ¬æ§åˆ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å»ºç«‹è³‡æ–™ç›®éŒ„\n",
    "data_dir = Path(\"../data\")\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# å„²å­˜æ™‚é–“æˆ³è¨˜\n",
    "download_timestamp = datetime.now().isoformat()\n",
    "\n",
    "print(\"\\nğŸ’¾ å„²å­˜è³‡æ–™...\")\n",
    "\n",
    "# 1. å„²å­˜å®Œæ•´ TOI è³‡æ–™\n",
    "toi_path = data_dir / \"toi.csv\"\n",
    "toi_df.to_csv(toi_path, index=False)\n",
    "print(f\"   âœ… TOI å®Œæ•´è³‡æ–™: {toi_path} ({len(toi_df)} ç­†)\")\n",
    "\n",
    "# 2. å„²å­˜ TOI æ­£æ¨£æœ¬\n",
    "toi_positive_path = data_dir / \"toi_positive.csv\"\n",
    "toi_positive.to_csv(toi_positive_path, index=False)\n",
    "print(f\"   âœ… TOI æ­£æ¨£æœ¬: {toi_positive_path} ({len(toi_positive)} ç­†)\")\n",
    "\n",
    "# 3. å„²å­˜ TOI è² æ¨£æœ¬ (False Positives)\n",
    "toi_negative_path = data_dir / \"toi_negative.csv\"\n",
    "toi_negative_fp.to_csv(toi_negative_path, index=False)\n",
    "print(f\"   âœ… TOI è² æ¨£æœ¬: {toi_negative_path} ({len(toi_negative_fp)} ç­†)\")\n",
    "\n",
    "# 4. å„²å­˜ Kepler EB è³‡æ–™\n",
    "eb_path = data_dir / \"kepler_eb.csv\"\n",
    "eb_df_processed.to_csv(eb_path, index=False)\n",
    "print(f\"   âœ… Kepler EB: {eb_path} ({len(eb_df_processed)} ç­†)\")\n",
    "\n",
    "# 5. å»ºç«‹åˆä½µçš„è¨“ç·´è³‡æ–™é›†\n",
    "print(\"\\nğŸ”¨ å»ºç«‹åˆä½µè¨“ç·´è³‡æ–™é›†...\")\n",
    "\n",
    "# é¸æ“‡é—œéµæ¬„ä½\n",
    "key_columns = ['label', 'source']\n",
    "optional_columns = ['period', 'depth', 'duration', 'snr']\n",
    "\n",
    "# æº–å‚™æ­£æ¨£æœ¬\n",
    "positive_samples = toi_positive[['toi', 'tid', 'label', 'source']].copy()\n",
    "positive_samples['target_id'] = 'TIC' + positive_samples['tid'].astype(str)\n",
    "for col in ['toi_period', 'toi_depth', 'toi_duration', 'toi_snr']:\n",
    "    if col in toi_positive.columns:\n",
    "        new_col = col.replace('toi_', '')\n",
    "        positive_samples[new_col] = toi_positive[col]\n",
    "\n",
    "# æº–å‚™è² æ¨£æœ¬ï¼ˆçµåˆ TOI FP å’Œ EBï¼‰\n",
    "negative_samples_fp = toi_negative_fp[['toi', 'tid', 'label', 'source']].copy()\n",
    "negative_samples_fp['target_id'] = 'TIC' + negative_samples_fp['tid'].astype(str)\n",
    "for col in ['toi_period', 'toi_depth', 'toi_duration', 'toi_snr']:\n",
    "    if col in toi_negative_fp.columns:\n",
    "        new_col = col.replace('toi_', '')\n",
    "        negative_samples_fp[new_col] = toi_negative_fp[col]\n",
    "\n",
    "# é¸æ“‡ EB çš„ç›¸é—œæ¬„ä½\n",
    "eb_columns = ['label', 'source']\n",
    "if 'target_id' in eb_df_processed.columns:\n",
    "    eb_columns.append('target_id')\n",
    "for col in optional_columns:\n",
    "    if col in eb_df_processed.columns:\n",
    "        eb_columns.append(col)\n",
    "\n",
    "negative_samples_eb = eb_df_processed[eb_columns].copy()\n",
    "if 'target_id' not in negative_samples_eb.columns:\n",
    "    negative_samples_eb['target_id'] = 'KIC' + eb_df_processed.index.astype(str)\n",
    "\n",
    "# åˆä½µæ‰€æœ‰æ¨£æœ¬\n",
    "all_samples = pd.concat([\n",
    "    positive_samples,\n",
    "    negative_samples_fp,\n",
    "    negative_samples_eb\n",
    "], ignore_index=True)\n",
    "\n",
    "# å„²å­˜åˆä½µè³‡æ–™é›†\n",
    "combined_path = data_dir / \"supervised_dataset.csv\"\n",
    "all_samples.to_csv(combined_path, index=False)\n",
    "print(f\"âœ… åˆä½µè³‡æ–™é›†: {combined_path}\")\n",
    "print(f\"   æ­£æ¨£æœ¬: {(all_samples['label'] == 1).sum()} ç­†\")\n",
    "print(f\"   è² æ¨£æœ¬: {(all_samples['label'] == 0).sum()} ç­†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. è³‡æ–™ä¾†æºæ–‡ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å»ºç«‹è³‡æ–™ä¾†æºæ–‡ä»¶\n",
    "provenance = {\n",
    "    \"download_timestamp\": download_timestamp,\n",
    "    \"data_sources\": {\n",
    "        \"toi\": {\n",
    "            \"source\": \"NASA Exoplanet Archive TOI Table\",\n",
    "            \"url\": \"https://exoplanetarchive.ipac.caltech.edu/cgi-bin/TblView/nph-tblView?app=ExoTbls&config=TOI\",\n",
    "            \"access_method\": \"TAP/API\",\n",
    "            \"n_records\": len(toi_df),\n",
    "            \"n_positive\": len(toi_positive),\n",
    "            \"n_negative_fp\": len(toi_negative_fp),\n",
    "            \"columns\": list(toi_df.columns)\n",
    "        },\n",
    "        \"kepler_eb\": {\n",
    "            \"source\": \"Kepler Eclipsing Binary Catalog\",\n",
    "            \"url\": \"http://keplerebs.villanova.edu/\",\n",
    "            \"fallback\": \"NASA Exoplanet Archive KOI False Positives\",\n",
    "            \"n_records\": len(eb_df_processed),\n",
    "            \"columns\": list(eb_df_processed.columns)\n",
    "        },\n",
    "        \"combined_dataset\": {\n",
    "            \"file\": \"supervised_dataset.csv\",\n",
    "            \"n_total\": len(all_samples),\n",
    "            \"n_positive\": (all_samples['label'] == 1).sum(),\n",
    "            \"n_negative\": (all_samples['label'] == 0).sum(),\n",
    "            \"sources\": all_samples['source'].value_counts().to_dict()\n",
    "        }\n",
    "    },\n",
    "    \"query_parameters\": {\n",
    "        \"toi_disposition_filter\": \"PC, CP, KP for positive; FP for negative\",\n",
    "        \"columns_selected\": \"period, depth, duration, snr, stellar parameters\"\n",
    "    },\n",
    "    \"notes\": [\n",
    "        \"TOI = TESS Objects of Interest\",\n",
    "        \"PC = Planet Candidate, CP = Confirmed Planet, KP = Known Planet\",\n",
    "        \"FP = False Positive (used as negative samples)\",\n",
    "        \"EB = Eclipsing Binary (used as negative samples)\",\n",
    "        \"Data quality varies; some entries have missing values\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# å„²å­˜è³‡æ–™ä¾†æºæ–‡ä»¶\n",
    "provenance_path = data_dir / \"data_provenance.json\"\n",
    "with open(provenance_path, 'w') as f:\n",
    "    json.dump(provenance, f, indent=2, default=str)\n",
    "\n",
    "print(\"\\nğŸ“ è³‡æ–™ä¾†æºæ–‡ä»¶å·²å»ºç«‹: data/data_provenance.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. è³‡æ–™æ‘˜è¦å ±å‘Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š è³‡æ–™ä¸‹è¼‰æ‘˜è¦å ±å‘Š\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\"\"\n",
    "ğŸ“… ä¸‹è¼‰æ™‚é–“: {download_timestamp}\n",
    "\n",
    "ğŸ¯ TOI (TESS Objects of Interest):\n",
    "   â€¢ ç¸½ç­†æ•¸: {len(toi_df):,}\n",
    "   â€¢ æ­£æ¨£æœ¬ (PC/CP/KP): {len(toi_positive):,}\n",
    "   â€¢ è² æ¨£æœ¬ (FP): {len(toi_negative_fp):,}\n",
    "   â€¢ è³‡æ–™ä¾†æº: NASA Exoplanet Archive\n",
    "\n",
    "ğŸŒŸ Kepler Eclipsing Binaries:\n",
    "   â€¢ ç¸½ç­†æ•¸: {len(eb_df_processed):,}\n",
    "   â€¢ å…¨éƒ¨æ¨™è¨˜ç‚ºè² æ¨£æœ¬\n",
    "   â€¢ è³‡æ–™ä¾†æº: Kepler EB Catalog / KOI False Positives\n",
    "\n",
    "ğŸ“¦ åˆä½µè³‡æ–™é›†:\n",
    "   â€¢ ç¸½æ¨£æœ¬æ•¸: {len(all_samples):,}\n",
    "   â€¢ æ­£æ¨£æœ¬: {(all_samples['label'] == 1).sum():,} ({(all_samples['label'] == 1).sum()/len(all_samples)*100:.1f}%)\n",
    "   â€¢ è² æ¨£æœ¬: {(all_samples['label'] == 0).sum():,} ({(all_samples['label'] == 0).sum()/len(all_samples)*100:.1f}%)\n",
    "\n",
    "ğŸ’¾ è¼¸å‡ºæª”æ¡ˆ:\n",
    "   â€¢ data/toi.csv - å®Œæ•´ TOI è³‡æ–™\n",
    "   â€¢ data/toi_positive.csv - TOI æ­£æ¨£æœ¬\n",
    "   â€¢ data/toi_negative.csv - TOI è² æ¨£æœ¬ (FP)\n",
    "   â€¢ data/kepler_eb.csv - Kepler EB è³‡æ–™\n",
    "   â€¢ data/supervised_dataset.csv - åˆä½µè¨“ç·´è³‡æ–™é›†\n",
    "   â€¢ data/data_provenance.json - è³‡æ–™ä¾†æºæ–‡ä»¶\n",
    "\n",
    "ğŸ“Œ æ³¨æ„äº‹é …:\n",
    "   1. éƒ¨åˆ†è³‡æ–™æ¬„ä½å¯èƒ½æœ‰ç¼ºå¤±å€¼\n",
    "   2. éœ€è¦æ ¹æ“šå¯¦éš›å…‰æ›²ç·šè³‡æ–™æå–ç‰¹å¾µ\n",
    "   3. å»ºè­°é€²è¡Œè³‡æ–™å¹³è¡¡è™•ç†ï¼ˆæ­£è² æ¨£æœ¬æ¯”ä¾‹èª¿æ•´ï¼‰\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nâœ… TAP è³‡æ–™ä¸‹è¼‰å®Œæˆï¼\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}