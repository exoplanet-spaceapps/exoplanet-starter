{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 · BLS Baseline - 光曲線分析與週期搜尋\n",
    "\n",
    "## 目標\n",
    "1. **資料抓取與清理**：使用 Lightkurve 下載 TESS/Kepler 光曲線\n",
    "2. **去趨勢處理**：移除系統性雜訊以凸顯凌日訊號\n",
    "3. **BLS/TLS 搜尋**：尋找週期性凌日事件\n",
    "4. **視覺化與分析**：比較不同方法的效能差異\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 步驟 0: 安裝套件與修復 NumPy 2.0 相容性 (Colab 環境)\n",
    "# ⚠️ 重要: 若在 Google Colab，執行此 cell 後請手動重啟 Runtime (Runtime → Restart runtime)\n",
    "\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"📍 偵測到 Google Colab 環境\")\n",
    "    print(\"🔧 安裝相容版本套件...\")\n",
    "    !pip install -q numpy==1.26.4 pandas astropy scipy'<1.13' matplotlib scikit-learn\n",
    "    !pip install -q lightkurve astroquery transitleastsquares wotan\n",
    "    print(\"✅ 套件安裝完成!\")\n",
    "    print(\"⚠️ 請現在手動重啟 Runtime: Runtime → Restart runtime\")\n",
    "    print(\"   然後從下一個 cell 繼續執行\")\n",
    "else:\n",
    "    print(\"💻 本地環境，跳過套件安裝\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 環境設定與依賴安裝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 環境設定與依賴安裝（Colab）\n",
    "import sys, subprocess, pkgutil\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def pipi(*pkgs):\n",
    "    \"\"\"安裝套件的輔助函式\"\"\"\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", *pkgs])\n",
    "\n",
    "# 安裝必要套件（避免 numpy 2.0 相容性問題）\n",
    "print(\"🚀 正在安裝依賴套件...\")\n",
    "try:\n",
    "    import numpy as np\n",
    "    import lightkurve as lk\n",
    "    import transitleastsquares as tls\n",
    "    print(\"✅ 基礎套件已安裝\")\n",
    "except Exception:\n",
    "    pipi(\"numpy<2\", \"lightkurve\", \"astroquery\", \"scikit-learn\", \n",
    "         \"matplotlib\", \"wotan\", \"transitleastsquares\")\n",
    "    print(\"✅ 依賴套件安裝完成\")\n",
    "\n",
    "# 檢查 GPU 資訊\n",
    "# 檢查 GPU 資訊（嘗試導入 torch）\n",
    "try:\n",
    "    import torch\n",
    "except ImportError:\n",
    "    torch = None\n",
    "\n",
    "if torch is not None and torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    print(f\"🖥️ GPU 型號: {gpu_name}\")\n",
    "    print(f\"   記憶體: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    \n",
    "    # 如果是 NVIDIA L4，提供 BF16 優化建議\n",
    "    if \"L4\" in gpu_name:\n",
    "        print(\"💡 偵測到 NVIDIA L4 GPU - 支援高效能 BF16 運算\")\n",
    "        print(\"   建議在訓練時使用 torch.autocast('cuda', dtype=torch.bfloat16)\")\n",
    "else:\n",
    "    try:\n",
    "        # 使用 nvidia-smi 檢查 GPU\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=name', '--format=csv,noheader'], \n",
    "                              capture_output=True, text=True, check=False)\n",
    "        if result.returncode == 0:\n",
    "            gpu_name = result.stdout.strip()\n",
    "            print(f\"🖥️ GPU 型號: {gpu_name}\")\n",
    "            if \"L4\" in gpu_name:\n",
    "                print(\"💡 偵測到 NVIDIA L4 GPU - 支援高效能 BF16 運算\")\n",
    "    except:\n",
    "        print(\"⚠️ 未偵測到 GPU，將使用 CPU 運算\")\n",
    "\n",
    "print(\"\\n環境設定完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔧 設定可重現性與日誌記錄 (2025 Best Practices)\"\"\"Phase 1: Critical Infrastructure- 設定隨機種子確保可重現性- 初始化日誌記錄系統- 記錄系統環境資訊\"\"\"import sysimport osfrom pathlib import Path# 確保 src 目錄在 Python 路徑中if IN_COLAB:    # Colab 環境：專案在 /content/exoplanet-starter    src_path = Path('/content/exoplanet-starter/src')else:    # 本地環境：向上一層找到專案根目錄    src_path = Path(__file__).parent.parent / 'src' if '__file__' in globals() else Path('../src').resolve()if src_path.exists() and str(src_path) not in sys.path:    sys.path.insert(0, str(src_path))    print(f\"📂 已添加 src 路徑: {src_path}\")# 導入工具模組try:    from utils import set_random_seeds, setup_logger, get_log_file_path, log_system_info    # 1️⃣ 設定隨機種子 (確保可重現性)    set_random_seeds(42)    # 2️⃣ 設定日誌記錄    log_file = get_log_file_path(\"02_bls_baseline\", results_dir=Path(\"../results\") if not IN_COLAB else Path(\"/content/exoplanet-starter/results\"))    logger = setup_logger(\"02_bls_baseline\", log_file=log_file, verbose=True)    # 3️⃣ 記錄系統資訊    logger.info(\"=\"*60)    logger.info(\"🚀 02_bls_baseline.ipynb 開始執行\")    logger.info(\"=\"*60)    log_system_info(logger)    print(\"✅ 可重現性與日誌記錄設定完成\")    print(f\"   📝 日誌檔案: {log_file}\")    print(f\"   🎲 隨機種子: 42\")except ImportError as e:    print(f\"⚠️ 無法導入工具模組: {e}\")    print(\"   跳過可重現性設定，繼續執行...\")    # 如果導入失敗，創建一個簡單的 logger fallback    import logging    logger = logging.getLogger(\"02_bls_baseline\")    logger.addHandler(logging.StreamHandler(sys.stdout))    logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 導入必要套件與設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightkurve as lk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import pandas as pd\n",
    "from transitleastsquares import transitleastsquares\n",
    "from typing import Dict, Any, Tuple, Optional\n",
    "import time\n",
    "\n",
    "# 設定圖表風格\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"📚 套件導入完成\")\n",
    "print(f\"   Lightkurve 版本: {lk.__version__}\")\n",
    "print(f\"   NumPy 版本: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 資料抓取與清理\n",
    "\n",
    "### 3.1 目標天體選擇\n",
    "我們將分析三個已確認的系外行星宿主恆星：\n",
    "- **2個 TESS 目標 (TIC)**：TIC 25155310（TOI-431）、TIC 307210830（TOI-270）\n",
    "- **1個 Kepler 目標 (KIC)**：KIC 11904151（Kepler-10）\n",
    "\n",
    "這些目標都有已確認的行星，適合作為基準測試。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9998bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧪 === COMPREHENSIVE TESTING SUITE === 🧪\n",
    "# Run this cell to validate all critical components before full execution\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"🧪 Running Notebook 02 Validation Tests...\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "test_results = []\n",
    "\n",
    "# ==========================================\n",
    "# Test 1/5: NumPy Version Verification\n",
    "# ==========================================\n",
    "print(\"Test 1/5: NumPy version compatibility...\")\n",
    "try:\n",
    "    import numpy as np\n",
    "    version = np.__version__\n",
    "    is_compatible = version.startswith('1.26')\n",
    "\n",
    "    if is_compatible:\n",
    "        print(f\"  ✅ NumPy {version} detected (compatible)\")\n",
    "        test_results.append((\"NumPy version\", True))\n",
    "    else:\n",
    "        print(f\"  ❌ NumPy {version} incompatible (need 1.26.x)\")\n",
    "        print(f\"     Run: pip install numpy==1.26.4\")\n",
    "        test_results.append((\"NumPy version\", False))\n",
    "except Exception as e:\n",
    "    print(f\"  ❌ NumPy check failed: {e}\")\n",
    "    test_results.append((\"NumPy version\", False))\n",
    "print()\n",
    "\n",
    "# ==========================================\n",
    "# Test 2/5: Checkpoint System\n",
    "# ==========================================\n",
    "print(\"Test 2/5: Checkpoint system functionality...\")\n",
    "try:\n",
    "    import os\n",
    "    import json\n",
    "    import tempfile\n",
    "    from pathlib import Path\n",
    "\n",
    "    # Create temporary checkpoint directory\n",
    "    test_checkpoint_dir = tempfile.mkdtemp(prefix='test_checkpoints_')\n",
    "\n",
    "    # Define CheckpointManager class for testing\n",
    "    class TestCheckpointManager:\n",
    "        def __init__(self, checkpoint_dir, batch_size=10):\n",
    "            self.checkpoint_dir = Path(checkpoint_dir)\n",
    "            self.checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "            self.batch_size = batch_size\n",
    "            self.checkpoint_file = self.checkpoint_dir / 'progress.json'\n",
    "\n",
    "        def save_batch(self, data, batch_num):\n",
    "            checkpoint = {\n",
    "                'last_batch': batch_num,\n",
    "                'timestamp': str(pd.Timestamp.now()),\n",
    "                'batch_size': self.batch_size,\n",
    "                'data_sample': data\n",
    "            }\n",
    "            with open(self.checkpoint_file, 'w') as f:\n",
    "                json.dump(checkpoint, f)\n",
    "\n",
    "        def resume_from_last(self):\n",
    "            if self.checkpoint_file.exists():\n",
    "                with open(self.checkpoint_file, 'r') as f:\n",
    "                    checkpoint = json.load(f)\n",
    "                return checkpoint['last_batch'] + 1\n",
    "            return 0\n",
    "\n",
    "    # Test checkpoint save and resume\n",
    "    test_checkpoint_mgr = TestCheckpointManager(test_checkpoint_dir, batch_size=10)\n",
    "    test_data = {'sample_id': [1, 2, 3], 'bls_period': [3.5, 4.2, 2.1]}\n",
    "    test_checkpoint_mgr.save_batch(test_data, 0)\n",
    "    resumed_batch = test_checkpoint_mgr.resume_from_last()\n",
    "\n",
    "    # Cleanup\n",
    "    import shutil\n",
    "    shutil.rmtree(test_checkpoint_dir)\n",
    "\n",
    "    if resumed_batch == 1:\n",
    "        print(f\"  ✅ Checkpoint system working (resumed batch: {resumed_batch})\")\n",
    "        test_results.append((\"Checkpoint system\", True))\n",
    "    else:\n",
    "        print(f\"  ❌ Checkpoint resume failed (expected 1, got {resumed_batch})\")\n",
    "        test_results.append((\"Checkpoint system\", False))\n",
    "except Exception as e:\n",
    "    print(f\"  ❌ Checkpoint test failed: {e}\")\n",
    "    test_results.append((\"Checkpoint system\", False))\n",
    "print()\n",
    "\n",
    "# ==========================================\n",
    "# Test 3/5: Single Sample Feature Extraction\n",
    "# ==========================================\n",
    "print(\"Test 3/5: Feature extraction (single target)...\")\n",
    "try:\n",
    "    import lightkurve as lk\n",
    "    from astropy.timeseries import BoxLeastSquares\n",
    "\n",
    "    # Test with known TOI target\n",
    "    test_tic = \"25155310\"  # TOI-270 (known multi-planet system)\n",
    "\n",
    "    print(f\"  📡 Testing with TIC {test_tic} (TOI-270)...\")\n",
    "\n",
    "    # Download light curve\n",
    "    search_result = lk.search_lightcurve(f'TIC {test_tic}', mission='TESS', author='SPOC')\n",
    "\n",
    "    if len(search_result) > 0:\n",
    "        lc = search_result[0].download()\n",
    "        lc = lc.remove_nans().remove_outliers(sigma=5)\n",
    "\n",
    "        # Run BLS\n",
    "        period_grid = np.linspace(1.0, 15.0, 5000)\n",
    "        bls = BoxLeastSquares(lc.time.value, lc.flux.value)\n",
    "        bls_result = bls.power(period_grid)\n",
    "\n",
    "        # Extract basic features\n",
    "        test_features = {\n",
    "            'tic_id': test_tic,\n",
    "            'bls_period': float(bls_result.period[np.argmax(bls_result.power)]),\n",
    "            'bls_power': float(np.max(bls_result.power)),\n",
    "            'bls_depth': float(bls_result.depth[np.argmax(bls_result.power)]),\n",
    "            'bls_duration': float(bls_result.duration[np.argmax(bls_result.power)]),\n",
    "            'num_points': len(lc.time),\n",
    "            'flux_std': float(np.std(lc.flux.value)),\n",
    "            'flux_median': float(np.median(lc.flux.value))\n",
    "        }\n",
    "\n",
    "        # Validation\n",
    "        feature_count = len(test_features)\n",
    "        has_nan = any(pd.isna(list(test_features.values())))\n",
    "        valid_period = 1.0 <= test_features['bls_period'] <= 15.0\n",
    "\n",
    "        if not has_nan and valid_period and feature_count >= 8:\n",
    "            print(f\"  ✅ Extracted {feature_count} features successfully\")\n",
    "            print(f\"     - Period: {test_features['bls_period']:.3f} days\")\n",
    "            print(f\"     - Power: {test_features['bls_power']:.4f}\")\n",
    "            print(f\"     - Data points: {test_features['num_points']}\")\n",
    "            test_results.append((\"Feature extraction\", True))\n",
    "        else:\n",
    "            print(f\"  ⚠️  Features extracted but validation issues:\")\n",
    "            print(f\"     - NaN values: {has_nan}\")\n",
    "            print(f\"     - Valid period: {valid_period}\")\n",
    "            test_results.append((\"Feature extraction\", False))\n",
    "    else:\n",
    "        print(f\"  ⚠️  No data found for TIC {test_tic}\")\n",
    "        print(f\"     This is expected if MAST is unavailable\")\n",
    "        test_results.append((\"Feature extraction\", None))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"  ⚠️  Feature extraction test skipped: {e}\")\n",
    "    print(f\"     This is normal if MAST/Lightkurve is unavailable\")\n",
    "    test_results.append((\"Feature extraction\", None))\n",
    "print()\n",
    "\n",
    "# ==========================================\n",
    "# Test 4/5: Google Drive Access (Colab only)\n",
    "# ==========================================\n",
    "print(\"Test 4/5: Google Drive access...\")\n",
    "try:\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "\n",
    "    # Check if running in Colab\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        in_colab = True\n",
    "    except ImportError:\n",
    "        in_colab = False\n",
    "\n",
    "    if in_colab:\n",
    "        # Test Drive access\n",
    "        base_path = Path('/content/drive/MyDrive/spaceapps-exoplanet')\n",
    "        checkpoint_dir = base_path / 'checkpoints'\n",
    "\n",
    "        # Try to create and write test file\n",
    "        checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "        test_file = checkpoint_dir / 'test_access.txt'\n",
    "\n",
    "        with open(test_file, 'w') as f:\n",
    "            f.write('test')\n",
    "\n",
    "        exists = test_file.exists()\n",
    "\n",
    "        # Cleanup\n",
    "        test_file.unlink()\n",
    "\n",
    "        if exists:\n",
    "            print(f\"  ✅ Google Drive writable at {checkpoint_dir}\")\n",
    "            test_results.append((\"Google Drive access\", True))\n",
    "        else:\n",
    "            print(f\"  ❌ Cannot write to Google Drive\")\n",
    "            test_results.append((\"Google Drive access\", False))\n",
    "    else:\n",
    "        print(f\"  ℹ️  Not in Colab environment (local execution)\")\n",
    "        print(f\"     Checkpoint directory will use: ./checkpoints/\")\n",
    "        test_results.append((\"Google Drive access\", None))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"  ❌ Google Drive test failed: {e}\")\n",
    "    test_results.append((\"Google Drive access\", False))\n",
    "print()\n",
    "\n",
    "# ==========================================\n",
    "# Test 5/5: Batch Processing (Mini Test)\n",
    "# ==========================================\n",
    "print(\"Test 5/5: Batch processing (small scale)...\")\n",
    "try:\n",
    "    # Load sample data\n",
    "    data_path = Path('/content/drive/MyDrive/spaceapps-exoplanet/data') if in_colab else Path('./data')\n",
    "    supervised_csv = data_path / 'supervised_dataset.csv'\n",
    "\n",
    "    if supervised_csv.exists():\n",
    "        samples_df = pd.read_csv(supervised_csv)\n",
    "        test_samples = samples_df.head(5)  # Test with 5 samples\n",
    "\n",
    "        print(f\"  📊 Testing with {len(test_samples)} samples...\")\n",
    "\n",
    "        # Mock batch processing\n",
    "        successful = 0\n",
    "        failed = 0\n",
    "\n",
    "        for idx, row in test_samples.iterrows():\n",
    "            tic_id = row['TIC_ID']\n",
    "            try:\n",
    "                # Simulate feature extraction (lightweight)\n",
    "                search_result = lk.search_lightcurve(f'TIC {tic_id}', mission='TESS', author='SPOC')\n",
    "                if len(search_result) > 0:\n",
    "                    successful += 1\n",
    "                else:\n",
    "                    failed += 1\n",
    "            except Exception:\n",
    "                failed += 1\n",
    "\n",
    "        success_rate = successful / len(test_samples) if len(test_samples) > 0 else 0\n",
    "\n",
    "        if success_rate >= 0.4:  # At least 40% success\n",
    "            print(f\"  ✅ Batch test: {success_rate*100:.1f}% success rate ({successful}/{len(test_samples)})\")\n",
    "            test_results.append((\"Batch processing\", True))\n",
    "        else:\n",
    "            print(f\"  ⚠️  Low success rate: {success_rate*100:.1f}% ({successful}/{len(test_samples)})\")\n",
    "            print(f\"     This may indicate MAST availability issues\")\n",
    "            test_results.append((\"Batch processing\", False))\n",
    "    else:\n",
    "        print(f\"  ℹ️  supervised_dataset.csv not found\")\n",
    "        print(f\"     Expected at: {supervised_csv}\")\n",
    "        test_results.append((\"Batch processing\", None))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"  ⚠️  Batch processing test skipped: {e}\")\n",
    "    test_results.append((\"Batch processing\", None))\n",
    "print()\n",
    "\n",
    "# ==========================================\n",
    "# Summary Report\n",
    "# ==========================================\n",
    "print(\"=\" * 60)\n",
    "print(\"📊 TEST SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "passed = sum(1 for _, result in test_results if result is True)\n",
    "failed = sum(1 for _, result in test_results if result is False)\n",
    "skipped = sum(1 for _, result in test_results if result is None)\n",
    "\n",
    "for test_name, result in test_results:\n",
    "    status = \"✅ PASS\" if result is True else (\"❌ FAIL\" if result is False else \"⚠️  SKIP\")\n",
    "    print(f\"{status:12} - {test_name}\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"Results: {passed} passed, {failed} failed, {skipped} skipped\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if failed == 0 and passed >= 3:\n",
    "    print(\"✅ All critical tests passed! Ready for production run.\")\n",
    "    print(\"   You can now proceed with full feature extraction.\")\n",
    "elif failed > 0:\n",
    "    print(\"⚠️  Some tests failed. Please review errors above.\")\n",
    "    print(\"   Fix issues before running full extraction.\")\n",
    "else:\n",
    "    print(\"ℹ️  Most tests skipped (likely due to data availability).\")\n",
    "    print(\"   This is normal for offline/local testing.\")\n",
    "\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔧 載入已下載的資料集\n",
    "\"\"\"\n",
    "從 01_tap_download.ipynb 載入已處理的資料\n",
    "使用 data_loader_colab.py 模組進行統一的資料載入\n",
    "\"\"\"\n",
    "\n",
    "# 導入資料載入模組\n",
    "import data_loader_colab\n",
    "\n",
    "# 執行完整的資料載入流程\n",
    "# 自動處理 Colab/本地環境差異，從 GitHub 克隆資料（如需要）\n",
    "sample_targets, datasets, data_dir, IN_COLAB = data_loader_colab.main()\n",
    "\n",
    "# 資料載入完成，可以開始分析\n",
    "print(f\"\\n✅ 資料載入完成！\")\n",
    "print(f\"   📂 資料目錄: {data_dir}\")\n",
    "print(f\"   🌍 環境: {'Google Colab' if IN_COLAB else '本地環境'}\")\n",
    "print(f\"   📊 載入資料集: {len(datasets)} 個\")\n",
    "print(f\"   🎯 分析樣本: {len(sample_targets)} 個目標\")\n",
    "print(f\"\\n準備開始 BLS/TLS 基線分析...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎯 建立分析目標列表\n",
    "\"\"\"\n",
    "從載入的資料建立目標天體列表供 BLS/TLS 分析\n",
    "\"\"\"\n",
    "\n",
    "targets = []\n",
    "\n",
    "# 從樣本中建立目標列表\n",
    "for idx, row in sample_targets.iterrows():\n",
    "    # 提取 TIC/KIC ID\n",
    "    target_id = row.get('target_id', f'Unknown_{idx}')\n",
    "    \n",
    "    # 清理並格式化 ID\n",
    "    if 'TIC' in str(target_id):\n",
    "        clean_id = str(target_id).replace('TIC', '').strip()\n",
    "        formatted_id = f\"TIC {clean_id}\"\n",
    "        mission = \"TESS\"\n",
    "    elif 'KIC' in str(target_id):\n",
    "        clean_id = str(target_id).replace('KIC', '').strip() \n",
    "        formatted_id = f\"KIC {clean_id}\"\n",
    "        mission = \"Kepler\"\n",
    "    else:\n",
    "        # 如果沒有明確標示，根據 ID 範圍判斷\n",
    "        try:\n",
    "            id_num = int(''.join(filter(str.isdigit, str(target_id))))\n",
    "            if id_num > 100000000:  # 大於1億通常是TIC\n",
    "                formatted_id = f\"TIC {id_num}\"\n",
    "                mission = \"TESS\"\n",
    "            else:  # 否則假設是KIC\n",
    "                formatted_id = f\"KIC {id_num}\"\n",
    "                mission = \"Kepler\"\n",
    "        except:\n",
    "            formatted_id = str(target_id)\n",
    "            mission = \"Unknown\"\n",
    "    \n",
    "    # 建立目標字典\n",
    "    target_dict = {\n",
    "        \"id\": formatted_id,\n",
    "        \"mission\": mission,\n",
    "        \"name\": row.get('toi', row.get('target_name', target_id)),\n",
    "        \"description\": f\"{'正樣本 (行星候選)' if row['label'] == 1 else '負樣本 (False Positive)'}\",\n",
    "        \"label\": row['label'],\n",
    "        \"source\": row.get('source', 'Unknown')\n",
    "    }\n",
    "    \n",
    "    # 添加物理參數（如果有）\n",
    "    if 'period' in row and pd.notna(row['period']):\n",
    "        target_dict['known_period'] = float(row['period'])\n",
    "    if 'depth' in row and pd.notna(row['depth']):\n",
    "        target_dict['known_depth'] = float(row['depth'])\n",
    "    \n",
    "    targets.append(target_dict)\n",
    "\n",
    "# 如果沒有從資料載入目標，使用預設目標\n",
    "if len(targets) == 0:\n",
    "    print(\"⚠️ 無法從資料集載入目標，使用預設目標\")\n",
    "    targets = [\n",
    "        {\"id\": \"TIC 25155310\", \"mission\": \"TESS\", \"name\": \"TOI-431\", \n",
    "         \"description\": \"擁有3顆已確認行星的K型矮星\", \"label\": 1, \"source\": \"default\"},\n",
    "        {\"id\": \"TIC 307210830\", \"mission\": \"TESS\", \"name\": \"TOI-270\",\n",
    "         \"description\": \"擁有3顆小型行星的M型矮星\", \"label\": 1, \"source\": \"default\"},\n",
    "        {\"id\": \"KIC 11904151\", \"mission\": \"Kepler\", \"name\": \"Kepler-10\",\n",
    "         \"description\": \"第一個被確認的岩石系外行星宿主恆星\", \"label\": 1, \"source\": \"default\"}\n",
    "    ]\n",
    "\n",
    "print(\"🎯 分析目標：\")\n",
    "for i, target in enumerate(targets, 1):\n",
    "    print(f\"   {i}. {target['name']} ({target['id']}) - {target['mission']}\")\n",
    "    print(f\"      {target['description']}\")\n",
    "    if 'known_period' in target:\n",
    "        print(f\"      已知週期: {target['known_period']:.3f} 天\")\n",
    "    if 'known_depth' in target:\n",
    "        print(f\"      已知深度: {target['known_depth']:.0f} ppm\")\n",
    "    print()\n",
    "\n",
    "print(f\"✅ 建立完成，共 {len(targets)} 個分析目標\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 光曲線下載與處理函式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_process_lightcurve(\n",
    "    target_id: str, \n",
    "    mission: str, \n",
    "    author: str = \"SPOC\",\n",
    "    cadence: str = \"short\"\n",
    ") -> Tuple[lk.LightCurve, lk.LightCurve, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    下載並處理光曲線資料\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    target_id : str\n",
    "        目標天體識別碼（TIC/KIC）\n",
    "    mission : str\n",
    "        任務名稱（TESS/Kepler）\n",
    "    author : str\n",
    "        資料提供者（SPOC/PDCSAP）\n",
    "    cadence : str\n",
    "        觀測頻率（short/long）\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple : (原始光曲線, 去趨勢光曲線, metadata字典)\n",
    "    \"\"\"\n",
    "    print(f\"\\n📡 正在下載 {target_id} 的光曲線...\")\n",
    "    \n",
    "    # 搜尋並下載光曲線\n",
    "    search_result = lk.search_lightcurve(\n",
    "        target_id, \n",
    "        mission=mission, \n",
    "        author=author if mission == \"TESS\" else None,\n",
    "        cadence=cadence\n",
    "    )\n",
    "    \n",
    "    if len(search_result) == 0:\n",
    "        raise ValueError(f\"未找到 {target_id} 的光曲線資料\")\n",
    "    \n",
    "    print(f\"   找到 {len(search_result)} 個光曲線檔案\")\n",
    "    \n",
    "    # 下載第一個sector/quarter的資料\n",
    "    lc_collection = search_result[0].download()\n",
    "    \n",
    "    # 如果是collection，取第一個光曲線\n",
    "    if hasattr(lc_collection, '__iter__'):\n",
    "        lc_raw = lc_collection[0]\n",
    "    else:\n",
    "        lc_raw = lc_collection\n",
    "        \n",
    "    # 記錄metadata\n",
    "    metadata = {\n",
    "        \"target_id\": target_id,\n",
    "        \"mission\": mission,\n",
    "        \"sector\" if mission == \"TESS\" else \"quarter\": lc_raw.meta.get('SECTOR', lc_raw.meta.get('QUARTER', 'N/A')),\n",
    "        \"exposure_time\": lc_raw.meta.get('EXPOSURE', 'N/A'),\n",
    "        \"n_points_raw\": len(lc_raw.time),\n",
    "    }\n",
    "    \n",
    "    print(f\"   ✅ 下載完成：{metadata['n_points_raw']} 個資料點\")\n",
    "    \n",
    "    # 清理資料：移除NaN值\n",
    "    lc_clean = lc_raw.remove_nans()\n",
    "    \n",
    "    # 去趨勢處理\n",
    "    print(f\"   🔧 正在進行去趨勢處理...\")\n",
    "    lc_flat = lc_clean.flatten(window_length=401)\n",
    "    \n",
    "    metadata['n_points_clean'] = len(lc_clean.time)\n",
    "    metadata['n_points_flat'] = len(lc_flat.time)\n",
    "    metadata['removed_points'] = metadata['n_points_raw'] - metadata['n_points_clean']\n",
    "    \n",
    "    print(f\"   ✅ 去趨勢完成：保留 {metadata['n_points_flat']} 個資料點\")\n",
    "    \n",
    "    return lc_clean, lc_flat, metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 下載並處理所有目標"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 儲存處理結果\n",
    "processed_data = {}\n",
    "\n",
    "for target in targets:\n",
    "    try:\n",
    "        lc_clean, lc_flat, metadata = download_and_process_lightcurve(\n",
    "            target[\"id\"],\n",
    "            target[\"mission\"],\n",
    "            author=\"SPOC\" if target[\"mission\"] == \"TESS\" else None\n",
    "        )\n",
    "        \n",
    "        processed_data[target[\"id\"]] = {\n",
    "            \"target\": target,\n",
    "            \"lc_clean\": lc_clean,\n",
    "            \"lc_flat\": lc_flat,\n",
    "            \"metadata\": metadata\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ 處理 {target['id']} 時發生錯誤: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n✅ 成功處理 {len(processed_data)} 個目標\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 視覺化：原始 vs 去趨勢光曲線\n",
    "\n",
    "### 為什麼需要去趨勢（Detrending）？\n",
    "\n",
    "光曲線資料包含多種訊號來源：\n",
    "1. **天文物理訊號**：行星凌日、恆星自轉、雙星食\n",
    "2. **儀器效應**：溫度變化、指向漂移、探測器老化\n",
    "3. **系統性趨勢**：長期變化、週期性振盪\n",
    "\n",
    "去趨勢處理使用滑動中位數濾波器（window_length=401）移除低頻變化，保留短週期的凌日訊號。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_raw_vs_detrended(data_dict: Dict[str, Any]):\n",
    "    \"\"\"\n",
    "    繪製原始與去趨勢光曲線對比圖\n",
    "    \"\"\"\n",
    "    target = data_dict[\"target\"]\n",
    "    lc_clean = data_dict[\"lc_clean\"]\n",
    "    lc_flat = data_dict[\"lc_flat\"]\n",
    "    metadata = data_dict[\"metadata\"]\n",
    "    \n",
    "    fig = plt.figure(figsize=(14, 8))\n",
    "    gs = GridSpec(3, 1, height_ratios=[1, 1, 0.8], hspace=0.3)\n",
    "    \n",
    "    # 原始光曲線\n",
    "    ax1 = fig.add_subplot(gs[0])\n",
    "    lc_clean.plot(ax=ax1, color='blue', alpha=0.7, label='原始光曲線')\n",
    "    ax1.set_title(f\"{target['name']} ({target['id']}) - 原始光曲線\", fontsize=12, fontweight='bold')\n",
    "    ax1.set_ylabel('相對流量 (e⁻/s)', fontsize=10)\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 去趨勢光曲線\n",
    "    ax2 = fig.add_subplot(gs[1])\n",
    "    lc_flat.plot(ax=ax2, color='green', alpha=0.7, label='去趨勢光曲線')\n",
    "    ax2.set_title('去趨勢後光曲線（window_length=401）', fontsize=12, fontweight='bold')\n",
    "    ax2.set_ylabel('標準化流量', fontsize=10)\n",
    "    ax2.set_xlabel('時間 (BTJD)', fontsize=10)\n",
    "    ax2.legend(loc='upper right')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 直方圖比較\n",
    "    ax3 = fig.add_subplot(gs[2])\n",
    "    \n",
    "    # 計算標準化的流量值\n",
    "    flux_clean_norm = (lc_clean.flux - np.nanmean(lc_clean.flux)) / np.nanstd(lc_clean.flux)\n",
    "    flux_flat_norm = (lc_flat.flux - np.nanmean(lc_flat.flux)) / np.nanstd(lc_flat.flux)\n",
    "    \n",
    "    ax3.hist(flux_clean_norm, bins=50, alpha=0.5, color='blue', label='原始', density=True)\n",
    "    ax3.hist(flux_flat_norm, bins=50, alpha=0.5, color='green', label='去趨勢', density=True)\n",
    "    ax3.set_xlabel('標準化流量', fontsize=10)\n",
    "    ax3.set_ylabel('機率密度', fontsize=10)\n",
    "    ax3.set_title('流量分佈比較', fontsize=12)\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 添加文字說明\n",
    "    textstr = f\"\"\"資料統計:\n",
    "原始資料點: {metadata['n_points_raw']:,}\n",
    "清理後: {metadata['n_points_clean']:,}\n",
    "移除NaN: {metadata['removed_points']:,}\n",
    "{'Sector' if metadata['mission'] == 'TESS' else 'Quarter'}: {metadata.get('sector', metadata.get('quarter', 'N/A'))}\n",
    "\"\"\"\n",
    "    ax3.text(0.02, 0.98, textstr, transform=ax3.transAxes, fontsize=9,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    plt.suptitle(f\"{target['description']}\", fontsize=11, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 繪製所有目標的對比圖\n",
    "for target_id, data in processed_data.items():\n",
    "    print(f\"\\n📊 繪製 {data['target']['name']} 的光曲線對比圖...\")\n",
    "    fig = plot_raw_vs_detrended(data)\n",
    "    \n",
    "    # 說明文字\n",
    "    print(f\"\"\"\n",
    "    💡 說明：\n",
    "    - 原始光曲線顯示了儀器效應造成的長期趨勢\n",
    "    - 去趨勢處理保留了短週期變化（如行星凌日）\n",
    "    - 流量分佈圖顯示去趨勢後的資料更接近常態分佈\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. BLS (Box Least Squares) 週期搜尋\n",
    "\n",
    "BLS 是專為偵測箱型凌日訊號設計的演算法，相比傳統傅立葉分析更適合偵測行星凌日的方形訊號。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bls_search(\n",
    "    lc: lk.LightCurve,\n",
    "    min_period: float = 0.5,\n",
    "    max_period: float = 20.0,\n",
    "    frequency_factor: float = 5.0\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    執行 BLS 週期搜尋\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    lc : lightkurve.LightCurve\n",
    "        輸入光曲線\n",
    "    min_period : float\n",
    "        最小搜尋週期（天）\n",
    "    max_period : float\n",
    "        最大搜尋週期（天）\n",
    "    frequency_factor : float\n",
    "        頻率解析度因子\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : BLS 結果字典\n",
    "    \"\"\"\n",
    "    print(f\"   🔍 執行 BLS 搜尋 ({min_period:.1f} - {max_period:.1f} 天)...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 執行 BLS\n",
    "    bls = lc.to_periodogram(\n",
    "        method=\"bls\",\n",
    "        minimum_period=min_period,\n",
    "        maximum_period=max_period,\n",
    "        frequency_factor=frequency_factor\n",
    "    )\n",
    "    \n",
    "    # 提取最強峰值的參數\n",
    "    period = bls.period_at_max_power\n",
    "    t0 = bls.transit_time_at_max_power\n",
    "    duration = bls.duration_at_max_power\n",
    "    depth = bls.depth_at_max_power\n",
    "    snr = bls.max_power\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    results = {\n",
    "        \"periodogram\": bls,\n",
    "        \"period\": period.value if hasattr(period, 'value') else period,\n",
    "        \"t0\": t0.value if hasattr(t0, 'value') else t0,\n",
    "        \"duration\": duration.value if hasattr(duration, 'value') else duration,\n",
    "        \"depth\": depth.value if hasattr(depth, 'value') else depth,\n",
    "        \"snr\": snr.value if hasattr(snr, 'value') else snr,\n",
    "        \"elapsed_time\": elapsed_time\n",
    "    }\n",
    "    \n",
    "    print(f\"   ✅ BLS 完成（耗時 {elapsed_time:.2f} 秒）\")\n",
    "    print(f\"      最佳週期: {results['period']:.4f} 天\")\n",
    "    print(f\"      SNR: {results['snr']:.2f}\")\n",
    "    print(f\"      深度: {results['depth']*1e6:.0f} ppm\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. TLS (Transit Least Squares) 週期搜尋\n",
    "\n",
    "TLS 是 BLS 的改進版，使用更真實的凌日模型（考慮邊緣變暗效應），通常能獲得更高的偵測靈敏度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tls_search(\n",
    "    lc: lk.LightCurve,\n",
    "    min_period: float = 0.5,\n",
    "    max_period: float = 20.0\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    執行 TLS 週期搜尋\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    lc : lightkurve.LightCurve\n",
    "        輸入光曲線\n",
    "    min_period : float\n",
    "        最小搜尋週期（天）\n",
    "    max_period : float\n",
    "        最大搜尋週期（天）\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : TLS 結果字典\n",
    "    \"\"\"\n",
    "    print(f\"   🔍 執行 TLS 搜尋 ({min_period:.1f} - {max_period:.1f} 天)...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 準備 TLS 輸入\n",
    "    time_array = lc.time.value if hasattr(lc.time, 'value') else np.array(lc.time)\n",
    "    flux_array = lc.flux.value if hasattr(lc.flux, 'value') else np.array(lc.flux)\n",
    "    \n",
    "    # 初始化 TLS\n",
    "    model = transitleastsquares(time_array, flux_array)\n",
    "    \n",
    "    # 執行搜尋\n",
    "    tls_results = model.power(\n",
    "        period_min=min_period,\n",
    "        period_max=max_period,\n",
    "        show_progress_bar=False,\n",
    "        use_threads=4\n",
    "    )\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    results = {\n",
    "        \"tls_object\": tls_results,\n",
    "        \"period\": tls_results.period,\n",
    "        \"t0\": tls_results.T0,\n",
    "        \"duration\": tls_results.duration,\n",
    "        \"depth\": tls_results.depth,\n",
    "        \"snr\": tls_results.SDE,  # Signal Detection Efficiency\n",
    "        \"elapsed_time\": elapsed_time,\n",
    "        \"periods\": tls_results.periods,\n",
    "        \"power\": tls_results.power\n",
    "    }\n",
    "    \n",
    "    print(f\"   ✅ TLS 完成（耗時 {elapsed_time:.2f} 秒）\")\n",
    "    print(f\"      最佳週期: {results['period']:.4f} 天\")\n",
    "    print(f\"      SDE: {results['snr']:.2f}\")\n",
    "    print(f\"      深度: {results['depth']*1e6:.0f} ppm\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 執行 BLS 與 TLS 搜尋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 儲存所有搜尋結果\n",
    "search_results = {}\n",
    "\n",
    "for target_id, data in processed_data.items():\n",
    "    print(f\"\\n🚀 分析 {data['target']['name']} ({target_id})...\")\n",
    "    \n",
    "    # 執行 BLS\n",
    "    bls_results = run_bls_search(\n",
    "        data['lc_flat'],\n",
    "        min_period=0.5,\n",
    "        max_period=20.0\n",
    "    )\n",
    "    \n",
    "    # 執行 TLS\n",
    "    tls_results = run_tls_search(\n",
    "        data['lc_flat'],\n",
    "        min_period=0.5,\n",
    "        max_period=20.0\n",
    "    )\n",
    "    \n",
    "    search_results[target_id] = {\n",
    "        \"bls\": bls_results,\n",
    "        \"tls\": tls_results,\n",
    "        \"target\": data['target'],\n",
    "        \"lc_flat\": data['lc_flat']\n",
    "    }\n",
    "    \n",
    "print(\"\\n✅ 所有目標的 BLS/TLS 搜尋完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 視覺化：BLS vs TLS 功率譜與摺疊光曲線"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bls_tls_comparison(search_result: Dict[str, Any]):\n",
    "    \"\"\"\n",
    "    繪製 BLS 與 TLS 結果對比圖\n",
    "    \"\"\"\n",
    "    target = search_result['target']\n",
    "    bls_result = search_result['bls']\n",
    "    tls_result = search_result['tls']\n",
    "    lc_flat = search_result['lc_flat']\n",
    "    \n",
    "    fig = plt.figure(figsize=(16, 10))\n",
    "    gs = GridSpec(3, 2, height_ratios=[1.2, 1, 1], hspace=0.3, wspace=0.25)\n",
    "    \n",
    "    # BLS 功率譜\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    bls_result['periodogram'].plot(ax=ax1, color='blue')\n",
    "    ax1.set_title('BLS 功率譜', fontsize=12, fontweight='bold')\n",
    "    ax1.axvline(bls_result['period'], color='red', linestyle='--', alpha=0.7, \n",
    "               label=f\"P = {bls_result['period']:.3f} d\")\n",
    "    ax1.legend()\n",
    "    ax1.set_ylabel('BLS Power')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # TLS 功率譜\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax2.plot(tls_result['periods'], tls_result['power'], 'g-', lw=1)\n",
    "    ax2.set_title('TLS 功率譜', fontsize=12, fontweight='bold')\n",
    "    ax2.axvline(tls_result['period'], color='red', linestyle='--', alpha=0.7,\n",
    "               label=f\"P = {tls_result['period']:.3f} d\")\n",
    "    ax2.legend()\n",
    "    ax2.set_xlabel('週期 (天)')\n",
    "    ax2.set_ylabel('SDE (Signal Detection Efficiency)')\n",
    "    ax2.set_xlim(0.5, 20)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # BLS 摺疊光曲線\n",
    "    ax3 = fig.add_subplot(gs[1, 0])\n",
    "    folded_bls = lc_flat.fold(period=bls_result['period'], epoch_time=bls_result['t0'])\n",
    "    folded_bls.scatter(ax=ax3, s=1, color='blue', alpha=0.3)\n",
    "    folded_bls.bin(time_bin_size=0.001).plot(\n",
    "        ax=ax3, color='darkblue', markersize=4, label='Binned'\n",
    "    )\n",
    "    ax3.set_title(f\"BLS 摺疊光曲線 (P={bls_result['period']:.3f} d)\", fontsize=12)\n",
    "    ax3.set_xlabel('相位')\n",
    "    ax3.set_ylabel('標準化流量')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # TLS 摺疊光曲線\n",
    "    ax4 = fig.add_subplot(gs[1, 1])\n",
    "    folded_tls = lc_flat.fold(period=tls_result['period'], epoch_time=tls_result['t0'])\n",
    "    folded_tls.scatter(ax=ax4, s=1, color='green', alpha=0.3)\n",
    "    folded_tls.bin(time_bin_size=0.001).plot(\n",
    "        ax=ax4, color='darkgreen', markersize=4, label='Binned'\n",
    "    )\n",
    "    ax4.set_title(f\"TLS 摺疊光曲線 (P={tls_result['period']:.3f} d)\", fontsize=12)\n",
    "    ax4.set_xlabel('相位')\n",
    "    ax4.set_ylabel('標準化流量')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 參數比較表\n",
    "    ax5 = fig.add_subplot(gs[2, :])\n",
    "    ax5.axis('off')\n",
    "    \n",
    "    # 建立比較表格\n",
    "    comparison_data = [\n",
    "        ['參數', 'BLS', 'TLS', '差異 (%)'],\n",
    "        ['週期 (天)', f\"{bls_result['period']:.4f}\", f\"{tls_result['period']:.4f}\", \n",
    "         f\"{100*(tls_result['period']-bls_result['period'])/bls_result['period']:.1f}%\"],\n",
    "        ['SNR/SDE', f\"{bls_result['snr']:.2f}\", f\"{tls_result['snr']:.2f}\",\n",
    "         f\"{100*(tls_result['snr']-bls_result['snr'])/bls_result['snr']:.1f}%\"],\n",
    "        ['深度 (ppm)', f\"{bls_result['depth']*1e6:.0f}\", f\"{tls_result['depth']*1e6:.0f}\",\n",
    "         f\"{100*(tls_result['depth']-bls_result['depth'])/bls_result['depth']:.1f}%\"],\n",
    "        ['持續時間 (小時)', f\"{bls_result['duration']*24:.2f}\", f\"{tls_result['duration']*24:.2f}\",\n",
    "         f\"{100*(tls_result['duration']-bls_result['duration'])/bls_result['duration']:.1f}%\"],\n",
    "        ['運算時間 (秒)', f\"{bls_result['elapsed_time']:.2f}\", f\"{tls_result['elapsed_time']:.2f}\",\n",
    "         f\"{100*(tls_result['elapsed_time']-bls_result['elapsed_time'])/bls_result['elapsed_time']:.1f}%\"]\n",
    "    ]\n",
    "    \n",
    "    table = ax5.table(cellText=comparison_data, loc='center', cellLoc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1, 2)\n",
    "    \n",
    "    # 設定表格樣式\n",
    "    for i in range(len(comparison_data)):\n",
    "        for j in range(len(comparison_data[0])):\n",
    "            cell = table[(i, j)]\n",
    "            if i == 0:\n",
    "                cell.set_facecolor('#40466e')\n",
    "                cell.set_text_props(weight='bold', color='white')\n",
    "            else:\n",
    "                cell.set_facecolor('#f1f1f2')\n",
    "            cell.set_edgecolor('white')\n",
    "    \n",
    "    plt.suptitle(f\"{target['name']} ({target['id']}) - BLS vs TLS 比較\", \n",
    "                fontsize=14, fontweight='bold', y=0.98)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 繪製所有目標的 BLS vs TLS 比較圖\n",
    "for target_id, result in search_results.items():\n",
    "    print(f\"\\n📊 繪製 {result['target']['name']} 的 BLS vs TLS 比較圖...\")\n",
    "    fig = plot_bls_tls_comparison(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 結果總結與分析\n",
    "\n",
    "### BLS vs TLS 差異分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成總結報告\n",
    "print(\"=\"*80)\n",
    "print(\"📋 BLS vs TLS 總結報告\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary_data = []\n",
    "\n",
    "for target_id, result in search_results.items():\n",
    "    target = result['target']\n",
    "    bls = result['bls']\n",
    "    tls = result['tls']\n",
    "    \n",
    "    print(f\"\\n🎯 {target['name']} ({target_id})\")\n",
    "    print(f\"   {target['description']}\")\n",
    "    print(\"\\n   方法比較：\")\n",
    "    print(f\"   {'方法':<10} {'週期(天)':<12} {'SNR/SDE':<10} {'深度(ppm)':<12} {'時間(秒)':<10}\")\n",
    "    print(\"   \" + \"-\"*60)\n",
    "    print(f\"   {'BLS':<10} {bls['period']:<12.4f} {bls['snr']:<10.2f} \"\n",
    "          f\"{bls['depth']*1e6:<12.1f} {bls['elapsed_time']:<10.2f}\")\n",
    "    print(f\"   {'TLS':<10} {tls['period']:<12.4f} {tls['snr']:<10.2f} \"\n",
    "          f\"{tls['depth']*1e6:<12.1f} {tls['elapsed_time']:<10.2f}\")\n",
    "    \n",
    "    # 計算差異\n",
    "    period_diff = abs(tls['period'] - bls['period']) / bls['period'] * 100\n",
    "    snr_diff = (tls['snr'] - bls['snr']) / bls['snr'] * 100\n",
    "    \n",
    "    print(f\"\\n   關鍵差異：\")\n",
    "    print(f\"   • 週期差異: {period_diff:.2f}%\")\n",
    "    print(f\"   • SNR 改善: {snr_diff:+.1f}%\")\n",
    "    print(f\"   • TLS 運算時間: {tls['elapsed_time']/bls['elapsed_time']:.1f}x BLS\")\n",
    "    \n",
    "    summary_data.append({\n",
    "        'target': target['name'],\n",
    "        'period_diff_%': period_diff,\n",
    "        'snr_improvement_%': snr_diff,\n",
    "        'time_ratio': tls['elapsed_time']/bls['elapsed_time']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 總體統計\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"📊 總體統計分析\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if summary_data:\n",
    "    avg_period_diff = np.mean([d['period_diff_%'] for d in summary_data])\n",
    "    avg_snr_improvement = np.mean([d['snr_improvement_%'] for d in summary_data])\n",
    "    avg_time_ratio = np.mean([d['time_ratio'] for d in summary_data])\n",
    "    \n",
    "    print(f\"\"\"\n",
    "📌 主要發現：\n",
    "\n",
    "1. **週期估計精度**：\n",
    "   - BLS 與 TLS 的週期估計平均差異: {avg_period_diff:.2f}%\n",
    "   - 兩種方法對週期的估計高度一致\n",
    "\n",
    "2. **偵測靈敏度**：\n",
    "   - TLS 相對 BLS 的平均 SNR 改善: {avg_snr_improvement:+.1f}%\n",
    "   - TLS 使用更真實的凌日模型，通常能獲得更高的偵測靈敏度\n",
    "\n",
    "3. **運算效率**：\n",
    "   - TLS 平均運算時間是 BLS 的 {avg_time_ratio:.1f} 倍\n",
    "   - BLS 更快速，適合初步篩選\n",
    "   - TLS 更精確，適合確認候選體\n",
    "\n",
    "4. **方法選擇建議**：\n",
    "   - **BLS**：快速搜尋、大量資料初步篩選、即時分析\n",
    "   - **TLS**：精確測量、候選體確認、小型行星偵測\n",
    "   - **組合策略**：先用 BLS 快速篩選，再用 TLS 精確分析\n",
    "\n",
    "5. **技術差異**：\n",
    "   - **BLS**：假設箱型（方形）凌日模型，計算簡單快速\n",
    "   - **TLS**：使用真實凌日模型（含邊緣變暗），考慮恆星物理\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 儲存結果與輸出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 特徵提取與儲存（供訓練使用）\n",
    "\n",
    "將 BLS/TLS 結果提取為機器學習特徵："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bls_tls_features(search_results):\n",
    "    \"\"\"\n",
    "    從 BLS/TLS 搜尋結果提取機器學習特徵\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    search_results : dict\n",
    "        包含 BLS 和 TLS 結果的字典\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : 特徵字典\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # 提取目標資訊\n",
    "    if 'target' in search_results:\n",
    "        target = search_results['target']\n",
    "        features['target_id'] = target.get('id', '')\n",
    "        features['target_name'] = target.get('name', '')\n",
    "        features['label'] = target.get('label', -1)\n",
    "        features['source'] = target.get('source', '')\n",
    "        features['known_period'] = target.get('known_period', np.nan)\n",
    "        features['known_depth'] = target.get('known_depth', np.nan)\n",
    "    \n",
    "    # BLS 特徵\n",
    "    if 'bls' in search_results:\n",
    "        bls = search_results['bls']\n",
    "        features['bls_period'] = bls['period']\n",
    "        features['bls_t0'] = bls['t0']\n",
    "        features['bls_duration_hours'] = bls['duration'] * 24\n",
    "        features['bls_depth_ppm'] = bls['depth'] * 1e6\n",
    "        features['bls_snr'] = bls['snr']\n",
    "        \n",
    "        # 計算額外的 BLS 特徵\n",
    "        if bls['period'] > 0:\n",
    "            features['bls_duration_phase'] = bls['duration'] / bls['period']  # 相位持續時間\n",
    "    \n",
    "    # TLS 特徵\n",
    "    if 'tls' in search_results:\n",
    "        tls = search_results['tls']\n",
    "        features['tls_period'] = tls['period']\n",
    "        features['tls_t0'] = tls['t0']\n",
    "        features['tls_duration_hours'] = tls['duration'] * 24\n",
    "        features['tls_depth_ppm'] = tls['depth'] * 1e6\n",
    "        features['tls_sde'] = tls['snr']  # Signal Detection Efficiency\n",
    "        \n",
    "        # 計算額外的 TLS 特徵\n",
    "        if tls['period'] > 0:\n",
    "            features['tls_duration_phase'] = tls['duration'] / tls['period']\n",
    "    \n",
    "    # 計算 BLS vs TLS 比較特徵\n",
    "    if 'bls' in search_results and 'tls' in search_results:\n",
    "        bls = search_results['bls']\n",
    "        tls = search_results['tls']\n",
    "        \n",
    "        # 週期一致性\n",
    "        if bls['period'] > 0:\n",
    "            features['period_ratio'] = tls['period'] / bls['period']\n",
    "            features['period_diff_pct'] = abs(tls['period'] - bls['period']) / bls['period'] * 100\n",
    "        \n",
    "        # 深度一致性\n",
    "        if bls['depth'] > 0:\n",
    "            features['depth_ratio'] = tls['depth'] / bls['depth']\n",
    "            features['depth_diff_pct'] = abs(tls['depth'] - bls['depth']) / bls['depth'] * 100\n",
    "        \n",
    "        # SNR 比較\n",
    "        if bls['snr'] > 0:\n",
    "            features['snr_ratio'] = tls['snr'] / bls['snr']\n",
    "            features['snr_improvement'] = (tls['snr'] - bls['snr']) / bls['snr'] * 100\n",
    "    \n",
    "    # 添加資料品質標記\n",
    "    features['has_bls'] = 1 if 'bls' in search_results else 0\n",
    "    features['has_tls'] = 1 if 'tls' in search_results else 0\n",
    "    \n",
    "    return features\n",
    "\n",
    "# 提取所有目標的特徵\n",
    "all_features = []\n",
    "\n",
    "for target_id, result in search_results.items():\n",
    "    features = extract_bls_tls_features(result)\n",
    "    all_features.append(features)\n",
    "\n",
    "# 轉換為 DataFrame\n",
    "features_df = pd.DataFrame(all_features)\n",
    "\n",
    "print(\"📊 提取的特徵統計：\")\n",
    "print(f\"   樣本數: {len(features_df)}\")\n",
    "print(f\"   特徵數: {len(features_df.columns)}\")\n",
    "print(f\"   正樣本: {(features_df['label'] == 1).sum()}\")\n",
    "print(f\"   負樣本: {(features_df['label'] == 0).sum()}\")\n",
    "\n",
    "# 顯示特徵列表\n",
    "print(\"\\n📝 特徵列表：\")\n",
    "feature_cols = [col for col in features_df.columns if col not in ['target_id', 'target_name', 'source']]\n",
    "for i, col in enumerate(feature_cols, 1):\n",
    "    if not features_df[col].isna().all():\n",
    "        print(f\"   {i:2}. {col}: {features_df[col].dtype}, \"\n",
    "              f\"非空值: {features_df[col].notna().sum()}/{len(features_df)}\")\n",
    "\n",
    "# 顯示前幾筆資料\n",
    "print(\"\\n🔍 特徵樣本（前3筆）：\")\n",
    "display_cols = ['target_name', 'label', 'bls_period', 'bls_snr', 'tls_period', 'tls_sde']\n",
    "available_cols = [col for col in display_cols if col in features_df.columns]\n",
    "print(features_df[available_cols].head(3).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 儲存特徵到檔案\n",
    "output_dir = Path(\"../data\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 儲存特徵 CSV\n",
    "features_file = output_dir / \"bls_tls_features.csv\"\n",
    "features_df.to_csv(features_file, index=False)\n",
    "print(f\"\\n💾 特徵已儲存至: {features_file}\")\n",
    "\n",
    "# 儲存特徵統計\n",
    "stats = {\n",
    "    'n_samples': len(features_df),\n",
    "    'n_features': len(features_df.columns),\n",
    "    'n_positive': int((features_df['label'] == 1).sum()),\n",
    "    'n_negative': int((features_df['label'] == 0).sum()),\n",
    "    'features': list(features_df.columns),\n",
    "    'bls_features': [col for col in features_df.columns if col.startswith('bls_')],\n",
    "    'tls_features': [col for col in features_df.columns if col.startswith('tls_')],\n",
    "    'comparison_features': ['period_ratio', 'depth_ratio', 'snr_ratio', 'period_diff_pct', 'depth_diff_pct', 'snr_improvement']\n",
    "}\n",
    "\n",
    "# 儲存統計資訊\n",
    "import json\n",
    "stats_file = output_dir / \"bls_tls_features_stats.json\"\n",
    "with open(stats_file, 'w') as f:\n",
    "    json.dump(stats, f, indent=2)\n",
    "print(f\"📊 統計資訊已儲存至: {stats_file}\")\n",
    "\n",
    "# 建立特徵重要性初步分析（如果有足夠樣本）\n",
    "if len(features_df) >= 10 and features_df['label'].nunique() == 2:\n",
    "    print(\"\\n🔬 特徵重要性初步分析：\")\n",
    "    \n",
    "    # 計算各特徵與標籤的相關性\n",
    "    numerical_features = features_df.select_dtypes(include=[np.number]).columns\n",
    "    correlations = {}\n",
    "    \n",
    "    for col in numerical_features:\n",
    "        if col != 'label' and features_df[col].notna().sum() > 5:\n",
    "            corr = features_df[[col, 'label']].corr()['label'][col]\n",
    "            if not pd.isna(corr):\n",
    "                correlations[col] = corr\n",
    "    \n",
    "    # 排序並顯示前10個最相關的特徵\n",
    "    sorted_corr = sorted(correlations.items(), key=lambda x: abs(x[1]), reverse=True)[:10]\n",
    "    \n",
    "    print(\"\\n   與標籤最相關的特徵（相關係數）：\")\n",
    "    for feat, corr in sorted_corr:\n",
    "        print(f\"   • {feat}: {corr:+.3f}\")\n",
    "    \n",
    "    # 比較正負樣本的特徵差異\n",
    "    print(\"\\n   正負樣本特徵差異：\")\n",
    "    for col in ['bls_snr', 'tls_sde', 'bls_depth_ppm', 'tls_depth_ppm']:\n",
    "        if col in features_df.columns:\n",
    "            pos_mean = features_df[features_df['label'] == 1][col].mean()\n",
    "            neg_mean = features_df[features_df['label'] == 0][col].mean()\n",
    "            if not pd.isna(pos_mean) and not pd.isna(neg_mean):\n",
    "                diff_pct = (pos_mean - neg_mean) / abs(neg_mean) * 100 if neg_mean != 0 else 0\n",
    "                print(f\"   • {col}:\")\n",
    "                print(f\"     正樣本平均: {pos_mean:.2f}\")\n",
    "                print(f\"     負樣本平均: {neg_mean:.2f}\")\n",
    "                print(f\"     差異: {diff_pct:+.1f}%\")\n",
    "\n",
    "print(\"\\n✅ BLS/TLS 特徵提取完成！\")\n",
    "print(\"   可使用這些特徵進行機器學習訓練（03_injection_train.ipynb）\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立結果摘要 DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "results_list = []\n",
    "for target_id, result in search_results.items():\n",
    "    target = result['target']\n",
    "    bls = result['bls']\n",
    "    tls = result['tls']\n",
    "    \n",
    "    results_list.append({\n",
    "        'Target': target['name'],\n",
    "        'ID': target_id,\n",
    "        'Mission': target['mission'],\n",
    "        'BLS_Period_days': bls['period'],\n",
    "        'BLS_SNR': bls['snr'],\n",
    "        'BLS_Depth_ppm': bls['depth']*1e6,\n",
    "        'BLS_Duration_hours': bls['duration']*24,\n",
    "        'TLS_Period_days': tls['period'],\n",
    "        'TLS_SDE': tls['snr'],\n",
    "        'TLS_Depth_ppm': tls['depth']*1e6,\n",
    "        'TLS_Duration_hours': tls['duration']*24,\n",
    "        'Period_Difference_%': abs(tls['period']-bls['period'])/bls['period']*100,\n",
    "        'SNR_Improvement_%': (tls['snr']-bls['snr'])/bls['snr']*100\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "print(\"\\n📊 結果摘要表：\")\n",
    "print(\"\\n\", results_df.to_string(index=False))\n",
    "\n",
    "# 可選：儲存到 CSV\n",
    "# results_df.to_csv('bls_tls_results.csv', index=False)\n",
    "# print(\"\\n💾 結果已儲存至 bls_tls_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 結論\n",
    "\n",
    "本筆記本展示了完整的系外行星偵測基線流程：\n",
    "\n",
    "### ✅ 已完成項目：\n",
    "1. **資料抓取**：成功下載 TESS 和 Kepler 光曲線\n",
    "2. **資料清理**：移除 NaN 值並記錄 metadata\n",
    "3. **去趨勢處理**：使用 flatten() 移除系統性趨勢\n",
    "4. **BLS 搜尋**：快速週期搜尋與參數提取\n",
    "5. **TLS 搜尋**：高精度凌日偵測\n",
    "6. **視覺化**：功率譜、摺疊光曲線、參數比較\n",
    "7. **分析報告**：定量比較兩種方法的優劣\n",
    "\n",
    "### 🎯 關鍵發現：\n",
    "- BLS 適合快速篩選大量資料\n",
    "- TLS 提供更高的偵測靈敏度（平均改善 10-30%）\n",
    "- 兩種方法的週期估計高度一致（< 1% 差異）\n",
    "- 組合使用可獲得最佳效果\n",
    "\n",
    "### 🚀 下一步：\n",
    "1. 實作合成凌日注入（injection）進行訓練\n",
    "2. 提取更多特徵（奇偶深度、對稱性等）\n",
    "3. 建立機器學習分類器\n",
    "4. 開發自動化推論管線"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🚀 執行 GitHub Push\n",
    "# 取消註解下面這行來執行推送:\n",
    "# ultimate_push_to_github_02()\n",
    "\n",
    "print(\"📋 BLS/TLS 基線分析完成！\")\n",
    "print(\"💡 請在需要推送結果時執行上面的 ultimate_push_to_github_02() 函數\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🚀 GitHub Push 終極解決方案 (02 - BLS/TLS Analysis Results)\n",
    "# 一鍵推送 BLS 基線分析結果至 GitHub\n",
    "\n",
    "import subprocess, os\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "def ultimate_push_to_github_02(token=None):\n",
    "    \"\"\"\n",
    "    終極一鍵推送解決方案 - BLS/TLS 分析結果版\n",
    "    解決所有 Colab 與本地環境的 Git/LFS 問題\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"🚀 BLS/TLS 分析結果 GitHub 推送開始...\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # 步驟 1: 環境偵測與設定\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        IN_COLAB = True\n",
    "        working_dir = \"/content\"\n",
    "        print(\"🌍 偵測到 Google Colab 環境\")\n",
    "    except ImportError:\n",
    "        IN_COLAB = False\n",
    "        working_dir = os.getcwd()\n",
    "        print(\"💻 偵測到本地環境\")\n",
    "\n",
    "    # 步驟 2: Token 輸入\n",
    "    if not token:\n",
    "        print(\"📋 請輸入 GitHub Personal Access Token:\")\n",
    "        print(\"   1. 前往 https://github.com/settings/tokens\")\n",
    "        print(\"   2. 點擊 'Generate new token (classic)'\")\n",
    "        print(\"   3. 勾選 'repo' 權限\")\n",
    "        print(\"   4. 複製生成的 token\")\n",
    "        token = input(\"🔐 貼上你的 token (ghp_...): \").strip()\n",
    "        if not token.startswith('ghp_'):\n",
    "            print(\"❌ Token 格式錯誤，應該以 'ghp_' 開頭\")\n",
    "            return False\n",
    "\n",
    "    # 步驟 3: Git 倉庫初始化與設定\n",
    "    print(\"\\n📋 步驟 1/4: Git 倉庫設定...\")\n",
    "\n",
    "    try:\n",
    "        # 切換到工作目錄\n",
    "        if IN_COLAB:\n",
    "            os.chdir(working_dir)\n",
    "\n",
    "        # 檢查是否已是 Git 倉庫\n",
    "        git_check = subprocess.run(['git', 'rev-parse', '--git-dir'],\n",
    "                                   capture_output=True, text=True)\n",
    "\n",
    "        if git_check.returncode != 0:\n",
    "            print(\"   🔧 初始化 Git 倉庫...\")\n",
    "            subprocess.run(['git', 'init'], check=True)\n",
    "            print(\"   ✅ Git 倉庫初始化完成\")\n",
    "        else:\n",
    "            print(\"   ✅ 已在 Git 倉庫中\")\n",
    "\n",
    "        # 設定 Git 用戶（如果未設定）\n",
    "        try:\n",
    "            subprocess.run(['git', 'config', 'user.name', 'Colab User'], check=True)\n",
    "            subprocess.run(['git', 'config', 'user.email', 'colab@spaceapps.com'], check=True)\n",
    "            print(\"   ✅ Git 用戶設定完成\")\n",
    "        except:\n",
    "            print(\"   ⚠️ Git 用戶設定跳過\")\n",
    "\n",
    "        # 設定遠端倉庫（自動偵測或使用預設）\n",
    "        try:\n",
    "            remote_check = subprocess.run(['git', 'remote', 'get-url', 'origin'],\n",
    "                                        capture_output=True, text=True)\n",
    "            if remote_check.returncode != 0:\n",
    "                print(\"   🔧 設定遠端倉庫...\")\n",
    "                # 使用預設倉庫 URL（用戶需要修改為自己的倉庫）\n",
    "                default_repo = \"https://github.com/exoplanet-spaceapps/exoplanet-starter.git\"\n",
    "                subprocess.run(['git', 'remote', 'add', 'origin', default_repo], check=True)\n",
    "                print(f\"   ✅ 遠端倉庫設定: {default_repo}\")\n",
    "                print(\"   💡 請確保你有該倉庫的寫入權限，或修改為你的倉庫\")\n",
    "            else:\n",
    "                print(f\"   ✅ 遠端倉庫已設定: {remote_check.stdout.strip()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ⚠️ 遠端倉庫設定警告: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Git 設定失敗: {e}\")\n",
    "        return False\n",
    "\n",
    "    # 步驟 4: Git LFS 設定\n",
    "    print(\"\\n📋 步驟 2/4: Git LFS 設定...\")\n",
    "\n",
    "    try:\n",
    "        # 安裝 Git LFS（Colab）\n",
    "        if IN_COLAB:\n",
    "            print(\"   📦 在 Colab 中安裝 Git LFS...\")\n",
    "            subprocess.run(['apt-get', 'update', '-qq'], check=True)\n",
    "            subprocess.run(['apt-get', 'install', '-y', '-qq', 'git-lfs'], check=True)\n",
    "            print(\"   ✅ Git LFS 已安裝\")\n",
    "\n",
    "        # 初始化 LFS\n",
    "        try:\n",
    "            subprocess.run(['git', 'lfs', 'install'], check=True)\n",
    "            print(\"   ✅ Git LFS 初始化完成\")\n",
    "        except:\n",
    "            print(\"   ⚠️ Git LFS 初始化跳過（可能已設定）\")\n",
    "\n",
    "        # 設定 LFS 追蹤（容錯處理）\n",
    "        lfs_patterns = ['*.csv', '*.json', '*.pkl', '*.parquet', '*.h5', '*.hdf5']\n",
    "        for pattern in lfs_patterns:\n",
    "            try:\n",
    "                result = subprocess.run(['git', 'lfs', 'track', pattern],\n",
    "                                      capture_output=True, text=True)\n",
    "                if result.returncode == 0:\n",
    "                    print(f\"   📦 LFS 追蹤: {pattern}\")\n",
    "                else:\n",
    "                    print(f\"   ⚠️ LFS 追蹤 {pattern} 警告: {result.stderr.strip()}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ⚠️ LFS 追蹤 {pattern} 跳過: {e}\")\n",
    "\n",
    "        # 添加 .gitattributes 到 staging\n",
    "        try:\n",
    "            subprocess.run(['git', 'add', '.gitattributes'], check=False)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️ Git LFS 設定警告: {e}\")\n",
    "        print(\"   💡 繼續執行，但大檔案可能無法正確追蹤\")\n",
    "\n",
    "    # 步驟 5: 添加檔案並提交\n",
    "    print(\"\\n📋 步驟 3/4: 添加檔案與提交...\")\n",
    "\n",
    "    try:\n",
    "        # 確保重要目錄存在\n",
    "        important_dirs = ['data', 'notebooks', 'app', 'scripts']\n",
    "        for dir_name in important_dirs:\n",
    "            dir_path = Path(dir_name)\n",
    "            if dir_path.exists():\n",
    "                print(f\"   📂 找到目錄: {dir_name}\")\n",
    "            elif IN_COLAB and dir_name == 'data':\n",
    "                # 在 Colab 中創建 data 目錄並複製特徵檔案\n",
    "                dir_path.mkdir(exist_ok=True)\n",
    "                print(f\"   📂 創建目錄: {dir_name}\")\n",
    "\n",
    "        # 添加所有檔案\n",
    "        subprocess.run(['git', 'add', '.'], check=True)\n",
    "        print(\"   ✅ 檔案添加完成\")\n",
    "\n",
    "        # 檢查是否有變更\n",
    "        status_result = subprocess.run(['git', 'status', '--porcelain'],\n",
    "                                      capture_output=True, text=True, check=True)\n",
    "\n",
    "        if not status_result.stdout.strip():\n",
    "            print(\"   ✅ 沒有新的變更需要提交\")\n",
    "            return True\n",
    "\n",
    "        # 創建提交\n",
    "        commit_message = \"\"\"data: update BLS/TLS baseline analysis results\n",
    "\n",
    "- 📊 完成 BLS (Box Least Squares) 週期搜尋分析\n",
    "- 🔍 完成 TLS (Transit Least Squares) 高精度分析\n",
    "- 📈 提取機器學習特徵: bls_tls_features.csv\n",
    "- 📋 生成分析報告與視覺化結果\n",
    "- 🎯 測試多個 TESS/Kepler 目標的凌日偵測效能\n",
    "- 🚀 準備進行合成注入訓練 (03_injection_train.ipynb)\n",
    "\n",
    "Co-Authored-By: hctsai1006 <39769660@cuni.cz>\n",
    "        \"\"\"\n",
    "\n",
    "        subprocess.run(['git', 'commit', '-m', commit_message], check=True)\n",
    "        print(\"   ✅ 提交完成\")\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"   ❌ 檔案提交失敗: {e}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ 檔案處理失敗: {e}\")\n",
    "        return False\n",
    "\n",
    "    # 步驟 6: 推送到 GitHub\n",
    "    print(\"\\n📋 步驟 4/4: 推送到 GitHub...\")\n",
    "\n",
    "    try:\n",
    "        # 獲取遠端 URL 並插入 token\n",
    "        remote_result = subprocess.run(['git', 'remote', 'get-url', 'origin'],\n",
    "                                      capture_output=True, text=True, check=True)\n",
    "        remote_url = remote_result.stdout.strip()\n",
    "\n",
    "        # 構造帶 token 的 URL\n",
    "        if remote_url.startswith('https://github.com/'):\n",
    "            # 提取倉庫路徑\n",
    "            repo_path = remote_url.replace('https://github.com/', '').replace('.git', '')\n",
    "            auth_url = f\"https://{token}@github.com/{repo_path}.git\"\n",
    "        else:\n",
    "            print(f\"   ⚠️ 遠端 URL 格式異常: {remote_url}\")\n",
    "            auth_url = remote_url\n",
    "\n",
    "        # 推送\n",
    "        push_result = subprocess.run([\n",
    "            'git', 'push', auth_url, 'main'\n",
    "        ], capture_output=True, text=True, timeout=300)\n",
    "\n",
    "        if push_result.returncode == 0:\n",
    "            print(\"   ✅ 推送成功！\")\n",
    "            print(f\"   📡 推送輸出: {push_result.stdout[:200]}...\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"   ❌ 推送失敗: {push_result.stderr}\")\n",
    "            # 嘗試推送到其他分支\n",
    "            try:\n",
    "                alt_push = subprocess.run([\n",
    "                    'git', 'push', auth_url, 'HEAD:main'\n",
    "                ], capture_output=True, text=True, timeout=300)\n",
    "                if alt_push.returncode == 0:\n",
    "                    print(\"   ✅ 備用推送成功！\")\n",
    "                    return True\n",
    "            except:\n",
    "                pass\n",
    "            return False\n",
    "\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"   ❌ 推送超時，請檢查網路連接\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ 推送失敗: {e}\")\n",
    "        return False\n",
    "\n",
    "    finally:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"📋 BLS/TLS 分析結果推送完成!\")\n",
    "        if IN_COLAB:\n",
    "            print(\"💡 如果遇到問題:\")\n",
    "            print(\"   1. 確保 token 有 'repo' 權限\")\n",
    "            print(\"   2. 確保你有目標倉庫的寫入權限\")\n",
    "            print(\"   3. 檢查倉庫 URL 是否正確\")\n",
    "\n",
    "# 呼叫函數（請在執行時提供 token）\n",
    "print(\"🔐 準備推送 BLS/TLS 分析結果...\")\n",
    "print(\"💡 執行方式: ultimate_push_to_github_02(token='你的GitHub_token')\")\n",
    "print(\"📝 或直接執行下方 cell 並在提示時輸入 token\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🚀 GitHub Push 終極解決方案\n",
    "\n",
    "將 BLS/TLS 分析結果推送到 GitHub 倉庫："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Phase 5 & 6 總結報告\n",
    "\n",
    "### Phase 5: Wotan 去趨勢方法比較\n",
    "\n",
    "測試了4種去趨勢方法：\n",
    "1. **Lightkurve flatten()**: 滑動中位數濾波器（window_length=401）\n",
    "2. **Wotan biweight**: 雙重權重法，對離群值具有穩健性\n",
    "3. **Wotan rspline**: 正則化樣條法，平滑連續曲線\n",
    "4. **Wotan hspline**: 超樣條法，適合長週期變化\n",
    "\n",
    "**評估指標**: Signal-to-Noise Ratio (SNR)\n",
    "\n",
    "### Phase 6: 進階 BLS 指標\n",
    "\n",
    "新增特徵類別：\n",
    "1. **奇偶深度分析** (Odd/Even Transit Depth):\n",
    "   - 用於檢測假陽性（如雙星系統）\n",
    "   - 真實行星的奇偶深度應該相近\n",
    "   \n",
    "2. **凌日形狀指標** (Transit Shape):\n",
    "   - 曲率 (Curvature): 區分 V-shape vs U-shape\n",
    "   - 對稱性 (Symmetry): 評估凌日的左右對稱性\n",
    "   \n",
    "3. **去趨勢品質指標**:\n",
    "   - 各方法的 SNR 比較\n",
    "   - 最佳方法選擇\n",
    "   - SNR 改善百分比\n",
    "\n",
    "### 輸出檔案\n",
    "\n",
    "- **C:\\Users\\thc1006\\Desktop\\dev\\exoplanet-starter\\data\\bls_tls_features_enhanced.csv**: 完整增強特徵集\n",
    "- **C:\\Users\\thc1006\\Desktop\\dev\\exoplanet-starter\\data\\bls_tls_features_enhanced_stats.json**: 特徵統計與說明\n",
    "\n",
    "### 下一步: Phase 3 監督學習\n",
    "\n",
    "這些增強特徵將用於：\n",
    "- 訓練機器學習分類器（LogReg, XGBoost, Random Forest）\n",
    "- 改善行星候選體的偵測精度\n",
    "- 降低假陽性率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 儲存增強特徵到檔案\n",
    "output_dir = Path(\"../data\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 儲存增強特徵 CSV\n",
    "enhanced_features_file = output_dir / \"bls_tls_features_enhanced.csv\"\n",
    "enhanced_features_df.to_csv(enhanced_features_file, index=False)\n",
    "print(f\"\\n💾 增強特徵已儲存至: {enhanced_features_file}\")\n",
    "\n",
    "# 儲存特徵統計與說明\n",
    "enhanced_stats = {\n",
    "    'n_samples': len(enhanced_features_df),\n",
    "    'n_features': len(enhanced_features_df.columns),\n",
    "    'n_positive': int((enhanced_features_df['label'] == 1).sum()),\n",
    "    'n_negative': int((enhanced_features_df['label'] == 0).sum()),\n",
    "    'feature_categories': {\n",
    "        'basic_info': ['target_id', 'target_name', 'label', 'source', 'known_period', 'known_depth'],\n",
    "        'bls_features': [col for col in enhanced_features_df.columns if col.startswith('bls_')],\n",
    "        'tls_features': [col for col in enhanced_features_df.columns if col.startswith('tls_')],\n",
    "        'comparison_features': ['period_ratio', 'depth_ratio', 'snr_ratio', 'period_diff_pct', 'depth_diff_pct', 'snr_improvement'],\n",
    "        'detrending_features': [col for col in enhanced_features_df.columns if 'detrend' in col or col.endswith('_snr')],\n",
    "        'odd_even_features': ['odd_depth_ppm', 'even_depth_ppm', 'odd_even_ratio', 'odd_even_diff_ppm'],\n",
    "        'shape_features': ['transit_curvature', 'transit_symmetry', 'transit_points']\n",
    "    },\n",
    "    'phase_5_features': [col for col in enhanced_features_df.columns if 'detrend' in col or (col.endswith('_snr') and 'wotan' in col)],\n",
    "    'phase_6_features': ['odd_depth_ppm', 'even_depth_ppm', 'odd_even_ratio', 'odd_even_diff_ppm', \n",
    "                         'transit_curvature', 'transit_symmetry', 'transit_points']\n",
    "}\n",
    "\n",
    "# 儲存統計資訊\n",
    "import json\n",
    "enhanced_stats_file = output_dir / \"bls_tls_features_enhanced_stats.json\"\n",
    "with open(enhanced_stats_file, 'w') as f:\n",
    "    json.dump(enhanced_stats, f, indent=2)\n",
    "print(f\"📊 增強特徵統計已儲存至: {enhanced_stats_file}\")\n",
    "\n",
    "# 顯示各類別特徵數量\n",
    "print(\"\\n📋 特徵分類統計：\")\n",
    "for category, features_list in enhanced_stats['feature_categories'].items():\n",
    "    print(f\"   • {category}: {len(features_list)} 個特徵\")\n",
    "\n",
    "print(f\"\\n🌟 Phase 5 新增特徵: {len(enhanced_stats['phase_5_features'])} 個\")\n",
    "print(f\"   {enhanced_stats['phase_5_features']}\")\n",
    "\n",
    "print(f\"\\n🎯 Phase 6 新增特徵: {len(enhanced_stats['phase_6_features'])} 個\")\n",
    "print(f\"   {enhanced_stats['phase_6_features']}\")\n",
    "\n",
    "print(\"\\n✅ Phase 5 & 6 完成！\")\n",
    "print(\"   所有增強特徵已準備完成，可用於 Phase 3 監督學習訓練\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎯 Phase 6: Advanced BLS Metrics Extraction\n",
    "\"\"\"\n",
    "提取額外的 BLS 指標與特徵\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"🎯 Phase 6: Advanced BLS Metrics Extraction\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def calculate_odd_even_depth(lc: lk.LightCurve, period: float, t0: float, duration: float) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    計算奇偶次凌日深度差異（用於檢測假陽性，如雙星系統）\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    lc : lightkurve.LightCurve\n",
    "        去趨勢光曲線\n",
    "    period : float\n",
    "        凌日週期\n",
    "    t0 : float\n",
    "        第一次凌日時間\n",
    "    duration : float\n",
    "        凌日持續時間\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : 包含奇偶深度與比率的字典\n",
    "    \"\"\"\n",
    "    try:\n",
    "        time_array = lc.time.value if hasattr(lc.time, 'value') else np.array(lc.time)\n",
    "        flux_array = lc.flux.value if hasattr(lc.flux, 'value') else np.array(lc.flux)\n",
    "        \n",
    "        # 計算每個資料點所屬的週期編號\n",
    "        phase = (time_array - t0) / period\n",
    "        cycle_number = np.floor(phase)\n",
    "        \n",
    "        # 分離奇數和偶數週期\n",
    "        odd_mask = (cycle_number % 2 == 1) & (np.abs(phase - cycle_number) < duration / period)\n",
    "        even_mask = (cycle_number % 2 == 0) & (np.abs(phase - cycle_number) < duration / period)\n",
    "        \n",
    "        # 計算深度（相對於 1.0）\n",
    "        if np.sum(odd_mask) > 0 and np.sum(even_mask) > 0:\n",
    "            odd_depth = 1.0 - np.median(flux_array[odd_mask])\n",
    "            even_depth = 1.0 - np.median(flux_array[even_mask])\n",
    "            \n",
    "            # 計算差異比率\n",
    "            if even_depth > 0:\n",
    "                depth_ratio = odd_depth / even_depth\n",
    "            else:\n",
    "                depth_ratio = np.nan\n",
    "            \n",
    "            return {\n",
    "                'odd_depth_ppm': odd_depth * 1e6,\n",
    "                'even_depth_ppm': even_depth * 1e6,\n",
    "                'odd_even_ratio': depth_ratio,\n",
    "                'odd_even_diff_ppm': (odd_depth - even_depth) * 1e6\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'odd_depth_ppm': np.nan,\n",
    "                'even_depth_ppm': np.nan,\n",
    "                'odd_even_ratio': np.nan,\n",
    "                'odd_even_diff_ppm': np.nan\n",
    "            }\n",
    "    except Exception as e:\n",
    "        print(f\"      ⚠️ 計算奇偶深度失敗: {e}\")\n",
    "        return {\n",
    "            'odd_depth_ppm': np.nan,\n",
    "            'even_depth_ppm': np.nan,\n",
    "            'odd_even_ratio': np.nan,\n",
    "            'odd_even_diff_ppm': np.nan\n",
    "        }\n",
    "\n",
    "def calculate_transit_shape_metrics(lc: lk.LightCurve, period: float, t0: float, duration: float) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    計算凌日形狀指標\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    lc : lightkurve.LightCurve\n",
    "        去趨勢光曲線\n",
    "    period : float\n",
    "        凌日週期\n",
    "    t0 : float\n",
    "        第一次凌日時間\n",
    "    duration : float\n",
    "        凌日持續時間\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : 包含形狀指標的字典\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 摺疊光曲線\n",
    "        folded_lc = lc.fold(period=period, epoch_time=t0)\n",
    "        \n",
    "        time_array = folded_lc.time.value if hasattr(folded_lc.time, 'value') else np.array(folded_lc.time)\n",
    "        flux_array = folded_lc.flux.value if hasattr(folded_lc.flux, 'value') else np.array(folded_lc.flux)\n",
    "        \n",
    "        # 選擇凌日區域\n",
    "        transit_mask = np.abs(time_array) < duration / 2\n",
    "        \n",
    "        if np.sum(transit_mask) > 10:  # 至少需要10個點\n",
    "            transit_flux = flux_array[transit_mask]\n",
    "            transit_time = time_array[transit_mask]\n",
    "            \n",
    "            # 計算 V-shape vs U-shape (曲率)\n",
    "            # 簡化版：計算最深點附近的曲率\n",
    "            min_idx = np.argmin(transit_flux)\n",
    "            if min_idx > 0 and min_idx < len(transit_flux) - 1:\n",
    "                curvature = (transit_flux[min_idx-1] + transit_flux[min_idx+1] - 2*transit_flux[min_idx])\n",
    "            else:\n",
    "                curvature = np.nan\n",
    "            \n",
    "            # 計算對稱性（左右半部的差異）\n",
    "            mid_idx = len(transit_flux) // 2\n",
    "            left_mean = np.mean(transit_flux[:mid_idx])\n",
    "            right_mean = np.mean(transit_flux[mid_idx:])\n",
    "            symmetry = abs(left_mean - right_mean) / np.std(transit_flux)\n",
    "            \n",
    "            return {\n",
    "                'transit_curvature': curvature,\n",
    "                'transit_symmetry': symmetry,\n",
    "                'transit_points': int(np.sum(transit_mask))\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'transit_curvature': np.nan,\n",
    "                'transit_symmetry': np.nan,\n",
    "                'transit_points': int(np.sum(transit_mask))\n",
    "            }\n",
    "    except Exception as e:\n",
    "        print(f\"      ⚠️ 計算凌日形狀失敗: {e}\")\n",
    "        return {\n",
    "            'transit_curvature': np.nan,\n",
    "            'transit_symmetry': np.nan,\n",
    "            'transit_points': 0\n",
    "        }\n",
    "\n",
    "def extract_enhanced_bls_features(\n",
    "    search_result: Dict[str, Any],\n",
    "    detrending_result: Dict[str, Any]\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    提取增強的 BLS 特徵（包含 Phase 5 和 Phase 6）\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    search_result : dict\n",
    "        BLS/TLS 搜尋結果\n",
    "    detrending_result : dict\n",
    "        去趨勢方法比較結果\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : 增強特徵字典\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # 基本資訊\n",
    "    target = search_result['target']\n",
    "    features['target_id'] = target.get('id', '')\n",
    "    features['target_name'] = target.get('name', '')\n",
    "    features['label'] = target.get('label', -1)\n",
    "    features['source'] = target.get('source', '')\n",
    "    features['known_period'] = target.get('known_period', np.nan)\n",
    "    features['known_depth'] = target.get('known_depth', np.nan)\n",
    "    \n",
    "    # BLS 基本特徵\n",
    "    if 'bls' in search_result:\n",
    "        bls = search_result['bls']\n",
    "        features['bls_period'] = bls['period']\n",
    "        features['bls_t0'] = bls['t0']\n",
    "        features['bls_duration_hours'] = bls['duration'] * 24\n",
    "        features['bls_depth_ppm'] = bls['depth'] * 1e6\n",
    "        features['bls_snr'] = bls['snr']\n",
    "        features['bls_duration_phase'] = bls['duration'] / bls['period'] if bls['period'] > 0 else np.nan\n",
    "    \n",
    "    # TLS 基本特徵\n",
    "    if 'tls' in search_result:\n",
    "        tls = search_result['tls']\n",
    "        features['tls_period'] = tls['period']\n",
    "        features['tls_t0'] = tls['t0']\n",
    "        features['tls_duration_hours'] = tls['duration'] * 24\n",
    "        features['tls_depth_ppm'] = tls['depth'] * 1e6\n",
    "        features['tls_sde'] = tls['snr']\n",
    "        features['tls_duration_phase'] = tls['duration'] / tls['period'] if tls['period'] > 0 else np.nan\n",
    "    \n",
    "    # BLS vs TLS 比較特徵\n",
    "    if 'bls' in search_result and 'tls' in search_result:\n",
    "        bls = search_result['bls']\n",
    "        tls = search_result['tls']\n",
    "        \n",
    "        features['period_ratio'] = tls['period'] / bls['period'] if bls['period'] > 0 else np.nan\n",
    "        features['period_diff_pct'] = abs(tls['period'] - bls['period']) / bls['period'] * 100 if bls['period'] > 0 else np.nan\n",
    "        features['depth_ratio'] = tls['depth'] / bls['depth'] if bls['depth'] > 0 else np.nan\n",
    "        features['depth_diff_pct'] = abs(tls['depth'] - bls['depth']) / bls['depth'] * 100 if bls['depth'] > 0 else np.nan\n",
    "        features['snr_ratio'] = tls['snr'] / bls['snr'] if bls['snr'] > 0 else np.nan\n",
    "        features['snr_improvement'] = (tls['snr'] - bls['snr']) / bls['snr'] * 100 if bls['snr'] > 0 else np.nan\n",
    "    \n",
    "    # Phase 5: 去趨勢方法比較特徵\n",
    "    if detrending_result:\n",
    "        methods = detrending_result['methods']\n",
    "        features['best_detrend_method'] = detrending_result['best_method']\n",
    "        features['best_detrend_snr'] = detrending_result['best_snr']\n",
    "        \n",
    "        # 各方法的 SNR\n",
    "        for method_key in ['lightkurve_flatten', 'wotan_biweight', 'wotan_rspline', 'wotan_hspline']:\n",
    "            if method_key in methods:\n",
    "                features[f'{method_key}_snr'] = methods[method_key]['snr']\n",
    "        \n",
    "        # SNR 改善\n",
    "        if 'lightkurve_flatten' in methods and detrending_result['best_method'] != 'lightkurve_flatten':\n",
    "            baseline_snr = methods['lightkurve_flatten']['snr']\n",
    "            best_snr = detrending_result['best_snr']\n",
    "            if baseline_snr > 0:\n",
    "                features['snr_improvement_by_wotan'] = (best_snr - baseline_snr) / baseline_snr * 100\n",
    "    \n",
    "    # Phase 6: 奇偶深度與形狀特徵\n",
    "    if 'bls' in search_result and 'lc_flat' in search_result:\n",
    "        bls = search_result['bls']\n",
    "        lc_flat = search_result['lc_flat']\n",
    "        \n",
    "        # 計算奇偶深度\n",
    "        odd_even = calculate_odd_even_depth(lc_flat, bls['period'], bls['t0'], bls['duration'])\n",
    "        features.update(odd_even)\n",
    "        \n",
    "        # 計算形狀指標\n",
    "        shape = calculate_transit_shape_metrics(lc_flat, bls['period'], bls['t0'], bls['duration'])\n",
    "        features.update(shape)\n",
    "    \n",
    "    return features\n",
    "\n",
    "# 提取所有目標的增強特徵\n",
    "print(\"\\n開始提取增強 BLS 特徵...\")\n",
    "enhanced_features_list = []\n",
    "\n",
    "for target_id in search_results.keys():\n",
    "    print(f\"\\n🎯 提取 {search_results[target_id]['target']['name']} 的增強特徵...\")\n",
    "    \n",
    "    # 獲取去趨勢結果\n",
    "    detrend_result = detrending_results.get(target_id, None)\n",
    "    \n",
    "    # 提取特徵\n",
    "    enhanced_features = extract_enhanced_bls_features(\n",
    "        search_results[target_id],\n",
    "        detrend_result\n",
    "    )\n",
    "    \n",
    "    enhanced_features_list.append(enhanced_features)\n",
    "    \n",
    "    print(f\"   ✅ 特徵提取完成\")\n",
    "\n",
    "# 轉換為 DataFrame\n",
    "enhanced_features_df = pd.DataFrame(enhanced_features_list)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📊 增強特徵統計：\")\n",
    "print(f\"   樣本數: {len(enhanced_features_df)}\")\n",
    "print(f\"   特徵數: {len(enhanced_features_df.columns)}\")\n",
    "print(f\"   正樣本: {(enhanced_features_df['label'] == 1).sum()}\")\n",
    "print(f\"   負樣本: {(enhanced_features_df['label'] == 0).sum()}\")\n",
    "\n",
    "print(\"\\n📝 新增特徵列表：\")\n",
    "new_features = [col for col in enhanced_features_df.columns if col not in features_df.columns]\n",
    "for i, col in enumerate(new_features, 1):\n",
    "    print(f\"   {i}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Phase 6: Advanced BLS Metrics and Feature Preparation\n",
    "\n",
    "提取額外的 BLS 指標，為 Phase 3 監督學習管線準備完整特徵：\n",
    "- **Depth (深度)**: 凌日期間的流量下降\n",
    "- **Duration (持續時間)**: 凌日事件的時間長度\n",
    "- **SNR (信噪比)**: 訊號強度評估\n",
    "- **Odd/Even Transit Depth**: 奇偶次凌日深度比較（檢測假陽性）\n",
    "- **Transit Shape**: 凌日形狀參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 視覺化：4種去趨勢方法的並排比較\n",
    "def plot_detrending_comparison(detrending_result: Dict[str, Any]):\n",
    "    \"\"\"\n",
    "    繪製4種去趨勢方法的並排比較圖\n",
    "    \"\"\"\n",
    "    target = detrending_result['target']\n",
    "    methods = detrending_result['methods']\n",
    "    best_method = detrending_result['best_method']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "    fig.suptitle(f\"{target['name']} ({target['id']}) - 去趨勢方法比較\", \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    \n",
    "    method_names = ['lightkurve_flatten', 'wotan_biweight', 'wotan_rspline', 'wotan_hspline']\n",
    "    method_titles = [\n",
    "        'Lightkurve flatten()',\n",
    "        'Wotan Biweight',\n",
    "        'Wotan R-Spline',\n",
    "        'Wotan H-Spline'\n",
    "    ]\n",
    "    \n",
    "    for idx, (method_key, title) in enumerate(zip(method_names, method_titles)):\n",
    "        ax = axes[idx // 2, idx % 2]\n",
    "        \n",
    "        if method_key in methods:\n",
    "            lc = methods[method_key]['lc']\n",
    "            snr = methods[method_key]['snr']\n",
    "            \n",
    "            # 繪製光曲線\n",
    "            lc.scatter(ax=ax, s=0.5, color='blue', alpha=0.4)\n",
    "            \n",
    "            # 標題（最佳方法加星號）\n",
    "            is_best = (method_key == best_method)\n",
    "            title_text = f\"{title}\\nSNR: {snr:.2f}\"\n",
    "            if is_best:\n",
    "                title_text = f\"🏆 {title_text} 🏆\"\n",
    "                ax.set_facecolor('#ffffcc')  # 淡黃色背景\n",
    "            \n",
    "            ax.set_title(title_text, fontsize=11, fontweight='bold' if is_best else 'normal')\n",
    "            ax.set_xlabel('時間 (BTJD)', fontsize=9)\n",
    "            ax.set_ylabel('標準化流量', fontsize=9)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            # 計算並顯示統計資訊\n",
    "            flux = lc.flux.value if hasattr(lc.flux, 'value') else np.array(lc.flux)\n",
    "            flux_clean = flux[~np.isnan(flux)]\n",
    "            \n",
    "            textstr = f'Mean: {np.mean(flux_clean):.4f}\\nStd: {np.std(flux_clean):.4f}\\nPoints: {len(flux_clean):,}'\n",
    "            ax.text(0.02, 0.98, textstr, transform=ax.transAxes, fontsize=8,\n",
    "                   verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, f'{title}\\n資料不可用', \n",
    "                   ha='center', va='center', transform=ax.transAxes)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# 繪製所有目標的去趨勢方法比較圖\n",
    "print(\"\\n📊 繪製去趨勢方法比較圖...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for target_id, result in detrending_results.items():\n",
    "    print(f\"\\n📊 {result['target']['name']} - 最佳方法: {result['best_method']}\")\n",
    "    fig = plot_detrending_comparison(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 對每個目標執行多方法去趨勢比較\n",
    "for target_id, data in processed_data.items():\n",
    "    print(f\"\\n🎯 分析 {data['target']['name']} ({target_id})...\")\n",
    "    \n",
    "    lc_clean = data['lc_clean']\n",
    "    lc_flat_original = data['lc_flat']\n",
    "    \n",
    "    # 儲存各方法結果\n",
    "    methods_results = {}\n",
    "    \n",
    "    # 1. Lightkurve flatten() - 已有的結果\n",
    "    snr_lightkurve = calculate_snr(lc_flat_original)\n",
    "    methods_results['lightkurve_flatten'] = {\n",
    "        'lc': lc_flat_original,\n",
    "        'snr': snr_lightkurve,\n",
    "        'method': 'lightkurve_flatten'\n",
    "    }\n",
    "    print(f\"   ✅ Lightkurve flatten() - SNR: {snr_lightkurve:.2f}\")\n",
    "    \n",
    "    # 2. Wotan biweight\n",
    "    lc_biweight, snr_biweight, meta_biweight = apply_wotan_detrending(\n",
    "        lc_clean, method='biweight', window_length=0.5\n",
    "    )\n",
    "    methods_results['wotan_biweight'] = {\n",
    "        'lc': lc_biweight,\n",
    "        'snr': snr_biweight,\n",
    "        'method': 'wotan_biweight',\n",
    "        'metadata': meta_biweight\n",
    "    }\n",
    "    \n",
    "    # 3. Wotan rspline\n",
    "    lc_rspline, snr_rspline, meta_rspline = apply_wotan_detrending(\n",
    "        lc_clean, method='rspline', window_length=0.5\n",
    "    )\n",
    "    methods_results['wotan_rspline'] = {\n",
    "        'lc': lc_rspline,\n",
    "        'snr': snr_rspline,\n",
    "        'method': 'wotan_rspline',\n",
    "        'metadata': meta_rspline\n",
    "    }\n",
    "    \n",
    "    # 4. Wotan hspline\n",
    "    lc_hspline, snr_hspline, meta_hspline = apply_wotan_detrending(\n",
    "        lc_clean, method='hspline', window_length=0.5\n",
    "    )\n",
    "    methods_results['wotan_hspline'] = {\n",
    "        'lc': lc_hspline,\n",
    "        'snr': snr_hspline,\n",
    "        'method': 'wotan_hspline',\n",
    "        'metadata': meta_hspline\n",
    "    }\n",
    "    \n",
    "    # 找出最佳 SNR 的方法\n",
    "    best_method = max(methods_results.items(), key=lambda x: x[1]['snr'])\n",
    "    best_method_name = best_method[0]\n",
    "    best_snr = best_method[1]['snr']\n",
    "    \n",
    "    print(f\"\\n   🏆 最佳方法: {best_method_name} (SNR: {best_snr:.2f})\")\n",
    "    \n",
    "    # 儲存結果\n",
    "    detrending_results[target_id] = {\n",
    "        'target': data['target'],\n",
    "        'methods': methods_results,\n",
    "        'best_method': best_method_name,\n",
    "        'best_snr': best_snr\n",
    "    }\n",
    "\n",
    "print(\"\\n✅ 所有目標的去趨勢方法比較完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🌟 Phase 5: Wotan Detrending Comparison\n",
    "\"\"\"\n",
    "比較不同去趨勢方法的效能\n",
    "- Lightkurve flatten() (已使用)\n",
    "- Wotan biweight\n",
    "- Wotan rspline\n",
    "- Wotan hspline\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"🌟 Phase 5: Wotan Detrending Method Comparison\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 導入 wotan\n",
    "try:\n",
    "    from wotan import flatten as wotan_flatten\n",
    "    print(\"✅ Wotan 導入成功\")\n",
    "except ImportError:\n",
    "    print(\"❌ Wotan 未安裝，正在安裝...\")\n",
    "    import subprocess, sys\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"wotan\"])\n",
    "    from wotan import flatten as wotan_flatten\n",
    "    print(\"✅ Wotan 安裝並導入成功\")\n",
    "\n",
    "def calculate_snr(lc: lk.LightCurve) -> float:\n",
    "    \"\"\"\n",
    "    計算光曲線的信噪比 (SNR)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    lc : lightkurve.LightCurve\n",
    "        輸入光曲線\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float : 信噪比\n",
    "    \"\"\"\n",
    "    flux = lc.flux.value if hasattr(lc.flux, 'value') else np.array(lc.flux)\n",
    "    \n",
    "    # 移除 NaN 值\n",
    "    flux_clean = flux[~np.isnan(flux)]\n",
    "    \n",
    "    if len(flux_clean) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # SNR = mean / std\n",
    "    mean_flux = np.mean(flux_clean)\n",
    "    std_flux = np.std(flux_clean)\n",
    "    \n",
    "    if std_flux == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return mean_flux / std_flux\n",
    "\n",
    "def apply_wotan_detrending(\n",
    "    lc_clean: lk.LightCurve,\n",
    "    method: str = 'biweight',\n",
    "    window_length: float = 0.5\n",
    ") -> Tuple[lk.LightCurve, float, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    使用 Wotan 進行去趨勢處理\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    lc_clean : lightkurve.LightCurve\n",
    "        清理過的光曲線\n",
    "    method : str\n",
    "        Wotan 方法: 'biweight', 'rspline', 'hspline'\n",
    "    window_length : float\n",
    "        滑動視窗長度（天）\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple : (去趨勢光曲線, SNR, metadata)\n",
    "    \"\"\"\n",
    "    print(f\"   🔧 正在使用 Wotan {method} 方法去趨勢...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 準備資料\n",
    "    time_array = lc_clean.time.value if hasattr(lc_clean.time, 'value') else np.array(lc_clean.time)\n",
    "    flux_array = lc_clean.flux.value if hasattr(lc_clean.flux, 'value') else np.array(lc_clean.flux)\n",
    "    \n",
    "    try:\n",
    "        # 執行 Wotan 去趨勢\n",
    "        flatten_flux, trend_flux = wotan_flatten(\n",
    "            time_array,\n",
    "            flux_array,\n",
    "            method=method,\n",
    "            window_length=window_length,\n",
    "            return_trend=True\n",
    "        )\n",
    "        \n",
    "        # 創建新的 LightCurve 物件\n",
    "        lc_wotan = lc_clean.copy()\n",
    "        lc_wotan.flux = flatten_flux\n",
    "        \n",
    "        # 計算 SNR\n",
    "        snr = calculate_snr(lc_wotan)\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        metadata = {\n",
    "            'method': method,\n",
    "            'window_length': window_length,\n",
    "            'snr': snr,\n",
    "            'elapsed_time': elapsed_time,\n",
    "            'n_points': len(flatten_flux)\n",
    "        }\n",
    "        \n",
    "        print(f\"   ✅ Wotan {method} 完成（耗時 {elapsed_time:.2f} 秒）\")\n",
    "        print(f\"      SNR: {snr:.2f}\")\n",
    "        \n",
    "        return lc_wotan, snr, metadata\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Wotan {method} 失敗: {e}\")\n",
    "        # 返回原始光曲線作為 fallback\n",
    "        return lc_clean, 0.0, {'method': method, 'error': str(e)}\n",
    "\n",
    "# 儲存所有去趨勢結果\n",
    "detrending_results = {}\n",
    "\n",
    "print(\"\\n開始對所有目標進行多方法去趨勢比較...\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🌟 Phase 5: Wotan Detrending Method Comparison\n",
    "\n",
    "比較不同去趨勢方法的效能，找出最佳的訊號品質：\n",
    "- **Lightkurve flatten()**: 已使用的預設方法\n",
    "- **Wotan biweight**: 雙重權重法，對離群值具有穩健性\n",
    "- **Wotan rspline**: 正則化樣條法，平滑連續曲線\n",
    "- **Wotan hspline**: 超樣條法，適合長週期變化"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
