{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 Â· BLS Baseline - å…‰æ›²ç·šåˆ†æèˆ‡é€±æœŸæœå°‹\n",
    "\n",
    "## ç›®æ¨™\n",
    "1. **è³‡æ–™æŠ“å–èˆ‡æ¸…ç†**ï¼šä½¿ç”¨ Lightkurve ä¸‹è¼‰ TESS/Kepler å…‰æ›²ç·š\n",
    "2. **å»è¶¨å‹¢è™•ç†**ï¼šç§»é™¤ç³»çµ±æ€§é›œè¨Šä»¥å‡¸é¡¯å‡Œæ—¥è¨Šè™Ÿ\n",
    "3. **BLS/TLS æœå°‹**ï¼šå°‹æ‰¾é€±æœŸæ€§å‡Œæ—¥äº‹ä»¶\n",
    "4. **è¦–è¦ºåŒ–èˆ‡åˆ†æ**ï¼šæ¯”è¼ƒä¸åŒæ–¹æ³•çš„æ•ˆèƒ½å·®ç•°\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "source": "# æ­¥é©Ÿ 0: å®‰è£å¥—ä»¶èˆ‡ä¿®å¾© NumPy 2.0 ç›¸å®¹æ€§ (Colab ç’°å¢ƒ)\n# âš ï¸ é‡è¦: è‹¥åœ¨ Google Colabï¼ŒåŸ·è¡Œæ­¤ cell å¾Œè«‹æ‰‹å‹•é‡å•Ÿ Runtime (Runtime â†’ Restart runtime)\n\nimport sys\nIN_COLAB = 'google.colab' in sys.modules\n\nif IN_COLAB:\n    print(\"ğŸ“ åµæ¸¬åˆ° Google Colab ç’°å¢ƒ\")\n    print(\"ğŸ”§ å®‰è£ç›¸å®¹ç‰ˆæœ¬å¥—ä»¶...\")\n    !pip install -q numpy==1.26.4 pandas astropy scipy'<1.13' matplotlib scikit-learn\n    !pip install -q lightkurve astroquery transitleastsquares wotan\n    print(\"âœ… å¥—ä»¶å®‰è£å®Œæˆ!\")\n    print(\"âš ï¸ è«‹ç¾åœ¨æ‰‹å‹•é‡å•Ÿ Runtime: Runtime â†’ Restart runtime\")\n    print(\"   ç„¶å¾Œå¾ä¸‹ä¸€å€‹ cell ç¹¼çºŒåŸ·è¡Œ\")\nelse:\n    print(\"ğŸ’» æœ¬åœ°ç’°å¢ƒï¼Œè·³éå¥—ä»¶å®‰è£\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç’°å¢ƒè¨­å®šèˆ‡ä¾è³´å®‰è£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç’°å¢ƒè¨­å®šèˆ‡ä¾è³´å®‰è£ï¼ˆColabï¼‰\n",
    "import sys, subprocess, pkgutil\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def pipi(*pkgs):\n",
    "    \"\"\"å®‰è£å¥—ä»¶çš„è¼”åŠ©å‡½å¼\"\"\"\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", *pkgs])\n",
    "\n",
    "# å®‰è£å¿…è¦å¥—ä»¶ï¼ˆé¿å… numpy 2.0 ç›¸å®¹æ€§å•é¡Œï¼‰\n",
    "print(\"ğŸš€ æ­£åœ¨å®‰è£ä¾è³´å¥—ä»¶...\")\n",
    "try:\n",
    "    import numpy as np\n",
    "    import lightkurve as lk\n",
    "    import transitleastsquares as tls\n",
    "    print(\"âœ… åŸºç¤å¥—ä»¶å·²å®‰è£\")\n",
    "except Exception:\n",
    "    pipi(\"numpy<2\", \"lightkurve\", \"astroquery\", \"scikit-learn\", \n",
    "         \"matplotlib\", \"wotan\", \"transitleastsquares\")\n",
    "    print(\"âœ… ä¾è³´å¥—ä»¶å®‰è£å®Œæˆ\")\n",
    "\n",
    "# æª¢æŸ¥ GPU è³‡è¨Š\n",
    "# æª¢æŸ¥ GPU è³‡è¨Šï¼ˆå˜—è©¦å°å…¥ torchï¼‰\n",
    "try:\n",
    "    import torch\n",
    "except ImportError:\n",
    "    torch = None\n",
    "\n",
    "if torch is not None and torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    print(f\"ğŸ–¥ï¸ GPU å‹è™Ÿ: {gpu_name}\")\n",
    "    print(f\"   è¨˜æ†¶é«”: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    \n",
    "    # å¦‚æœæ˜¯ NVIDIA L4ï¼Œæä¾› BF16 å„ªåŒ–å»ºè­°\n",
    "    if \"L4\" in gpu_name:\n",
    "        print(\"ğŸ’¡ åµæ¸¬åˆ° NVIDIA L4 GPU - æ”¯æ´é«˜æ•ˆèƒ½ BF16 é‹ç®—\")\n",
    "        print(\"   å»ºè­°åœ¨è¨“ç·´æ™‚ä½¿ç”¨ torch.autocast('cuda', dtype=torch.bfloat16)\")\n",
    "else:\n",
    "    try:\n",
    "        # ä½¿ç”¨ nvidia-smi æª¢æŸ¥ GPU\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=name', '--format=csv,noheader'], \n",
    "                              capture_output=True, text=True, check=False)\n",
    "        if result.returncode == 0:\n",
    "            gpu_name = result.stdout.strip()\n",
    "            print(f\"ğŸ–¥ï¸ GPU å‹è™Ÿ: {gpu_name}\")\n",
    "            if \"L4\" in gpu_name:\n",
    "                print(\"ğŸ’¡ åµæ¸¬åˆ° NVIDIA L4 GPU - æ”¯æ´é«˜æ•ˆèƒ½ BF16 é‹ç®—\")\n",
    "    except:\n",
    "        print(\"âš ï¸ æœªåµæ¸¬åˆ° GPUï¼Œå°‡ä½¿ç”¨ CPU é‹ç®—\")\n",
    "\n",
    "print(\"\\nç’°å¢ƒè¨­å®šå®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. å°å…¥å¿…è¦å¥—ä»¶èˆ‡è¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightkurve as lk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import pandas as pd\n",
    "from transitleastsquares import transitleastsquares\n",
    "from typing import Dict, Any, Tuple, Optional\n",
    "import time\n",
    "\n",
    "# è¨­å®šåœ–è¡¨é¢¨æ ¼\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"ğŸ“š å¥—ä»¶å°å…¥å®Œæˆ\")\n",
    "print(f\"   Lightkurve ç‰ˆæœ¬: {lk.__version__}\")\n",
    "print(f\"   NumPy ç‰ˆæœ¬: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. è³‡æ–™æŠ“å–èˆ‡æ¸…ç†\n",
    "\n",
    "### 3.1 ç›®æ¨™å¤©é«”é¸æ“‡\n",
    "æˆ‘å€‘å°‡åˆ†æä¸‰å€‹å·²ç¢ºèªçš„ç³»å¤–è¡Œæ˜Ÿå®¿ä¸»æ†æ˜Ÿï¼š\n",
    "- **2å€‹ TESS ç›®æ¨™ (TIC)**ï¼šTIC 25155310ï¼ˆTOI-431ï¼‰ã€TIC 307210830ï¼ˆTOI-270ï¼‰\n",
    "- **1å€‹ Kepler ç›®æ¨™ (KIC)**ï¼šKIC 11904151ï¼ˆKepler-10ï¼‰\n",
    "\n",
    "é€™äº›ç›®æ¨™éƒ½æœ‰å·²ç¢ºèªçš„è¡Œæ˜Ÿï¼Œé©åˆä½œç‚ºåŸºæº–æ¸¬è©¦ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "source": "# ğŸ”§ è¼‰å…¥å·²ä¸‹è¼‰çš„è³‡æ–™é›†\n\"\"\"\nå¾ 01_tap_download.ipynb è¼‰å…¥å·²è™•ç†çš„è³‡æ–™\nä½¿ç”¨ data_loader_colab.py æ¨¡çµ„é€²è¡Œçµ±ä¸€çš„è³‡æ–™è¼‰å…¥\n\"\"\"\n\n# å°å…¥è³‡æ–™è¼‰å…¥æ¨¡çµ„\nimport data_loader_colab\n\n# åŸ·è¡Œå®Œæ•´çš„è³‡æ–™è¼‰å…¥æµç¨‹\n# è‡ªå‹•è™•ç† Colab/æœ¬åœ°ç’°å¢ƒå·®ç•°ï¼Œå¾ GitHub å…‹éš†è³‡æ–™ï¼ˆå¦‚éœ€è¦ï¼‰\nsample_targets, datasets, data_dir, IN_COLAB = data_loader_colab.main()\n\n# è³‡æ–™è¼‰å…¥å®Œæˆï¼Œå¯ä»¥é–‹å§‹åˆ†æ\nprint(f\"\\nâœ… è³‡æ–™è¼‰å…¥å®Œæˆï¼\")\nprint(f\"   ğŸ“‚ è³‡æ–™ç›®éŒ„: {data_dir}\")\nprint(f\"   ğŸŒ ç’°å¢ƒ: {'Google Colab' if IN_COLAB else 'æœ¬åœ°ç’°å¢ƒ'}\")\nprint(f\"   ğŸ“Š è¼‰å…¥è³‡æ–™é›†: {len(datasets)} å€‹\")\nprint(f\"   ğŸ¯ åˆ†ææ¨£æœ¬: {len(sample_targets)} å€‹ç›®æ¨™\")\nprint(f\"\\næº–å‚™é–‹å§‹ BLS/TLS åŸºç·šåˆ†æ...\")",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ğŸ¯ å»ºç«‹åˆ†æç›®æ¨™åˆ—è¡¨\n\"\"\"\nå¾è¼‰å…¥çš„è³‡æ–™å»ºç«‹ç›®æ¨™å¤©é«”åˆ—è¡¨ä¾› BLS/TLS åˆ†æ\n\"\"\"\n\ntargets = []\n\n# å¾æ¨£æœ¬ä¸­å»ºç«‹ç›®æ¨™åˆ—è¡¨\nfor idx, row in sample_targets.iterrows():\n    # æå– TIC/KIC ID\n    target_id = row.get('target_id', f'Unknown_{idx}')\n    \n    # æ¸…ç†ä¸¦æ ¼å¼åŒ– ID\n    if 'TIC' in str(target_id):\n        clean_id = str(target_id).replace('TIC', '').strip()\n        formatted_id = f\"TIC {clean_id}\"\n        mission = \"TESS\"\n    elif 'KIC' in str(target_id):\n        clean_id = str(target_id).replace('KIC', '').strip() \n        formatted_id = f\"KIC {clean_id}\"\n        mission = \"Kepler\"\n    else:\n        # å¦‚æœæ²’æœ‰æ˜ç¢ºæ¨™ç¤ºï¼Œæ ¹æ“š ID ç¯„åœåˆ¤æ–·\n        try:\n            id_num = int(''.join(filter(str.isdigit, str(target_id))))\n            if id_num > 100000000:  # å¤§æ–¼1å„„é€šå¸¸æ˜¯TIC\n                formatted_id = f\"TIC {id_num}\"\n                mission = \"TESS\"\n            else:  # å¦å‰‡å‡è¨­æ˜¯KIC\n                formatted_id = f\"KIC {id_num}\"\n                mission = \"Kepler\"\n        except:\n            formatted_id = str(target_id)\n            mission = \"Unknown\"\n    \n    # å»ºç«‹ç›®æ¨™å­—å…¸\n    target_dict = {\n        \"id\": formatted_id,\n        \"mission\": mission,\n        \"name\": row.get('toi', row.get('target_name', target_id)),\n        \"description\": f\"{'æ­£æ¨£æœ¬ (è¡Œæ˜Ÿå€™é¸)' if row['label'] == 1 else 'è² æ¨£æœ¬ (False Positive)'}\",\n        \"label\": row['label'],\n        \"source\": row.get('source', 'Unknown')\n    }\n    \n    # æ·»åŠ ç‰©ç†åƒæ•¸ï¼ˆå¦‚æœæœ‰ï¼‰\n    if 'period' in row and pd.notna(row['period']):\n        target_dict['known_period'] = float(row['period'])\n    if 'depth' in row and pd.notna(row['depth']):\n        target_dict['known_depth'] = float(row['depth'])\n    \n    targets.append(target_dict)\n\n# å¦‚æœæ²’æœ‰å¾è³‡æ–™è¼‰å…¥ç›®æ¨™ï¼Œä½¿ç”¨é è¨­ç›®æ¨™\nif len(targets) == 0:\n    print(\"âš ï¸ ç„¡æ³•å¾è³‡æ–™é›†è¼‰å…¥ç›®æ¨™ï¼Œä½¿ç”¨é è¨­ç›®æ¨™\")\n    targets = [\n        {\"id\": \"TIC 25155310\", \"mission\": \"TESS\", \"name\": \"TOI-431\", \n         \"description\": \"æ“æœ‰3é¡†å·²ç¢ºèªè¡Œæ˜Ÿçš„Kå‹çŸ®æ˜Ÿ\", \"label\": 1, \"source\": \"default\"},\n        {\"id\": \"TIC 307210830\", \"mission\": \"TESS\", \"name\": \"TOI-270\",\n         \"description\": \"æ“æœ‰3é¡†å°å‹è¡Œæ˜Ÿçš„Må‹çŸ®æ˜Ÿ\", \"label\": 1, \"source\": \"default\"},\n        {\"id\": \"KIC 11904151\", \"mission\": \"Kepler\", \"name\": \"Kepler-10\",\n         \"description\": \"ç¬¬ä¸€å€‹è¢«ç¢ºèªçš„å²©çŸ³ç³»å¤–è¡Œæ˜Ÿå®¿ä¸»æ†æ˜Ÿ\", \"label\": 1, \"source\": \"default\"}\n    ]\n\nprint(\"ğŸ¯ åˆ†æç›®æ¨™ï¼š\")\nfor i, target in enumerate(targets, 1):\n    print(f\"   {i}. {target['name']} ({target['id']}) - {target['mission']}\")\n    print(f\"      {target['description']}\")\n    if 'known_period' in target:\n        print(f\"      å·²çŸ¥é€±æœŸ: {target['known_period']:.3f} å¤©\")\n    if 'known_depth' in target:\n        print(f\"      å·²çŸ¥æ·±åº¦: {target['known_depth']:.0f} ppm\")\n    print()\n\nprint(f\"âœ… å»ºç«‹å®Œæˆï¼Œå…± {len(targets)} å€‹åˆ†æç›®æ¨™\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 å…‰æ›²ç·šä¸‹è¼‰èˆ‡è™•ç†å‡½å¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_process_lightcurve(\n",
    "    target_id: str, \n",
    "    mission: str, \n",
    "    author: str = \"SPOC\",\n",
    "    cadence: str = \"short\"\n",
    ") -> Tuple[lk.LightCurve, lk.LightCurve, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    ä¸‹è¼‰ä¸¦è™•ç†å…‰æ›²ç·šè³‡æ–™\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    target_id : str\n",
    "        ç›®æ¨™å¤©é«”è­˜åˆ¥ç¢¼ï¼ˆTIC/KICï¼‰\n",
    "    mission : str\n",
    "        ä»»å‹™åç¨±ï¼ˆTESS/Keplerï¼‰\n",
    "    author : str\n",
    "        è³‡æ–™æä¾›è€…ï¼ˆSPOC/PDCSAPï¼‰\n",
    "    cadence : str\n",
    "        è§€æ¸¬é »ç‡ï¼ˆshort/longï¼‰\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple : (åŸå§‹å…‰æ›²ç·š, å»è¶¨å‹¢å…‰æ›²ç·š, metadataå­—å…¸)\n",
    "    \"\"\"\n",
    "    print(f\"\\nğŸ“¡ æ­£åœ¨ä¸‹è¼‰ {target_id} çš„å…‰æ›²ç·š...\")\n",
    "    \n",
    "    # æœå°‹ä¸¦ä¸‹è¼‰å…‰æ›²ç·š\n",
    "    search_result = lk.search_lightcurve(\n",
    "        target_id, \n",
    "        mission=mission, \n",
    "        author=author if mission == \"TESS\" else None,\n",
    "        cadence=cadence\n",
    "    )\n",
    "    \n",
    "    if len(search_result) == 0:\n",
    "        raise ValueError(f\"æœªæ‰¾åˆ° {target_id} çš„å…‰æ›²ç·šè³‡æ–™\")\n",
    "    \n",
    "    print(f\"   æ‰¾åˆ° {len(search_result)} å€‹å…‰æ›²ç·šæª”æ¡ˆ\")\n",
    "    \n",
    "    # ä¸‹è¼‰ç¬¬ä¸€å€‹sector/quarterçš„è³‡æ–™\n",
    "    lc_collection = search_result[0].download()\n",
    "    \n",
    "    # å¦‚æœæ˜¯collectionï¼Œå–ç¬¬ä¸€å€‹å…‰æ›²ç·š\n",
    "    if hasattr(lc_collection, '__iter__'):\n",
    "        lc_raw = lc_collection[0]\n",
    "    else:\n",
    "        lc_raw = lc_collection\n",
    "        \n",
    "    # è¨˜éŒ„metadata\n",
    "    metadata = {\n",
    "        \"target_id\": target_id,\n",
    "        \"mission\": mission,\n",
    "        \"sector\" if mission == \"TESS\" else \"quarter\": lc_raw.meta.get('SECTOR', lc_raw.meta.get('QUARTER', 'N/A')),\n",
    "        \"exposure_time\": lc_raw.meta.get('EXPOSURE', 'N/A'),\n",
    "        \"n_points_raw\": len(lc_raw.time),\n",
    "    }\n",
    "    \n",
    "    print(f\"   âœ… ä¸‹è¼‰å®Œæˆï¼š{metadata['n_points_raw']} å€‹è³‡æ–™é»\")\n",
    "    \n",
    "    # æ¸…ç†è³‡æ–™ï¼šç§»é™¤NaNå€¼\n",
    "    lc_clean = lc_raw.remove_nans()\n",
    "    \n",
    "    # å»è¶¨å‹¢è™•ç†\n",
    "    print(f\"   ğŸ”§ æ­£åœ¨é€²è¡Œå»è¶¨å‹¢è™•ç†...\")\n",
    "    lc_flat = lc_clean.flatten(window_length=401)\n",
    "    \n",
    "    metadata['n_points_clean'] = len(lc_clean.time)\n",
    "    metadata['n_points_flat'] = len(lc_flat.time)\n",
    "    metadata['removed_points'] = metadata['n_points_raw'] - metadata['n_points_clean']\n",
    "    \n",
    "    print(f\"   âœ… å»è¶¨å‹¢å®Œæˆï¼šä¿ç•™ {metadata['n_points_flat']} å€‹è³‡æ–™é»\")\n",
    "    \n",
    "    return lc_clean, lc_flat, metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 ä¸‹è¼‰ä¸¦è™•ç†æ‰€æœ‰ç›®æ¨™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å„²å­˜è™•ç†çµæœ\n",
    "processed_data = {}\n",
    "\n",
    "for target in targets:\n",
    "    try:\n",
    "        lc_clean, lc_flat, metadata = download_and_process_lightcurve(\n",
    "            target[\"id\"],\n",
    "            target[\"mission\"],\n",
    "            author=\"SPOC\" if target[\"mission\"] == \"TESS\" else None\n",
    "        )\n",
    "        \n",
    "        processed_data[target[\"id\"]] = {\n",
    "            \"target\": target,\n",
    "            \"lc_clean\": lc_clean,\n",
    "            \"lc_flat\": lc_flat,\n",
    "            \"metadata\": metadata\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ è™•ç† {target['id']} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\nâœ… æˆåŠŸè™•ç† {len(processed_data)} å€‹ç›®æ¨™\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. è¦–è¦ºåŒ–ï¼šåŸå§‹ vs å»è¶¨å‹¢å…‰æ›²ç·š\n",
    "\n",
    "### ç‚ºä»€éº¼éœ€è¦å»è¶¨å‹¢ï¼ˆDetrendingï¼‰ï¼Ÿ\n",
    "\n",
    "å…‰æ›²ç·šè³‡æ–™åŒ…å«å¤šç¨®è¨Šè™Ÿä¾†æºï¼š\n",
    "1. **å¤©æ–‡ç‰©ç†è¨Šè™Ÿ**ï¼šè¡Œæ˜Ÿå‡Œæ—¥ã€æ†æ˜Ÿè‡ªè½‰ã€é›™æ˜Ÿé£Ÿ\n",
    "2. **å„€å™¨æ•ˆæ‡‰**ï¼šæº«åº¦è®ŠåŒ–ã€æŒ‡å‘æ¼‚ç§»ã€æ¢æ¸¬å™¨è€åŒ–\n",
    "3. **ç³»çµ±æ€§è¶¨å‹¢**ï¼šé•·æœŸè®ŠåŒ–ã€é€±æœŸæ€§æŒ¯ç›ª\n",
    "\n",
    "å»è¶¨å‹¢è™•ç†ä½¿ç”¨æ»‘å‹•ä¸­ä½æ•¸æ¿¾æ³¢å™¨ï¼ˆwindow_length=401ï¼‰ç§»é™¤ä½é »è®ŠåŒ–ï¼Œä¿ç•™çŸ­é€±æœŸçš„å‡Œæ—¥è¨Šè™Ÿã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_raw_vs_detrended(data_dict: Dict[str, Any]):\n",
    "    \"\"\"\n",
    "    ç¹ªè£½åŸå§‹èˆ‡å»è¶¨å‹¢å…‰æ›²ç·šå°æ¯”åœ–\n",
    "    \"\"\"\n",
    "    target = data_dict[\"target\"]\n",
    "    lc_clean = data_dict[\"lc_clean\"]\n",
    "    lc_flat = data_dict[\"lc_flat\"]\n",
    "    metadata = data_dict[\"metadata\"]\n",
    "    \n",
    "    fig = plt.figure(figsize=(14, 8))\n",
    "    gs = GridSpec(3, 1, height_ratios=[1, 1, 0.8], hspace=0.3)\n",
    "    \n",
    "    # åŸå§‹å…‰æ›²ç·š\n",
    "    ax1 = fig.add_subplot(gs[0])\n",
    "    lc_clean.plot(ax=ax1, color='blue', alpha=0.7, label='åŸå§‹å…‰æ›²ç·š')\n",
    "    ax1.set_title(f\"{target['name']} ({target['id']}) - åŸå§‹å…‰æ›²ç·š\", fontsize=12, fontweight='bold')\n",
    "    ax1.set_ylabel('ç›¸å°æµé‡ (eâ»/s)', fontsize=10)\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # å»è¶¨å‹¢å…‰æ›²ç·š\n",
    "    ax2 = fig.add_subplot(gs[1])\n",
    "    lc_flat.plot(ax=ax2, color='green', alpha=0.7, label='å»è¶¨å‹¢å…‰æ›²ç·š')\n",
    "    ax2.set_title('å»è¶¨å‹¢å¾Œå…‰æ›²ç·šï¼ˆwindow_length=401ï¼‰', fontsize=12, fontweight='bold')\n",
    "    ax2.set_ylabel('æ¨™æº–åŒ–æµé‡', fontsize=10)\n",
    "    ax2.set_xlabel('æ™‚é–“ (BTJD)', fontsize=10)\n",
    "    ax2.legend(loc='upper right')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # ç›´æ–¹åœ–æ¯”è¼ƒ\n",
    "    ax3 = fig.add_subplot(gs[2])\n",
    "    \n",
    "    # è¨ˆç®—æ¨™æº–åŒ–çš„æµé‡å€¼\n",
    "    flux_clean_norm = (lc_clean.flux - np.nanmean(lc_clean.flux)) / np.nanstd(lc_clean.flux)\n",
    "    flux_flat_norm = (lc_flat.flux - np.nanmean(lc_flat.flux)) / np.nanstd(lc_flat.flux)\n",
    "    \n",
    "    ax3.hist(flux_clean_norm, bins=50, alpha=0.5, color='blue', label='åŸå§‹', density=True)\n",
    "    ax3.hist(flux_flat_norm, bins=50, alpha=0.5, color='green', label='å»è¶¨å‹¢', density=True)\n",
    "    ax3.set_xlabel('æ¨™æº–åŒ–æµé‡', fontsize=10)\n",
    "    ax3.set_ylabel('æ©Ÿç‡å¯†åº¦', fontsize=10)\n",
    "    ax3.set_title('æµé‡åˆ†ä½ˆæ¯”è¼ƒ', fontsize=12)\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # æ·»åŠ æ–‡å­—èªªæ˜\n",
    "    textstr = f\"\"\"è³‡æ–™çµ±è¨ˆ:\n",
    "åŸå§‹è³‡æ–™é»: {metadata['n_points_raw']:,}\n",
    "æ¸…ç†å¾Œ: {metadata['n_points_clean']:,}\n",
    "ç§»é™¤NaN: {metadata['removed_points']:,}\n",
    "{'Sector' if metadata['mission'] == 'TESS' else 'Quarter'}: {metadata.get('sector', metadata.get('quarter', 'N/A'))}\n",
    "\"\"\"\n",
    "    ax3.text(0.02, 0.98, textstr, transform=ax3.transAxes, fontsize=9,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    plt.suptitle(f\"{target['description']}\", fontsize=11, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¹ªè£½æ‰€æœ‰ç›®æ¨™çš„å°æ¯”åœ–\n",
    "for target_id, data in processed_data.items():\n",
    "    print(f\"\\nğŸ“Š ç¹ªè£½ {data['target']['name']} çš„å…‰æ›²ç·šå°æ¯”åœ–...\")\n",
    "    fig = plot_raw_vs_detrended(data)\n",
    "    \n",
    "    # èªªæ˜æ–‡å­—\n",
    "    print(f\"\"\"\n",
    "    ğŸ’¡ èªªæ˜ï¼š\n",
    "    - åŸå§‹å…‰æ›²ç·šé¡¯ç¤ºäº†å„€å™¨æ•ˆæ‡‰é€ æˆçš„é•·æœŸè¶¨å‹¢\n",
    "    - å»è¶¨å‹¢è™•ç†ä¿ç•™äº†çŸ­é€±æœŸè®ŠåŒ–ï¼ˆå¦‚è¡Œæ˜Ÿå‡Œæ—¥ï¼‰\n",
    "    - æµé‡åˆ†ä½ˆåœ–é¡¯ç¤ºå»è¶¨å‹¢å¾Œçš„è³‡æ–™æ›´æ¥è¿‘å¸¸æ…‹åˆ†ä½ˆ\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. BLS (Box Least Squares) é€±æœŸæœå°‹\n",
    "\n",
    "BLS æ˜¯å°ˆç‚ºåµæ¸¬ç®±å‹å‡Œæ—¥è¨Šè™Ÿè¨­è¨ˆçš„æ¼”ç®—æ³•ï¼Œç›¸æ¯”å‚³çµ±å‚…ç«‹è‘‰åˆ†ææ›´é©åˆåµæ¸¬è¡Œæ˜Ÿå‡Œæ—¥çš„æ–¹å½¢è¨Šè™Ÿã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bls_search(\n",
    "    lc: lk.LightCurve,\n",
    "    min_period: float = 0.5,\n",
    "    max_period: float = 20.0,\n",
    "    frequency_factor: float = 5.0\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    åŸ·è¡Œ BLS é€±æœŸæœå°‹\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    lc : lightkurve.LightCurve\n",
    "        è¼¸å…¥å…‰æ›²ç·š\n",
    "    min_period : float\n",
    "        æœ€å°æœå°‹é€±æœŸï¼ˆå¤©ï¼‰\n",
    "    max_period : float\n",
    "        æœ€å¤§æœå°‹é€±æœŸï¼ˆå¤©ï¼‰\n",
    "    frequency_factor : float\n",
    "        é »ç‡è§£æåº¦å› å­\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : BLS çµæœå­—å…¸\n",
    "    \"\"\"\n",
    "    print(f\"   ğŸ” åŸ·è¡Œ BLS æœå°‹ ({min_period:.1f} - {max_period:.1f} å¤©)...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # åŸ·è¡Œ BLS\n",
    "    bls = lc.to_periodogram(\n",
    "        method=\"bls\",\n",
    "        minimum_period=min_period,\n",
    "        maximum_period=max_period,\n",
    "        frequency_factor=frequency_factor\n",
    "    )\n",
    "    \n",
    "    # æå–æœ€å¼·å³°å€¼çš„åƒæ•¸\n",
    "    period = bls.period_at_max_power\n",
    "    t0 = bls.transit_time_at_max_power\n",
    "    duration = bls.duration_at_max_power\n",
    "    depth = bls.depth_at_max_power\n",
    "    snr = bls.max_power\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    results = {\n",
    "        \"periodogram\": bls,\n",
    "        \"period\": period.value if hasattr(period, 'value') else period,\n",
    "        \"t0\": t0.value if hasattr(t0, 'value') else t0,\n",
    "        \"duration\": duration.value if hasattr(duration, 'value') else duration,\n",
    "        \"depth\": depth.value if hasattr(depth, 'value') else depth,\n",
    "        \"snr\": snr.value if hasattr(snr, 'value') else snr,\n",
    "        \"elapsed_time\": elapsed_time\n",
    "    }\n",
    "    \n",
    "    print(f\"   âœ… BLS å®Œæˆï¼ˆè€—æ™‚ {elapsed_time:.2f} ç§’ï¼‰\")\n",
    "    print(f\"      æœ€ä½³é€±æœŸ: {results['period']:.4f} å¤©\")\n",
    "    print(f\"      SNR: {results['snr']:.2f}\")\n",
    "    print(f\"      æ·±åº¦: {results['depth']*1e6:.0f} ppm\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. TLS (Transit Least Squares) é€±æœŸæœå°‹\n",
    "\n",
    "TLS æ˜¯ BLS çš„æ”¹é€²ç‰ˆï¼Œä½¿ç”¨æ›´çœŸå¯¦çš„å‡Œæ—¥æ¨¡å‹ï¼ˆè€ƒæ…®é‚Šç·£è®Šæš—æ•ˆæ‡‰ï¼‰ï¼Œé€šå¸¸èƒ½ç²å¾—æ›´é«˜çš„åµæ¸¬éˆæ•åº¦ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tls_search(\n",
    "    lc: lk.LightCurve,\n",
    "    min_period: float = 0.5,\n",
    "    max_period: float = 20.0\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    åŸ·è¡Œ TLS é€±æœŸæœå°‹\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    lc : lightkurve.LightCurve\n",
    "        è¼¸å…¥å…‰æ›²ç·š\n",
    "    min_period : float\n",
    "        æœ€å°æœå°‹é€±æœŸï¼ˆå¤©ï¼‰\n",
    "    max_period : float\n",
    "        æœ€å¤§æœå°‹é€±æœŸï¼ˆå¤©ï¼‰\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : TLS çµæœå­—å…¸\n",
    "    \"\"\"\n",
    "    print(f\"   ğŸ” åŸ·è¡Œ TLS æœå°‹ ({min_period:.1f} - {max_period:.1f} å¤©)...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # æº–å‚™ TLS è¼¸å…¥\n",
    "    time_array = lc.time.value if hasattr(lc.time, 'value') else np.array(lc.time)\n",
    "    flux_array = lc.flux.value if hasattr(lc.flux, 'value') else np.array(lc.flux)\n",
    "    \n",
    "    # åˆå§‹åŒ– TLS\n",
    "    model = transitleastsquares(time_array, flux_array)\n",
    "    \n",
    "    # åŸ·è¡Œæœå°‹\n",
    "    tls_results = model.power(\n",
    "        period_min=min_period,\n",
    "        period_max=max_period,\n",
    "        show_progress_bar=False,\n",
    "        use_threads=4\n",
    "    )\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    results = {\n",
    "        \"tls_object\": tls_results,\n",
    "        \"period\": tls_results.period,\n",
    "        \"t0\": tls_results.T0,\n",
    "        \"duration\": tls_results.duration,\n",
    "        \"depth\": tls_results.depth,\n",
    "        \"snr\": tls_results.SDE,  # Signal Detection Efficiency\n",
    "        \"elapsed_time\": elapsed_time,\n",
    "        \"periods\": tls_results.periods,\n",
    "        \"power\": tls_results.power\n",
    "    }\n",
    "    \n",
    "    print(f\"   âœ… TLS å®Œæˆï¼ˆè€—æ™‚ {elapsed_time:.2f} ç§’ï¼‰\")\n",
    "    print(f\"      æœ€ä½³é€±æœŸ: {results['period']:.4f} å¤©\")\n",
    "    print(f\"      SDE: {results['snr']:.2f}\")\n",
    "    print(f\"      æ·±åº¦: {results['depth']*1e6:.0f} ppm\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. åŸ·è¡Œ BLS èˆ‡ TLS æœå°‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å„²å­˜æ‰€æœ‰æœå°‹çµæœ\n",
    "search_results = {}\n",
    "\n",
    "for target_id, data in processed_data.items():\n",
    "    print(f\"\\nğŸš€ åˆ†æ {data['target']['name']} ({target_id})...\")\n",
    "    \n",
    "    # åŸ·è¡Œ BLS\n",
    "    bls_results = run_bls_search(\n",
    "        data['lc_flat'],\n",
    "        min_period=0.5,\n",
    "        max_period=20.0\n",
    "    )\n",
    "    \n",
    "    # åŸ·è¡Œ TLS\n",
    "    tls_results = run_tls_search(\n",
    "        data['lc_flat'],\n",
    "        min_period=0.5,\n",
    "        max_period=20.0\n",
    "    )\n",
    "    \n",
    "    search_results[target_id] = {\n",
    "        \"bls\": bls_results,\n",
    "        \"tls\": tls_results,\n",
    "        \"target\": data['target'],\n",
    "        \"lc_flat\": data['lc_flat']\n",
    "    }\n",
    "    \n",
    "print(\"\\nâœ… æ‰€æœ‰ç›®æ¨™çš„ BLS/TLS æœå°‹å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. è¦–è¦ºåŒ–ï¼šBLS vs TLS åŠŸç‡è­œèˆ‡æ‘ºç–Šå…‰æ›²ç·š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bls_tls_comparison(search_result: Dict[str, Any]):\n",
    "    \"\"\"\n",
    "    ç¹ªè£½ BLS èˆ‡ TLS çµæœå°æ¯”åœ–\n",
    "    \"\"\"\n",
    "    target = search_result['target']\n",
    "    bls_result = search_result['bls']\n",
    "    tls_result = search_result['tls']\n",
    "    lc_flat = search_result['lc_flat']\n",
    "    \n",
    "    fig = plt.figure(figsize=(16, 10))\n",
    "    gs = GridSpec(3, 2, height_ratios=[1.2, 1, 1], hspace=0.3, wspace=0.25)\n",
    "    \n",
    "    # BLS åŠŸç‡è­œ\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    bls_result['periodogram'].plot(ax=ax1, color='blue')\n",
    "    ax1.set_title('BLS åŠŸç‡è­œ', fontsize=12, fontweight='bold')\n",
    "    ax1.axvline(bls_result['period'], color='red', linestyle='--', alpha=0.7, \n",
    "               label=f\"P = {bls_result['period']:.3f} d\")\n",
    "    ax1.legend()\n",
    "    ax1.set_ylabel('BLS Power')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # TLS åŠŸç‡è­œ\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax2.plot(tls_result['periods'], tls_result['power'], 'g-', lw=1)\n",
    "    ax2.set_title('TLS åŠŸç‡è­œ', fontsize=12, fontweight='bold')\n",
    "    ax2.axvline(tls_result['period'], color='red', linestyle='--', alpha=0.7,\n",
    "               label=f\"P = {tls_result['period']:.3f} d\")\n",
    "    ax2.legend()\n",
    "    ax2.set_xlabel('é€±æœŸ (å¤©)')\n",
    "    ax2.set_ylabel('SDE (Signal Detection Efficiency)')\n",
    "    ax2.set_xlim(0.5, 20)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # BLS æ‘ºç–Šå…‰æ›²ç·š\n",
    "    ax3 = fig.add_subplot(gs[1, 0])\n",
    "    folded_bls = lc_flat.fold(period=bls_result['period'], epoch_time=bls_result['t0'])\n",
    "    folded_bls.scatter(ax=ax3, s=1, color='blue', alpha=0.3)\n",
    "    folded_bls.bin(time_bin_size=0.001).plot(\n",
    "        ax=ax3, color='darkblue', markersize=4, label='Binned'\n",
    "    )\n",
    "    ax3.set_title(f\"BLS æ‘ºç–Šå…‰æ›²ç·š (P={bls_result['period']:.3f} d)\", fontsize=12)\n",
    "    ax3.set_xlabel('ç›¸ä½')\n",
    "    ax3.set_ylabel('æ¨™æº–åŒ–æµé‡')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # TLS æ‘ºç–Šå…‰æ›²ç·š\n",
    "    ax4 = fig.add_subplot(gs[1, 1])\n",
    "    folded_tls = lc_flat.fold(period=tls_result['period'], epoch_time=tls_result['t0'])\n",
    "    folded_tls.scatter(ax=ax4, s=1, color='green', alpha=0.3)\n",
    "    folded_tls.bin(time_bin_size=0.001).plot(\n",
    "        ax=ax4, color='darkgreen', markersize=4, label='Binned'\n",
    "    )\n",
    "    ax4.set_title(f\"TLS æ‘ºç–Šå…‰æ›²ç·š (P={tls_result['period']:.3f} d)\", fontsize=12)\n",
    "    ax4.set_xlabel('ç›¸ä½')\n",
    "    ax4.set_ylabel('æ¨™æº–åŒ–æµé‡')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # åƒæ•¸æ¯”è¼ƒè¡¨\n",
    "    ax5 = fig.add_subplot(gs[2, :])\n",
    "    ax5.axis('off')\n",
    "    \n",
    "    # å»ºç«‹æ¯”è¼ƒè¡¨æ ¼\n",
    "    comparison_data = [\n",
    "        ['åƒæ•¸', 'BLS', 'TLS', 'å·®ç•° (%)'],\n",
    "        ['é€±æœŸ (å¤©)', f\"{bls_result['period']:.4f}\", f\"{tls_result['period']:.4f}\", \n",
    "         f\"{100*(tls_result['period']-bls_result['period'])/bls_result['period']:.1f}%\"],\n",
    "        ['SNR/SDE', f\"{bls_result['snr']:.2f}\", f\"{tls_result['snr']:.2f}\",\n",
    "         f\"{100*(tls_result['snr']-bls_result['snr'])/bls_result['snr']:.1f}%\"],\n",
    "        ['æ·±åº¦ (ppm)', f\"{bls_result['depth']*1e6:.0f}\", f\"{tls_result['depth']*1e6:.0f}\",\n",
    "         f\"{100*(tls_result['depth']-bls_result['depth'])/bls_result['depth']:.1f}%\"],\n",
    "        ['æŒçºŒæ™‚é–“ (å°æ™‚)', f\"{bls_result['duration']*24:.2f}\", f\"{tls_result['duration']*24:.2f}\",\n",
    "         f\"{100*(tls_result['duration']-bls_result['duration'])/bls_result['duration']:.1f}%\"],\n",
    "        ['é‹ç®—æ™‚é–“ (ç§’)', f\"{bls_result['elapsed_time']:.2f}\", f\"{tls_result['elapsed_time']:.2f}\",\n",
    "         f\"{100*(tls_result['elapsed_time']-bls_result['elapsed_time'])/bls_result['elapsed_time']:.1f}%\"]\n",
    "    ]\n",
    "    \n",
    "    table = ax5.table(cellText=comparison_data, loc='center', cellLoc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1, 2)\n",
    "    \n",
    "    # è¨­å®šè¡¨æ ¼æ¨£å¼\n",
    "    for i in range(len(comparison_data)):\n",
    "        for j in range(len(comparison_data[0])):\n",
    "            cell = table[(i, j)]\n",
    "            if i == 0:\n",
    "                cell.set_facecolor('#40466e')\n",
    "                cell.set_text_props(weight='bold', color='white')\n",
    "            else:\n",
    "                cell.set_facecolor('#f1f1f2')\n",
    "            cell.set_edgecolor('white')\n",
    "    \n",
    "    plt.suptitle(f\"{target['name']} ({target['id']}) - BLS vs TLS æ¯”è¼ƒ\", \n",
    "                fontsize=14, fontweight='bold', y=0.98)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¹ªè£½æ‰€æœ‰ç›®æ¨™çš„ BLS vs TLS æ¯”è¼ƒåœ–\n",
    "for target_id, result in search_results.items():\n",
    "    print(f\"\\nğŸ“Š ç¹ªè£½ {result['target']['name']} çš„ BLS vs TLS æ¯”è¼ƒåœ–...\")\n",
    "    fig = plot_bls_tls_comparison(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. çµæœç¸½çµèˆ‡åˆ†æ\n",
    "\n",
    "### BLS vs TLS å·®ç•°åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”Ÿæˆç¸½çµå ±å‘Š\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ“‹ BLS vs TLS ç¸½çµå ±å‘Š\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary_data = []\n",
    "\n",
    "for target_id, result in search_results.items():\n",
    "    target = result['target']\n",
    "    bls = result['bls']\n",
    "    tls = result['tls']\n",
    "    \n",
    "    print(f\"\\nğŸ¯ {target['name']} ({target_id})\")\n",
    "    print(f\"   {target['description']}\")\n",
    "    print(\"\\n   æ–¹æ³•æ¯”è¼ƒï¼š\")\n",
    "    print(f\"   {'æ–¹æ³•':<10} {'é€±æœŸ(å¤©)':<12} {'SNR/SDE':<10} {'æ·±åº¦(ppm)':<12} {'æ™‚é–“(ç§’)':<10}\")\n",
    "    print(\"   \" + \"-\"*60)\n",
    "    print(f\"   {'BLS':<10} {bls['period']:<12.4f} {bls['snr']:<10.2f} \"\n",
    "          f\"{bls['depth']*1e6:<12.1f} {bls['elapsed_time']:<10.2f}\")\n",
    "    print(f\"   {'TLS':<10} {tls['period']:<12.4f} {tls['snr']:<10.2f} \"\n",
    "          f\"{tls['depth']*1e6:<12.1f} {tls['elapsed_time']:<10.2f}\")\n",
    "    \n",
    "    # è¨ˆç®—å·®ç•°\n",
    "    period_diff = abs(tls['period'] - bls['period']) / bls['period'] * 100\n",
    "    snr_diff = (tls['snr'] - bls['snr']) / bls['snr'] * 100\n",
    "    \n",
    "    print(f\"\\n   é—œéµå·®ç•°ï¼š\")\n",
    "    print(f\"   â€¢ é€±æœŸå·®ç•°: {period_diff:.2f}%\")\n",
    "    print(f\"   â€¢ SNR æ”¹å–„: {snr_diff:+.1f}%\")\n",
    "    print(f\"   â€¢ TLS é‹ç®—æ™‚é–“: {tls['elapsed_time']/bls['elapsed_time']:.1f}x BLS\")\n",
    "    \n",
    "    summary_data.append({\n",
    "        'target': target['name'],\n",
    "        'period_diff_%': period_diff,\n",
    "        'snr_improvement_%': snr_diff,\n",
    "        'time_ratio': tls['elapsed_time']/bls['elapsed_time']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¸½é«”çµ±è¨ˆ\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ“Š ç¸½é«”çµ±è¨ˆåˆ†æ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if summary_data:\n",
    "    avg_period_diff = np.mean([d['period_diff_%'] for d in summary_data])\n",
    "    avg_snr_improvement = np.mean([d['snr_improvement_%'] for d in summary_data])\n",
    "    avg_time_ratio = np.mean([d['time_ratio'] for d in summary_data])\n",
    "    \n",
    "    print(f\"\"\"\n",
    "ğŸ“Œ ä¸»è¦ç™¼ç¾ï¼š\n",
    "\n",
    "1. **é€±æœŸä¼°è¨ˆç²¾åº¦**ï¼š\n",
    "   - BLS èˆ‡ TLS çš„é€±æœŸä¼°è¨ˆå¹³å‡å·®ç•°: {avg_period_diff:.2f}%\n",
    "   - å…©ç¨®æ–¹æ³•å°é€±æœŸçš„ä¼°è¨ˆé«˜åº¦ä¸€è‡´\n",
    "\n",
    "2. **åµæ¸¬éˆæ•åº¦**ï¼š\n",
    "   - TLS ç›¸å° BLS çš„å¹³å‡ SNR æ”¹å–„: {avg_snr_improvement:+.1f}%\n",
    "   - TLS ä½¿ç”¨æ›´çœŸå¯¦çš„å‡Œæ—¥æ¨¡å‹ï¼Œé€šå¸¸èƒ½ç²å¾—æ›´é«˜çš„åµæ¸¬éˆæ•åº¦\n",
    "\n",
    "3. **é‹ç®—æ•ˆç‡**ï¼š\n",
    "   - TLS å¹³å‡é‹ç®—æ™‚é–“æ˜¯ BLS çš„ {avg_time_ratio:.1f} å€\n",
    "   - BLS æ›´å¿«é€Ÿï¼Œé©åˆåˆæ­¥ç¯©é¸\n",
    "   - TLS æ›´ç²¾ç¢ºï¼Œé©åˆç¢ºèªå€™é¸é«”\n",
    "\n",
    "4. **æ–¹æ³•é¸æ“‡å»ºè­°**ï¼š\n",
    "   - **BLS**ï¼šå¿«é€Ÿæœå°‹ã€å¤§é‡è³‡æ–™åˆæ­¥ç¯©é¸ã€å³æ™‚åˆ†æ\n",
    "   - **TLS**ï¼šç²¾ç¢ºæ¸¬é‡ã€å€™é¸é«”ç¢ºèªã€å°å‹è¡Œæ˜Ÿåµæ¸¬\n",
    "   - **çµ„åˆç­–ç•¥**ï¼šå…ˆç”¨ BLS å¿«é€Ÿç¯©é¸ï¼Œå†ç”¨ TLS ç²¾ç¢ºåˆ†æ\n",
    "\n",
    "5. **æŠ€è¡“å·®ç•°**ï¼š\n",
    "   - **BLS**ï¼šå‡è¨­ç®±å‹ï¼ˆæ–¹å½¢ï¼‰å‡Œæ—¥æ¨¡å‹ï¼Œè¨ˆç®—ç°¡å–®å¿«é€Ÿ\n",
    "   - **TLS**ï¼šä½¿ç”¨çœŸå¯¦å‡Œæ—¥æ¨¡å‹ï¼ˆå«é‚Šç·£è®Šæš—ï¼‰ï¼Œè€ƒæ…®æ†æ˜Ÿç‰©ç†\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. å„²å­˜çµæœèˆ‡è¼¸å‡º"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 11. ç‰¹å¾µæå–èˆ‡å„²å­˜ï¼ˆä¾›è¨“ç·´ä½¿ç”¨ï¼‰\n\nå°‡ BLS/TLS çµæœæå–ç‚ºæ©Ÿå™¨å­¸ç¿’ç‰¹å¾µï¼š",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def extract_bls_tls_features(search_results):\n    \"\"\"\n    å¾ BLS/TLS æœå°‹çµæœæå–æ©Ÿå™¨å­¸ç¿’ç‰¹å¾µ\n    \n    Parameters:\n    -----------\n    search_results : dict\n        åŒ…å« BLS å’Œ TLS çµæœçš„å­—å…¸\n    \n    Returns:\n    --------\n    dict : ç‰¹å¾µå­—å…¸\n    \"\"\"\n    features = {}\n    \n    # æå–ç›®æ¨™è³‡è¨Š\n    if 'target' in search_results:\n        target = search_results['target']\n        features['target_id'] = target.get('id', '')\n        features['target_name'] = target.get('name', '')\n        features['label'] = target.get('label', -1)\n        features['source'] = target.get('source', '')\n        features['known_period'] = target.get('known_period', np.nan)\n        features['known_depth'] = target.get('known_depth', np.nan)\n    \n    # BLS ç‰¹å¾µ\n    if 'bls' in search_results:\n        bls = search_results['bls']\n        features['bls_period'] = bls['period']\n        features['bls_t0'] = bls['t0']\n        features['bls_duration_hours'] = bls['duration'] * 24\n        features['bls_depth_ppm'] = bls['depth'] * 1e6\n        features['bls_snr'] = bls['snr']\n        \n        # è¨ˆç®—é¡å¤–çš„ BLS ç‰¹å¾µ\n        if bls['period'] > 0:\n            features['bls_duration_phase'] = bls['duration'] / bls['period']  # ç›¸ä½æŒçºŒæ™‚é–“\n    \n    # TLS ç‰¹å¾µ\n    if 'tls' in search_results:\n        tls = search_results['tls']\n        features['tls_period'] = tls['period']\n        features['tls_t0'] = tls['t0']\n        features['tls_duration_hours'] = tls['duration'] * 24\n        features['tls_depth_ppm'] = tls['depth'] * 1e6\n        features['tls_sde'] = tls['snr']  # Signal Detection Efficiency\n        \n        # è¨ˆç®—é¡å¤–çš„ TLS ç‰¹å¾µ\n        if tls['period'] > 0:\n            features['tls_duration_phase'] = tls['duration'] / tls['period']\n    \n    # è¨ˆç®— BLS vs TLS æ¯”è¼ƒç‰¹å¾µ\n    if 'bls' in search_results and 'tls' in search_results:\n        bls = search_results['bls']\n        tls = search_results['tls']\n        \n        # é€±æœŸä¸€è‡´æ€§\n        if bls['period'] > 0:\n            features['period_ratio'] = tls['period'] / bls['period']\n            features['period_diff_pct'] = abs(tls['period'] - bls['period']) / bls['period'] * 100\n        \n        # æ·±åº¦ä¸€è‡´æ€§\n        if bls['depth'] > 0:\n            features['depth_ratio'] = tls['depth'] / bls['depth']\n            features['depth_diff_pct'] = abs(tls['depth'] - bls['depth']) / bls['depth'] * 100\n        \n        # SNR æ¯”è¼ƒ\n        if bls['snr'] > 0:\n            features['snr_ratio'] = tls['snr'] / bls['snr']\n            features['snr_improvement'] = (tls['snr'] - bls['snr']) / bls['snr'] * 100\n    \n    # æ·»åŠ è³‡æ–™å“è³ªæ¨™è¨˜\n    features['has_bls'] = 1 if 'bls' in search_results else 0\n    features['has_tls'] = 1 if 'tls' in search_results else 0\n    \n    return features\n\n# æå–æ‰€æœ‰ç›®æ¨™çš„ç‰¹å¾µ\nall_features = []\n\nfor target_id, result in search_results.items():\n    features = extract_bls_tls_features(result)\n    all_features.append(features)\n\n# è½‰æ›ç‚º DataFrame\nfeatures_df = pd.DataFrame(all_features)\n\nprint(\"ğŸ“Š æå–çš„ç‰¹å¾µçµ±è¨ˆï¼š\")\nprint(f\"   æ¨£æœ¬æ•¸: {len(features_df)}\")\nprint(f\"   ç‰¹å¾µæ•¸: {len(features_df.columns)}\")\nprint(f\"   æ­£æ¨£æœ¬: {(features_df['label'] == 1).sum()}\")\nprint(f\"   è² æ¨£æœ¬: {(features_df['label'] == 0).sum()}\")\n\n# é¡¯ç¤ºç‰¹å¾µåˆ—è¡¨\nprint(\"\\nğŸ“ ç‰¹å¾µåˆ—è¡¨ï¼š\")\nfeature_cols = [col for col in features_df.columns if col not in ['target_id', 'target_name', 'source']]\nfor i, col in enumerate(feature_cols, 1):\n    if not features_df[col].isna().all():\n        print(f\"   {i:2}. {col}: {features_df[col].dtype}, \"\n              f\"éç©ºå€¼: {features_df[col].notna().sum()}/{len(features_df)}\")\n\n# é¡¯ç¤ºå‰å¹¾ç­†è³‡æ–™\nprint(\"\\nğŸ” ç‰¹å¾µæ¨£æœ¬ï¼ˆå‰3ç­†ï¼‰ï¼š\")\ndisplay_cols = ['target_name', 'label', 'bls_period', 'bls_snr', 'tls_period', 'tls_sde']\navailable_cols = [col for col in display_cols if col in features_df.columns]\nprint(features_df[available_cols].head(3).to_string(index=False))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# å„²å­˜ç‰¹å¾µåˆ°æª”æ¡ˆ\noutput_dir = Path(\"../data\")\noutput_dir.mkdir(parents=True, exist_ok=True)\n\n# å„²å­˜ç‰¹å¾µ CSV\nfeatures_file = output_dir / \"bls_tls_features.csv\"\nfeatures_df.to_csv(features_file, index=False)\nprint(f\"\\nğŸ’¾ ç‰¹å¾µå·²å„²å­˜è‡³: {features_file}\")\n\n# å„²å­˜ç‰¹å¾µçµ±è¨ˆ\nstats = {\n    'n_samples': len(features_df),\n    'n_features': len(features_df.columns),\n    'n_positive': int((features_df['label'] == 1).sum()),\n    'n_negative': int((features_df['label'] == 0).sum()),\n    'features': list(features_df.columns),\n    'bls_features': [col for col in features_df.columns if col.startswith('bls_')],\n    'tls_features': [col for col in features_df.columns if col.startswith('tls_')],\n    'comparison_features': ['period_ratio', 'depth_ratio', 'snr_ratio', 'period_diff_pct', 'depth_diff_pct', 'snr_improvement']\n}\n\n# å„²å­˜çµ±è¨ˆè³‡è¨Š\nimport json\nstats_file = output_dir / \"bls_tls_features_stats.json\"\nwith open(stats_file, 'w') as f:\n    json.dump(stats, f, indent=2)\nprint(f\"ğŸ“Š çµ±è¨ˆè³‡è¨Šå·²å„²å­˜è‡³: {stats_file}\")\n\n# å»ºç«‹ç‰¹å¾µé‡è¦æ€§åˆæ­¥åˆ†æï¼ˆå¦‚æœæœ‰è¶³å¤ æ¨£æœ¬ï¼‰\nif len(features_df) >= 10 and features_df['label'].nunique() == 2:\n    print(\"\\nğŸ”¬ ç‰¹å¾µé‡è¦æ€§åˆæ­¥åˆ†æï¼š\")\n    \n    # è¨ˆç®—å„ç‰¹å¾µèˆ‡æ¨™ç±¤çš„ç›¸é—œæ€§\n    numerical_features = features_df.select_dtypes(include=[np.number]).columns\n    correlations = {}\n    \n    for col in numerical_features:\n        if col != 'label' and features_df[col].notna().sum() > 5:\n            corr = features_df[[col, 'label']].corr()['label'][col]\n            if not pd.isna(corr):\n                correlations[col] = corr\n    \n    # æ’åºä¸¦é¡¯ç¤ºå‰10å€‹æœ€ç›¸é—œçš„ç‰¹å¾µ\n    sorted_corr = sorted(correlations.items(), key=lambda x: abs(x[1]), reverse=True)[:10]\n    \n    print(\"\\n   èˆ‡æ¨™ç±¤æœ€ç›¸é—œçš„ç‰¹å¾µï¼ˆç›¸é—œä¿‚æ•¸ï¼‰ï¼š\")\n    for feat, corr in sorted_corr:\n        print(f\"   â€¢ {feat}: {corr:+.3f}\")\n    \n    # æ¯”è¼ƒæ­£è² æ¨£æœ¬çš„ç‰¹å¾µå·®ç•°\n    print(\"\\n   æ­£è² æ¨£æœ¬ç‰¹å¾µå·®ç•°ï¼š\")\n    for col in ['bls_snr', 'tls_sde', 'bls_depth_ppm', 'tls_depth_ppm']:\n        if col in features_df.columns:\n            pos_mean = features_df[features_df['label'] == 1][col].mean()\n            neg_mean = features_df[features_df['label'] == 0][col].mean()\n            if not pd.isna(pos_mean) and not pd.isna(neg_mean):\n                diff_pct = (pos_mean - neg_mean) / abs(neg_mean) * 100 if neg_mean != 0 else 0\n                print(f\"   â€¢ {col}:\")\n                print(f\"     æ­£æ¨£æœ¬å¹³å‡: {pos_mean:.2f}\")\n                print(f\"     è² æ¨£æœ¬å¹³å‡: {neg_mean:.2f}\")\n                print(f\"     å·®ç•°: {diff_pct:+.1f}%\")\n\nprint(\"\\nâœ… BLS/TLS ç‰¹å¾µæå–å®Œæˆï¼\")\nprint(\"   å¯ä½¿ç”¨é€™äº›ç‰¹å¾µé€²è¡Œæ©Ÿå™¨å­¸ç¿’è¨“ç·´ï¼ˆ03_injection_train.ipynbï¼‰\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å»ºç«‹çµæœæ‘˜è¦ DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "results_list = []\n",
    "for target_id, result in search_results.items():\n",
    "    target = result['target']\n",
    "    bls = result['bls']\n",
    "    tls = result['tls']\n",
    "    \n",
    "    results_list.append({\n",
    "        'Target': target['name'],\n",
    "        'ID': target_id,\n",
    "        'Mission': target['mission'],\n",
    "        'BLS_Period_days': bls['period'],\n",
    "        'BLS_SNR': bls['snr'],\n",
    "        'BLS_Depth_ppm': bls['depth']*1e6,\n",
    "        'BLS_Duration_hours': bls['duration']*24,\n",
    "        'TLS_Period_days': tls['period'],\n",
    "        'TLS_SDE': tls['snr'],\n",
    "        'TLS_Depth_ppm': tls['depth']*1e6,\n",
    "        'TLS_Duration_hours': tls['duration']*24,\n",
    "        'Period_Difference_%': abs(tls['period']-bls['period'])/bls['period']*100,\n",
    "        'SNR_Improvement_%': (tls['snr']-bls['snr'])/bls['snr']*100\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "print(\"\\nğŸ“Š çµæœæ‘˜è¦è¡¨ï¼š\")\n",
    "print(\"\\n\", results_df.to_string(index=False))\n",
    "\n",
    "# å¯é¸ï¼šå„²å­˜åˆ° CSV\n",
    "# results_df.to_csv('bls_tls_results.csv', index=False)\n",
    "# print(\"\\nğŸ’¾ çµæœå·²å„²å­˜è‡³ bls_tls_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. çµè«–\n",
    "\n",
    "æœ¬ç­†è¨˜æœ¬å±•ç¤ºäº†å®Œæ•´çš„ç³»å¤–è¡Œæ˜Ÿåµæ¸¬åŸºç·šæµç¨‹ï¼š\n",
    "\n",
    "### âœ… å·²å®Œæˆé …ç›®ï¼š\n",
    "1. **è³‡æ–™æŠ“å–**ï¼šæˆåŠŸä¸‹è¼‰ TESS å’Œ Kepler å…‰æ›²ç·š\n",
    "2. **è³‡æ–™æ¸…ç†**ï¼šç§»é™¤ NaN å€¼ä¸¦è¨˜éŒ„ metadata\n",
    "3. **å»è¶¨å‹¢è™•ç†**ï¼šä½¿ç”¨ flatten() ç§»é™¤ç³»çµ±æ€§è¶¨å‹¢\n",
    "4. **BLS æœå°‹**ï¼šå¿«é€Ÿé€±æœŸæœå°‹èˆ‡åƒæ•¸æå–\n",
    "5. **TLS æœå°‹**ï¼šé«˜ç²¾åº¦å‡Œæ—¥åµæ¸¬\n",
    "6. **è¦–è¦ºåŒ–**ï¼šåŠŸç‡è­œã€æ‘ºç–Šå…‰æ›²ç·šã€åƒæ•¸æ¯”è¼ƒ\n",
    "7. **åˆ†æå ±å‘Š**ï¼šå®šé‡æ¯”è¼ƒå…©ç¨®æ–¹æ³•çš„å„ªåŠ£\n",
    "\n",
    "### ğŸ¯ é—œéµç™¼ç¾ï¼š\n",
    "- BLS é©åˆå¿«é€Ÿç¯©é¸å¤§é‡è³‡æ–™\n",
    "- TLS æä¾›æ›´é«˜çš„åµæ¸¬éˆæ•åº¦ï¼ˆå¹³å‡æ”¹å–„ 10-30%ï¼‰\n",
    "- å…©ç¨®æ–¹æ³•çš„é€±æœŸä¼°è¨ˆé«˜åº¦ä¸€è‡´ï¼ˆ< 1% å·®ç•°ï¼‰\n",
    "- çµ„åˆä½¿ç”¨å¯ç²å¾—æœ€ä½³æ•ˆæœ\n",
    "\n",
    "### ğŸš€ ä¸‹ä¸€æ­¥ï¼š\n",
    "1. å¯¦ä½œåˆæˆå‡Œæ—¥æ³¨å…¥ï¼ˆinjectionï¼‰é€²è¡Œè¨“ç·´\n",
    "2. æå–æ›´å¤šç‰¹å¾µï¼ˆå¥‡å¶æ·±åº¦ã€å°ç¨±æ€§ç­‰ï¼‰\n",
    "3. å»ºç«‹æ©Ÿå™¨å­¸ç¿’åˆ†é¡å™¨\n",
    "4. é–‹ç™¼è‡ªå‹•åŒ–æ¨è«–ç®¡ç·š"
   ]
  },
  {
   "cell_type": "code",
   "source": "# ğŸš€ åŸ·è¡Œ GitHub Push\n# å–æ¶ˆè¨»è§£ä¸‹é¢é€™è¡Œä¾†åŸ·è¡Œæ¨é€:\n# ultimate_push_to_github_02()\n\nprint(\"ğŸ“‹ BLS/TLS åŸºç·šåˆ†æå®Œæˆï¼\")\nprint(\"ğŸ’¡ è«‹åœ¨éœ€è¦æ¨é€çµæœæ™‚åŸ·è¡Œä¸Šé¢çš„ ultimate_push_to_github_02() å‡½æ•¸\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# ğŸš€ GitHub Push çµ‚æ¥µè§£æ±ºæ–¹æ¡ˆ (02 - BLS/TLS Analysis Results)\n",
    "# ä¸€éµæ¨é€ BLS åŸºç·šåˆ†æçµæœè‡³ GitHub\n",
    "\n",
    "import subprocess, os\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "def ultimate_push_to_github_02(token=None):\n",
    "    \"\"\"\n",
    "    çµ‚æ¥µä¸€éµæ¨é€è§£æ±ºæ–¹æ¡ˆ - BLS/TLS åˆ†æçµæœç‰ˆ\n",
    "    è§£æ±ºæ‰€æœ‰ Colab èˆ‡æœ¬åœ°ç’°å¢ƒçš„ Git/LFS å•é¡Œ\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"ğŸš€ BLS/TLS åˆ†æçµæœ GitHub æ¨é€é–‹å§‹...\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # æ­¥é©Ÿ 1: ç’°å¢ƒåµæ¸¬èˆ‡è¨­å®š\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        IN_COLAB = True\n",
    "        working_dir = \"/content\"\n",
    "        print(\"ğŸŒ åµæ¸¬åˆ° Google Colab ç’°å¢ƒ\")\n",
    "    except ImportError:\n",
    "        IN_COLAB = False\n",
    "        working_dir = os.getcwd()\n",
    "        print(\"ğŸ’» åµæ¸¬åˆ°æœ¬åœ°ç’°å¢ƒ\")\n",
    "\n",
    "    # æ­¥é©Ÿ 2: Token è¼¸å…¥\n",
    "    if not token:\n",
    "        print(\"ğŸ“‹ è«‹è¼¸å…¥ GitHub Personal Access Token:\")\n",
    "        print(\"   1. å‰å¾€ https://github.com/settings/tokens\")\n",
    "        print(\"   2. é»æ“Š 'Generate new token (classic)'\")\n",
    "        print(\"   3. å‹¾é¸ 'repo' æ¬Šé™\")\n",
    "        print(\"   4. è¤‡è£½ç”Ÿæˆçš„ token\")\n",
    "        token = input(\"ğŸ” è²¼ä¸Šä½ çš„ token (ghp_...): \").strip()\n",
    "        if not token.startswith('ghp_'):\n",
    "            print(\"âŒ Token æ ¼å¼éŒ¯èª¤ï¼Œæ‡‰è©²ä»¥ 'ghp_' é–‹é ­\")\n",
    "            return False\n",
    "\n",
    "    # æ­¥é©Ÿ 3: Git å€‰åº«åˆå§‹åŒ–èˆ‡è¨­å®š\n",
    "    print(\"\\nğŸ“‹ æ­¥é©Ÿ 1/4: Git å€‰åº«è¨­å®š...\")\n",
    "\n",
    "    try:\n",
    "        # åˆ‡æ›åˆ°å·¥ä½œç›®éŒ„\n",
    "        if IN_COLAB:\n",
    "            os.chdir(working_dir)\n",
    "\n",
    "        # æª¢æŸ¥æ˜¯å¦å·²æ˜¯ Git å€‰åº«\n",
    "        git_check = subprocess.run(['git', 'rev-parse', '--git-dir'],\n",
    "                                   capture_output=True, text=True)\n",
    "\n",
    "        if git_check.returncode != 0:\n",
    "            print(\"   ğŸ”§ åˆå§‹åŒ– Git å€‰åº«...\")\n",
    "            subprocess.run(['git', 'init'], check=True)\n",
    "            print(\"   âœ… Git å€‰åº«åˆå§‹åŒ–å®Œæˆ\")\n",
    "        else:\n",
    "            print(\"   âœ… å·²åœ¨ Git å€‰åº«ä¸­\")\n",
    "\n",
    "        # è¨­å®š Git ç”¨æˆ¶ï¼ˆå¦‚æœæœªè¨­å®šï¼‰\n",
    "        try:\n",
    "            subprocess.run(['git', 'config', 'user.name', 'Colab User'], check=True)\n",
    "            subprocess.run(['git', 'config', 'user.email', 'colab@spaceapps.com'], check=True)\n",
    "            print(\"   âœ… Git ç”¨æˆ¶è¨­å®šå®Œæˆ\")\n",
    "        except:\n",
    "            print(\"   âš ï¸ Git ç”¨æˆ¶è¨­å®šè·³é\")\n",
    "\n",
    "        # è¨­å®šé ç«¯å€‰åº«ï¼ˆè‡ªå‹•åµæ¸¬æˆ–ä½¿ç”¨é è¨­ï¼‰\n",
    "        try:\n",
    "            remote_check = subprocess.run(['git', 'remote', 'get-url', 'origin'],\n",
    "                                        capture_output=True, text=True)\n",
    "            if remote_check.returncode != 0:\n",
    "                print(\"   ğŸ”§ è¨­å®šé ç«¯å€‰åº«...\")\n",
    "                # ä½¿ç”¨é è¨­å€‰åº« URLï¼ˆç”¨æˆ¶éœ€è¦ä¿®æ”¹ç‚ºè‡ªå·±çš„å€‰åº«ï¼‰\n",
    "                default_repo = \"https://github.com/exoplanet-spaceapps/exoplanet-starter.git\"\n",
    "                subprocess.run(['git', 'remote', 'add', 'origin', default_repo], check=True)\n",
    "                print(f\"   âœ… é ç«¯å€‰åº«è¨­å®š: {default_repo}\")\n",
    "                print(\"   ğŸ’¡ è«‹ç¢ºä¿ä½ æœ‰è©²å€‰åº«çš„å¯«å…¥æ¬Šé™ï¼Œæˆ–ä¿®æ”¹ç‚ºä½ çš„å€‰åº«\")\n",
    "            else:\n",
    "                print(f\"   âœ… é ç«¯å€‰åº«å·²è¨­å®š: {remote_check.stdout.strip()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   âš ï¸ é ç«¯å€‰åº«è¨­å®šè­¦å‘Š: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Git è¨­å®šå¤±æ•—: {e}\")\n",
    "        return False\n",
    "\n",
    "    # æ­¥é©Ÿ 4: Git LFS è¨­å®š\n",
    "    print(\"\\nğŸ“‹ æ­¥é©Ÿ 2/4: Git LFS è¨­å®š...\")\n",
    "\n",
    "    try:\n",
    "        # å®‰è£ Git LFSï¼ˆColabï¼‰\n",
    "        if IN_COLAB:\n",
    "            print(\"   ğŸ“¦ åœ¨ Colab ä¸­å®‰è£ Git LFS...\")\n",
    "            subprocess.run(['apt-get', 'update', '-qq'], check=True)\n",
    "            subprocess.run(['apt-get', 'install', '-y', '-qq', 'git-lfs'], check=True)\n",
    "            print(\"   âœ… Git LFS å·²å®‰è£\")\n",
    "\n",
    "        # åˆå§‹åŒ– LFS\n",
    "        try:\n",
    "            subprocess.run(['git', 'lfs', 'install'], check=True)\n",
    "            print(\"   âœ… Git LFS åˆå§‹åŒ–å®Œæˆ\")\n",
    "        except:\n",
    "            print(\"   âš ï¸ Git LFS åˆå§‹åŒ–è·³éï¼ˆå¯èƒ½å·²è¨­å®šï¼‰\")\n",
    "\n",
    "        # è¨­å®š LFS è¿½è¹¤ï¼ˆå®¹éŒ¯è™•ç†ï¼‰\n",
    "        lfs_patterns = ['*.csv', '*.json', '*.pkl', '*.parquet', '*.h5', '*.hdf5']\n",
    "        for pattern in lfs_patterns:\n",
    "            try:\n",
    "                result = subprocess.run(['git', 'lfs', 'track', pattern],\n",
    "                                      capture_output=True, text=True)\n",
    "                if result.returncode == 0:\n",
    "                    print(f\"   ğŸ“¦ LFS è¿½è¹¤: {pattern}\")\n",
    "                else:\n",
    "                    print(f\"   âš ï¸ LFS è¿½è¹¤ {pattern} è­¦å‘Š: {result.stderr.strip()}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   âš ï¸ LFS è¿½è¹¤ {pattern} è·³é: {e}\")\n",
    "\n",
    "        # æ·»åŠ  .gitattributes åˆ° staging\n",
    "        try:\n",
    "            subprocess.run(['git', 'add', '.gitattributes'], check=False)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸ Git LFS è¨­å®šè­¦å‘Š: {e}\")\n",
    "        print(\"   ğŸ’¡ ç¹¼çºŒåŸ·è¡Œï¼Œä½†å¤§æª”æ¡ˆå¯èƒ½ç„¡æ³•æ­£ç¢ºè¿½è¹¤\")\n",
    "\n",
    "    # æ­¥é©Ÿ 5: æ·»åŠ æª”æ¡ˆä¸¦æäº¤\n",
    "    print(\"\\nğŸ“‹ æ­¥é©Ÿ 3/4: æ·»åŠ æª”æ¡ˆèˆ‡æäº¤...\")\n",
    "\n",
    "    try:\n",
    "        # ç¢ºä¿é‡è¦ç›®éŒ„å­˜åœ¨\n",
    "        important_dirs = ['data', 'notebooks', 'app', 'scripts']\n",
    "        for dir_name in important_dirs:\n",
    "            dir_path = Path(dir_name)\n",
    "            if dir_path.exists():\n",
    "                print(f\"   ğŸ“‚ æ‰¾åˆ°ç›®éŒ„: {dir_name}\")\n",
    "            elif IN_COLAB and dir_name == 'data':\n",
    "                # åœ¨ Colab ä¸­å‰µå»º data ç›®éŒ„ä¸¦è¤‡è£½ç‰¹å¾µæª”æ¡ˆ\n",
    "                dir_path.mkdir(exist_ok=True)\n",
    "                print(f\"   ğŸ“‚ å‰µå»ºç›®éŒ„: {dir_name}\")\n",
    "\n",
    "        # æ·»åŠ æ‰€æœ‰æª”æ¡ˆ\n",
    "        subprocess.run(['git', 'add', '.'], check=True)\n",
    "        print(\"   âœ… æª”æ¡ˆæ·»åŠ å®Œæˆ\")\n",
    "\n",
    "        # æª¢æŸ¥æ˜¯å¦æœ‰è®Šæ›´\n",
    "        status_result = subprocess.run(['git', 'status', '--porcelain'],\n",
    "                                      capture_output=True, text=True, check=True)\n",
    "\n",
    "        if not status_result.stdout.strip():\n",
    "            print(\"   âœ… æ²’æœ‰æ–°çš„è®Šæ›´éœ€è¦æäº¤\")\n",
    "            return True\n",
    "\n",
    "        # å‰µå»ºæäº¤\n",
    "        commit_message = \"\"\"data: update BLS/TLS baseline analysis results\n",
    "\n",
    "- ğŸ“Š å®Œæˆ BLS (Box Least Squares) é€±æœŸæœå°‹åˆ†æ\n",
    "- ğŸ” å®Œæˆ TLS (Transit Least Squares) é«˜ç²¾åº¦åˆ†æ\n",
    "- ğŸ“ˆ æå–æ©Ÿå™¨å­¸ç¿’ç‰¹å¾µ: bls_tls_features.csv\n",
    "- ğŸ“‹ ç”Ÿæˆåˆ†æå ±å‘Šèˆ‡è¦–è¦ºåŒ–çµæœ\n",
    "- ğŸ¯ æ¸¬è©¦å¤šå€‹ TESS/Kepler ç›®æ¨™çš„å‡Œæ—¥åµæ¸¬æ•ˆèƒ½\n",
    "- ğŸš€ æº–å‚™é€²è¡Œåˆæˆæ³¨å…¥è¨“ç·´ (03_injection_train.ipynb)\n",
    "\n",
    "Co-Authored-By: hctsai1006 <39769660@cuni.cz>\n",
    "        \"\"\"\n",
    "\n",
    "        subprocess.run(['git', 'commit', '-m', commit_message], check=True)\n",
    "        print(\"   âœ… æäº¤å®Œæˆ\")\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"   âŒ æª”æ¡ˆæäº¤å¤±æ•—: {e}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ æª”æ¡ˆè™•ç†å¤±æ•—: {e}\")\n",
    "        return False\n",
    "\n",
    "    # æ­¥é©Ÿ 6: æ¨é€åˆ° GitHub\n",
    "    print(\"\\nğŸ“‹ æ­¥é©Ÿ 4/4: æ¨é€åˆ° GitHub...\")\n",
    "\n",
    "    try:\n",
    "        # ç²å–é ç«¯ URL ä¸¦æ’å…¥ token\n",
    "        remote_result = subprocess.run(['git', 'remote', 'get-url', 'origin'],\n",
    "                                      capture_output=True, text=True, check=True)\n",
    "        remote_url = remote_result.stdout.strip()\n",
    "\n",
    "        # æ§‹é€ å¸¶ token çš„ URL\n",
    "        if remote_url.startswith('https://github.com/'):\n",
    "            # æå–å€‰åº«è·¯å¾‘\n",
    "            repo_path = remote_url.replace('https://github.com/', '').replace('.git', '')\n",
    "            auth_url = f\"https://{token}@github.com/{repo_path}.git\"\n",
    "        else:\n",
    "            print(f\"   âš ï¸ é ç«¯ URL æ ¼å¼ç•°å¸¸: {remote_url}\")\n",
    "            auth_url = remote_url\n",
    "\n",
    "        # æ¨é€\n",
    "        push_result = subprocess.run([\n",
    "            'git', 'push', auth_url, 'main'\n",
    "        ], capture_output=True, text=True, timeout=300)\n",
    "\n",
    "        if push_result.returncode == 0:\n",
    "            print(\"   âœ… æ¨é€æˆåŠŸï¼\")\n",
    "            print(f\"   ğŸ“¡ æ¨é€è¼¸å‡º: {push_result.stdout[:200]}...\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"   âŒ æ¨é€å¤±æ•—: {push_result.stderr}\")\n",
    "            # å˜—è©¦æ¨é€åˆ°å…¶ä»–åˆ†æ”¯\n",
    "            try:\n",
    "                alt_push = subprocess.run([\n",
    "                    'git', 'push', auth_url, 'HEAD:main'\n",
    "                ], capture_output=True, text=True, timeout=300)\n",
    "                if alt_push.returncode == 0:\n",
    "                    print(\"   âœ… å‚™ç”¨æ¨é€æˆåŠŸï¼\")\n",
    "                    return True\n",
    "            except:\n",
    "                pass\n",
    "            return False\n",
    "\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"   âŒ æ¨é€è¶…æ™‚ï¼Œè«‹æª¢æŸ¥ç¶²è·¯é€£æ¥\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ æ¨é€å¤±æ•—: {e}\")\n",
    "        return False\n",
    "\n",
    "    finally:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"ğŸ“‹ BLS/TLS åˆ†æçµæœæ¨é€å®Œæˆ!\")\n",
    "        if IN_COLAB:\n",
    "            print(\"ğŸ’¡ å¦‚æœé‡åˆ°å•é¡Œ:\")\n",
    "            print(\"   1. ç¢ºä¿ token æœ‰ 'repo' æ¬Šé™\")\n",
    "            print(\"   2. ç¢ºä¿ä½ æœ‰ç›®æ¨™å€‰åº«çš„å¯«å…¥æ¬Šé™\")\n",
    "            print(\"   3. æª¢æŸ¥å€‰åº« URL æ˜¯å¦æ­£ç¢º\")\n",
    "\n",
    "# å‘¼å«å‡½æ•¸ï¼ˆè«‹åœ¨åŸ·è¡Œæ™‚æä¾› tokenï¼‰\n",
    "print(\"ğŸ” æº–å‚™æ¨é€ BLS/TLS åˆ†æçµæœ...\")\n",
    "print(\"ğŸ’¡ åŸ·è¡Œæ–¹å¼: ultimate_push_to_github_02(token='ä½ çš„GitHub_token')\")\n",
    "print(\"ğŸ“ æˆ–ç›´æ¥åŸ·è¡Œä¸‹æ–¹ cell ä¸¦åœ¨æç¤ºæ™‚è¼¸å…¥ token\")\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## ğŸš€ GitHub Push çµ‚æ¥µè§£æ±ºæ–¹æ¡ˆ\n\nå°‡ BLS/TLS åˆ†æçµæœæ¨é€åˆ° GitHub å€‰åº«ï¼š",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}