{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exoplanet Light Curve Download - Full Scale (Colab Version)\n",
    "\n",
    "**目標**: 下載 11,979 個 TESS 光曲線樣本  \n",
    "**預估時間**: 6-7 小時  \n",
    "**預估成功率**: ~57% (~6,800 樣本)  \n",
    "**儲存格式**: HDF5\n",
    "\n",
    "---\n",
    "\n",
    "## ⚠️ Colab 使用注意事項\n",
    "\n",
    "1. **執行時間**: 此 notebook 需要 6-7 小時連續執行\n",
    "2. **Colab 限制**: 免費版 12 小時限制，Pro 版 24 小時\n",
    "3. **中斷恢復**: 使用 checkpoint 系統，可從中斷處繼續\n",
    "4. **儲存空間**: 建議掛載 Google Drive (需約 5-10 GB)\n",
    "5. **網路穩定**: 確保網路連線穩定\n",
    "\n",
    "---\n",
    "\n",
    "## 📋 執行步驟\n",
    "\n",
    "1. **Cell 1**: 掛載 Google Drive (可選)\n",
    "2. **Cell 2**: 安裝依賴套件\n",
    "3. **Cell 3**: Clone GitHub 倉庫\n",
    "4. **Cell 4**: 設定配置參數\n",
    "5. **Cell 5**: 執行下載（主程式）\n",
    "6. **Cell 6**: 查看統計與驗證\n",
    "7. **Cell 7**: 下載結果到本地或推送 GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1️⃣ 掛載 Google Drive (可選但建議)\n",
    "\n",
    "將下載的資料存到 Google Drive，避免 Colab 重啟後遺失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 選項 A: 使用 Google Drive\n",
    "USE_GDRIVE = True  # 改為 False 則存在 Colab 本地\n",
    "\n",
    "if USE_GDRIVE:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # 設定工作目錄\n",
    "    WORK_DIR = '/content/drive/MyDrive/exoplanet-lightcurves'\n",
    "    !mkdir -p {WORK_DIR}\n",
    "    %cd {WORK_DIR}\n",
    "else:\n",
    "    WORK_DIR = '/content/exoplanet-starter'\n",
    "    !mkdir -p {WORK_DIR}\n",
    "    %cd {WORK_DIR}\n",
    "\n",
    "print(f\"Working directory: {WORK_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2️⃣ 安裝依賴套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -q lightkurve h5py pandas numpy tqdm pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3️⃣ Clone GitHub 倉庫並獲取數據集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Clone 倉庫（如果尚未存在）\n",
    "if not Path('exoplanet-starter').exists():\n",
    "    !git clone https://github.com/exoplanet-spaceapps/exoplanet-starter.git\n",
    "else:\n",
    "    print(\"Repository already exists, pulling latest changes...\")\n",
    "    !cd exoplanet-starter && git pull\n",
    "\n",
    "# 設定專案根目錄\n",
    "PROJECT_ROOT = Path('exoplanet-starter').resolve()\n",
    "os.chdir(PROJECT_ROOT)\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "\n",
    "# 確認數據集存在\n",
    "dataset_path = PROJECT_ROOT / 'data' / 'supervised_dataset.csv'\n",
    "if dataset_path.exists():\n",
    "    print(f\"✅ Dataset found: {dataset_path}\")\n",
    "else:\n",
    "    print(f\"❌ Dataset not found: {dataset_path}\")\n",
    "    print(\"Please check the repository structure.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4️⃣ 配置參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置參數\n",
    "CONFIG = {\n",
    "    'max_workers': 4,          # 並行下載數（Colab 建議 2-4）\n",
    "    'max_retries': 3,          # 失敗重試次數\n",
    "    'timeout': 60,             # 超時時間（秒）\n",
    "    'save_interval': 20,       # 每 N 個樣本保存 checkpoint\n",
    "    'test_samples': 11979,     # 全量下載（改為較小數字可測試）\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for key, val in CONFIG.items():\n",
    "    print(f\"  {key}: {val}\")\n",
    "\n",
    "# 估算時間\n",
    "estimated_hours = (CONFIG['test_samples'] * 5) / 3600 / CONFIG['max_workers']\n",
    "print(f\"\\nEstimated time: {estimated_hours:.1f} hours\")\n",
    "print(f\"Expected success: ~{int(CONFIG['test_samples'] * 0.57)} samples (57% rate)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5️⃣ 主下載程式\n",
    "\n",
    "**注意**: 此 cell 將運行 6-7 小時，請確保 Colab 連線穩定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm  # Colab 使用 notebook 版本\n",
    "import h5py\n",
    "import lightkurve as lk\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Exoplanet Detection - Full Download (Colab Version)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 設定路徑\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "LIGHTCURVE_DIR = DATA_DIR / 'lightcurves'\n",
    "CHECKPOINT_DIR = PROJECT_ROOT / 'checkpoints'\n",
    "\n",
    "LIGHTCURVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"\\n[1/5] Paths configured\")\n",
    "print(f\"  Lightcurves: {LIGHTCURVE_DIR}\")\n",
    "print(f\"  Checkpoints: {CHECKPOINT_DIR}\")\n",
    "\n",
    "# 載入數據集\n",
    "print(f\"\\n[2/5] Loading dataset...\")\n",
    "samples_df = pd.read_csv(dataset_path)\n",
    "samples_df = samples_df.head(CONFIG['test_samples'])\n",
    "\n",
    "if 'sample_id' not in samples_df.columns:\n",
    "    samples_df['sample_id'] = [f\"SAMPLE_{i:06d}\" for i in range(len(samples_df))]\n",
    "if 'tic_id' not in samples_df.columns:\n",
    "    if 'tid' in samples_df.columns:\n",
    "        samples_df['tic_id'] = samples_df['tid']\n",
    "\n",
    "print(f\"  Total samples: {len(samples_df)}\")\n",
    "print(f\"  Positive: {samples_df['label'].sum()}, Negative: {(~samples_df['label'].astype(bool)).sum()}\")\n",
    "\n",
    "# 下載函數\n",
    "def download_lightcurve(row, retries=3):\n",
    "    \"\"\"Download TESS light curve and save as HDF5\"\"\"\n",
    "    sample_id = row['sample_id']\n",
    "    tic_id = int(float(row['tic_id']))\n",
    "    \n",
    "    result = {\n",
    "        'sample_id': sample_id,\n",
    "        'tic_id': tic_id,\n",
    "        'status': 'failed',\n",
    "        'file_path': None,\n",
    "        'n_sectors': 0,\n",
    "        'error': None\n",
    "    }\n",
    "    \n",
    "    file_path = LIGHTCURVE_DIR / f\"{sample_id}_TIC{tic_id}.h5\"\n",
    "    \n",
    "    # 檢查是否已下載\n",
    "    if file_path.exists():\n",
    "        result['status'] = 'cached'\n",
    "        result['file_path'] = str(file_path)\n",
    "        try:\n",
    "            with h5py.File(file_path, 'r') as f:\n",
    "                result['n_sectors'] = f.attrs.get('n_sectors', 0)\n",
    "        except:\n",
    "            pass\n",
    "        return result\n",
    "    \n",
    "    # 嘗試下載\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            search_result = lk.search_lightcurve(f\"TIC {tic_id}\", author='SPOC')\n",
    "            if search_result is None or len(search_result) == 0:\n",
    "                result['error'] = 'no_data'\n",
    "                return result\n",
    "            \n",
    "            lc_collection = search_result.download_all()\n",
    "            if lc_collection is None or len(lc_collection) == 0:\n",
    "                result['error'] = 'download_failed'\n",
    "                return result\n",
    "            \n",
    "            # 保存為 HDF5\n",
    "            with h5py.File(file_path, 'w') as f:\n",
    "                f.attrs['sample_id'] = sample_id\n",
    "                f.attrs['tic_id'] = tic_id\n",
    "                f.attrs['n_sectors'] = len(lc_collection)\n",
    "                f.attrs['download_time'] = datetime.now().isoformat()\n",
    "                \n",
    "                for i, lc in enumerate(lc_collection):\n",
    "                    grp = f.create_group(f'sector_{i}')\n",
    "                    grp.create_dataset('time', data=np.array(lc.time.value))\n",
    "                    grp.create_dataset('flux', data=np.array(lc.flux.value))\n",
    "                    grp.create_dataset('flux_err', data=np.array(lc.flux_err.value))\n",
    "                    grp.attrs['sector'] = lc.meta.get('SECTOR', '?')\n",
    "                    grp.attrs['mission'] = str(lc.meta.get('MISSION', 'TESS'))\n",
    "            \n",
    "            result['status'] = 'success'\n",
    "            result['file_path'] = str(file_path)\n",
    "            result['n_sectors'] = len(lc_collection)\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            result['error'] = str(e)[:50]\n",
    "            if attempt < retries - 1:\n",
    "                time.sleep(2 ** attempt)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Checkpoint 管理\n",
    "def load_checkpoint():\n",
    "    cp = CHECKPOINT_DIR / 'download_progress.parquet'\n",
    "    if cp.exists():\n",
    "        df = pd.read_parquet(cp)\n",
    "        print(f\"  ✅ Loaded checkpoint: {len(df)} records\")\n",
    "        return df\n",
    "    return pd.DataFrame()\n",
    "\n",
    "def save_checkpoint(df):\n",
    "    cp = CHECKPOINT_DIR / 'download_progress.parquet'\n",
    "    df.to_parquet(cp, index=False)\n",
    "\n",
    "# 主下載流程\n",
    "print(f\"\\n[3/5] Starting download...\")\n",
    "progress_df = load_checkpoint()\n",
    "\n",
    "if len(progress_df) > 0:\n",
    "    completed = set(progress_df[progress_df['status'].isin(['success', 'cached'])]['sample_id'])\n",
    "    remaining = samples_df[~samples_df['sample_id'].isin(completed)]\n",
    "else:\n",
    "    remaining = samples_df.copy()\n",
    "\n",
    "print(f\"  Total: {len(samples_df)}\")\n",
    "print(f\"  Completed: {len(samples_df)-len(remaining)}\")\n",
    "print(f\"  Remaining: {len(remaining)}\")\n",
    "\n",
    "if len(remaining) == 0:\n",
    "    print(\"  ✅ All samples already downloaded!\")\n",
    "else:\n",
    "    print(f\"  ⏱️ Estimated time: {len(remaining)*5/60/CONFIG['max_workers']:.1f} minutes\")\n",
    "    print(f\"\\n⚠️ This will take approximately {len(remaining)*5/3600/CONFIG['max_workers']:.1f} hours\")\n",
    "    print(\"  Keep this notebook running...\\n\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    results = []\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=CONFIG['max_workers']) as executor:\n",
    "        futures = {executor.submit(download_lightcurve, row, CONFIG['max_retries']): row\n",
    "                   for _, row in remaining.iterrows()}\n",
    "        \n",
    "        with tqdm(total=len(remaining), desc=\"Downloading\") as pbar:\n",
    "            for future in as_completed(futures):\n",
    "                result = future.result()\n",
    "                results.append(result)\n",
    "                pbar.update(1)\n",
    "                \n",
    "                # 定期保存 checkpoint\n",
    "                if len(results) % CONFIG['save_interval'] == 0:\n",
    "                    temp_df = pd.concat([progress_df, pd.DataFrame(results)], ignore_index=True)\n",
    "                    save_checkpoint(temp_df)\n",
    "                    print(f\"  💾 Checkpoint saved: {len(results)} new downloads\")\n",
    "    \n",
    "    # 最終保存\n",
    "    if len(results) > 0:\n",
    "        progress_df = pd.concat([progress_df, pd.DataFrame(results)], ignore_index=True)\n",
    "        save_checkpoint(progress_df)\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n✅ Download complete!\")\n",
    "    print(f\"  Time: {elapsed/60:.1f} min ({elapsed/3600:.1f} hours)\")\n",
    "    print(f\"  Average: {elapsed/len(results):.1f} sec/sample\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6️⃣ 查看統計與驗證"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新載入最新的 checkpoint\n",
    "progress_df = load_checkpoint()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Download Statistics\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 狀態統計\n",
    "status_counts = progress_df['status'].value_counts()\n",
    "print(\"\\nStatus breakdown:\")\n",
    "for status, count in status_counts.items():\n",
    "    print(f\"  {status}: {count}\")\n",
    "\n",
    "success_count = status_counts.get('success', 0) + status_counts.get('cached', 0)\n",
    "success_rate = success_count / len(progress_df) * 100\n",
    "print(f\"\\nSuccess rate: {success_rate:.1f}% ({success_count}/{len(progress_df)})\")\n",
    "\n",
    "# 檔案驗證\n",
    "h5_files = list(LIGHTCURVE_DIR.glob('*.h5'))\n",
    "print(f\"\\nFiles on disk: {len(h5_files)}\")\n",
    "\n",
    "if len(h5_files) > 0:\n",
    "    total_size = sum(f.stat().st_size for f in h5_files) / 1024 / 1024 / 1024\n",
    "    print(f\"Total size: {total_size:.2f} GB\")\n",
    "    print(f\"Average: {total_size/len(h5_files)*1024:.1f} MB/file\")\n",
    "    \n",
    "    # 隨機檢查 3 個檔案\n",
    "    print(\"\\nSample verification:\")\n",
    "    samples = np.random.choice(h5_files, min(3, len(h5_files)), replace=False)\n",
    "    for h5_file in samples:\n",
    "        try:\n",
    "            with h5py.File(h5_file, 'r') as f:\n",
    "                tic_id = f.attrs['tic_id']\n",
    "                n_sectors = f.attrs['n_sectors']\n",
    "                total_points = sum(len(f[f'sector_{i}']['time']) for i in range(n_sectors))\n",
    "                print(f\"  TIC{tic_id}: {n_sectors} sectors, {total_points:,} data points\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ❌ {h5_file.name}: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7️⃣ 保存結果\n",
    "\n",
    "選擇以下其中一種方式保存結果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 選項 A: 下載 checkpoint 到本地"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# 下載 checkpoint 檔案\n",
    "checkpoint_file = CHECKPOINT_DIR / 'download_progress.parquet'\n",
    "if checkpoint_file.exists():\n",
    "    files.download(str(checkpoint_file))\n",
    "    print(\"✅ Checkpoint downloaded!\")\n",
    "else:\n",
    "    print(\"❌ Checkpoint file not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 選項 B: 推送到 GitHub (需要設定 token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定 GitHub token (不要直接寫在 notebook 中！)\n",
    "# 使用 Colab Secrets 或環境變數\n",
    "\n",
    "# from google.colab import userdata\n",
    "# GITHUB_TOKEN = userdata.get('GITHUB_TOKEN')\n",
    "\n",
    "# %cd {PROJECT_ROOT}\n",
    "# !git config user.name \"Your Name\"\n",
    "# !git config user.email \"your.email@example.com\"\n",
    "# !git add checkpoints/download_progress.parquet\n",
    "# !git commit -m \"feat: complete full-scale download from Colab\"\n",
    "# !git push https://{GITHUB_TOKEN}@github.com/exoplanet-spaceapps/exoplanet-starter.git main\n",
    "\n",
    "print(\"⚠️ Uncomment and configure the above code to push to GitHub\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 選項 C: 壓縮並下載部分資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 壓縮前 100 個成功下載的檔案（示例）\n",
    "!cd {LIGHTCURVE_DIR} && tar -czf sample_lightcurves_100.tar.gz $(ls *.h5 | head -100)\n",
    "\n",
    "# 下載壓縮檔\n",
    "sample_archive = LIGHTCURVE_DIR / 'sample_lightcurves_100.tar.gz'\n",
    "if sample_archive.exists():\n",
    "    files.download(str(sample_archive))\n",
    "    print(\"✅ Sample archive downloaded!\")\n",
    "else:\n",
    "    print(\"❌ Archive creation failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📝 下一步\n",
    "\n",
    "下載完成後，執行特徵提取：\n",
    "\n",
    "```python\n",
    "!python scripts/test_features.py\n",
    "```\n",
    "\n",
    "或使用對應的 Colab notebook 進行特徵提取。\n",
    "\n",
    "---\n",
    "\n",
    "## 🔧 故障排除\n",
    "\n",
    "**問題 1: Colab 中斷連線**\n",
    "- 解決: 使用 checkpoint 系統重新執行 Cell 5，會從中斷處繼續\n",
    "\n",
    "**問題 2: 儲存空間不足**\n",
    "- 解決: 使用 Google Drive 或定期下載並刪除本地檔案\n",
    "\n",
    "**問題 3: 下載速度過慢**\n",
    "- 解決: 減少 `max_workers` 或檢查網路連線\n",
    "\n",
    "**問題 4: MAST 快取錯誤**\n",
    "- 解決: 重試機制會自動處理，部分失敗屬正常現象（57% 成功率）"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
