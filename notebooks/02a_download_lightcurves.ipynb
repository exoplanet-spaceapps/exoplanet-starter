{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02a - 批量下载光曲线数据\n",
    "\n",
    "**目标**: 一次性下载所有 TOI 样本的 TESS 光曲线，保存为本地文件\n",
    "\n",
    "**特点**:\n",
    "- ✅ 批量并发下载（可配置线程数）\n",
    "- ✅ 断点续传（中断后可继续）\n",
    "- ✅ 自动重试失败样本\n",
    "- ✅ 进度追踪和统计\n",
    "- ✅ 保存为 FITS 格式（标准天文格式）\n",
    "\n",
    "**预计时间**: 4-8 小时（取决于网络和样本数）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: 安装依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab 环境检测和安装\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    print(\"📦 Installing dependencies...\")\n",
    "    !pip install -q numpy==1.26.4 'scipy<1.13' lightkurve pandas tqdm joblib\n",
    "    print(\"✅ Installation complete\")\n",
    "    print(\"⚠️ If errors, restart runtime and skip to Cell 2\")\n",
    "else:\n",
    "    print(\"✅ Running locally\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: 导入库和配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import lightkurve as lk\n",
    "import joblib\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✅ Imports successful\")\n",
    "print(f\"   Lightkurve: {lk.__version__}\")\n",
    "print(f\"   NumPy: {np.__version__}\")\n",
    "print(f\"   Pandas: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: 配置路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 环境检测\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"🌍 Running in Google Colab\")\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=False)\n",
    "    \n",
    "    REPO_DIR = Path('/content/exoplanet-starter')\n",
    "    if not REPO_DIR.exists():\n",
    "        print(\"📥 Cloning repository...\")\n",
    "        !git clone https://github.com/exoplanet-spaceapps/exoplanet-starter.git /content/exoplanet-starter\n",
    "    \n",
    "    os.chdir(str(REPO_DIR))\n",
    "    BASE_DIR = REPO_DIR\n",
    "    LIGHTCURVE_DIR = Path('/content/drive/MyDrive/spaceapps-lightcurves')\n",
    "    CHECKPOINT_DIR = Path('/content/drive/MyDrive/spaceapps-checkpoints')\n",
    "else:\n",
    "    print(\"💻 Running locally\")\n",
    "    BASE_DIR = Path.cwd().parent if 'notebooks' in str(Path.cwd()) else Path.cwd()\n",
    "    LIGHTCURVE_DIR = BASE_DIR / 'data' / 'lightcurves'\n",
    "    CHECKPOINT_DIR = BASE_DIR / 'checkpoints'\n",
    "\n",
    "DATA_DIR = BASE_DIR / 'data'\n",
    "LIGHTCURVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"\\n✅ Paths configured:\")\n",
    "print(f\"   Data: {DATA_DIR}\")\n",
    "print(f\"   Lightcurves: {LIGHTCURVE_DIR}\")\n",
    "print(f\"   Checkpoints: {CHECKPOINT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: 下载配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载配置\n",
    "CONFIG = {\n",
    "    'max_workers': 4,        # 并发线程数（建议 2-8）\n",
    "    'max_retries': 3,        # 失败重试次数\n",
    "    'timeout': 60,           # 单个下载超时（秒）\n",
    "    'batch_size': 100,       # 批处理大小\n",
    "    'save_interval': 50,     # 每 N 个保存一次进度\n",
    "    'test_mode': False,      # True = 只下载前 100 个样本测试\n",
    "}\n",
    "\n",
    "print(\"⚙️ Download Configuration:\")\n",
    "for key, val in CONFIG.items():\n",
    "    print(f\"   {key}: {val}\")\n",
    "\n",
    "# 加载数据集\n",
    "dataset_path = DATA_DIR / 'supervised_dataset.csv'\n",
    "if not dataset_path.exists():\n",
    "    raise FileNotFoundError(f\"❌ Dataset not found: {dataset_path}\")\n",
    "\n",
    "samples_df = pd.read_csv(dataset_path)\n",
    "\n",
    "# 测试模式\n",
    "if CONFIG['test_mode']:\n",
    "    samples_df = samples_df.head(100)\n",
    "    print(f\"\\n⚠️ TEST MODE: Only processing {len(samples_df)} samples\")\n",
    "\n",
    "# 添加唯一 ID\n",
    "if 'sample_id' not in samples_df.columns:\n",
    "    samples_df['sample_id'] = [f\"SAMPLE_{i:06d}\" for i in range(len(samples_df))]\n",
    "\n",
    "if 'tic_id' not in samples_df.columns:\n",
    "    if 'tid' in samples_df.columns:\n",
    "        samples_df['tic_id'] = samples_df['tid']\n",
    "    elif 'target_id' in samples_df.columns:\n",
    "        samples_df['tic_id'] = samples_df['target_id']\n",
    "\n",
    "print(f\"\\n✅ Dataset loaded: {len(samples_df):,} samples\")\n",
    "print(f\"   Positive: {samples_df['label'].sum():,}\")\n",
    "print(f\"   Negative: {(~samples_df['label'].astype(bool)).sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: 下载函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_single_lightcurve(row: pd.Series, retries: int = 3) -> dict:\n",
    "    \"\"\"\n",
    "    下载单个 TIC ID 的光曲线并保存为 pickle 文件\n",
    "    \n",
    "    Returns:\n",
    "        dict: {'sample_id', 'tic_id', 'status', 'file_path', 'n_sectors', 'error'}\n",
    "    \"\"\"\n",
    "    sample_id = row['sample_id']\n",
    "    tic_id = int(float(row['tic_id']))\n",
    "    \n",
    "    result = {\n",
    "        'sample_id': sample_id,\n",
    "        'tic_id': tic_id,\n",
    "        'status': 'failed',\n",
    "        'file_path': None,\n",
    "        'n_sectors': 0,\n",
    "        'error': None\n",
    "    }\n",
    "    \n",
    "    # 检查是否已下载\n",
    "    file_path = LIGHTCURVE_DIR / f\"{sample_id}_TIC{tic_id}.pkl\"\n",
    "    if file_path.exists():\n",
    "        result['status'] = 'cached'\n",
    "        result['file_path'] = str(file_path)\n",
    "        return result\n",
    "    \n",
    "    # 尝试下载\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            # 搜索光曲线\n",
    "            search_result = lk.search_lightcurve(f\"TIC {tic_id}\", author='SPOC')\n",
    "            \n",
    "            if search_result is None or len(search_result) == 0:\n",
    "                result['error'] = 'no_data_found'\n",
    "                return result\n",
    "            \n",
    "            # 下载所有扇区\n",
    "            lc_collection = search_result.download_all()\n",
    "            \n",
    "            if lc_collection is None or len(lc_collection) == 0:\n",
    "                result['error'] = 'download_failed'\n",
    "                return result\n",
    "            \n",
    "            # 保存为 pickle（包含完整的 LightCurveCollection）\n",
    "            save_data = {\n",
    "                'sample_id': sample_id,\n",
    "                'tic_id': tic_id,\n",
    "                'lc_collection': lc_collection,\n",
    "                'n_sectors': len(lc_collection),\n",
    "                'download_time': datetime.now().isoformat(),\n",
    "                'sectors': [lc.meta.get('SECTOR', 'unknown') for lc in lc_collection]\n",
    "            }\n",
    "            \n",
    "            joblib.dump(save_data, file_path)\n",
    "            \n",
    "            result['status'] = 'success'\n",
    "            result['file_path'] = str(file_path)\n",
    "            result['n_sectors'] = len(lc_collection)\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            result['error'] = str(e)\n",
    "            if attempt < retries - 1:\n",
    "                time.sleep(2 ** attempt)  # 指数退避\n",
    "                continue\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def load_checkpoint() -> pd.DataFrame:\n",
    "    \"\"\"加载下载进度 checkpoint\"\"\"\n",
    "    checkpoint_path = CHECKPOINT_DIR / 'download_progress.parquet'\n",
    "    if checkpoint_path.exists():\n",
    "        df = pd.read_parquet(checkpoint_path)\n",
    "        print(f\"📂 Loaded checkpoint: {len(df)} downloads\")\n",
    "        return df\n",
    "    return pd.DataFrame()\n",
    "\n",
    "\n",
    "def save_checkpoint(progress_df: pd.DataFrame):\n",
    "    \"\"\"保存下载进度\"\"\"\n",
    "    checkpoint_path = CHECKPOINT_DIR / 'download_progress.parquet'\n",
    "    progress_df.to_parquet(checkpoint_path, index=False)\n",
    "    print(f\"💾 Checkpoint saved: {len(progress_df)} downloads\")\n",
    "\n",
    "\n",
    "print(\"✅ Download functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: 批量下载（主要执行）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载进度\n",
    "progress_df = load_checkpoint()\n",
    "\n",
    "# 确定待下载样本\n",
    "if len(progress_df) > 0:\n",
    "    completed_ids = set(progress_df[progress_df['status'].isin(['success', 'cached'])]['sample_id'])\n",
    "    remaining_samples = samples_df[~samples_df['sample_id'].isin(completed_ids)]\n",
    "else:\n",
    "    remaining_samples = samples_df.copy()\n",
    "\n",
    "print(f\"📊 Download Progress:\")\n",
    "print(f\"   Total samples: {len(samples_df):,}\")\n",
    "print(f\"   Already downloaded: {len(samples_df) - len(remaining_samples):,}\")\n",
    "print(f\"   Remaining: {len(remaining_samples):,}\")\n",
    "\n",
    "if len(remaining_samples) == 0:\n",
    "    print(\"\\n✅ All lightcurves already downloaded!\")\n",
    "else:\n",
    "    print(f\"\\n🚀 Starting download for {len(remaining_samples):,} samples\")\n",
    "    print(f\"   Workers: {CONFIG['max_workers']}\")\n",
    "    print(f\"   Estimated time: {len(remaining_samples) * 5 / 3600 / CONFIG['max_workers']:.1f} hours\")\n",
    "    print(f\"   (assuming 5 sec/sample with {CONFIG['max_workers']} workers)\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    results = []\n",
    "    \n",
    "    # 并发下载\n",
    "    with ThreadPoolExecutor(max_workers=CONFIG['max_workers']) as executor:\n",
    "        # 提交所有任务\n",
    "        future_to_row = {\n",
    "            executor.submit(download_single_lightcurve, row, CONFIG['max_retries']): row \n",
    "            for _, row in remaining_samples.iterrows()\n",
    "        }\n",
    "        \n",
    "        # 进度条\n",
    "        with tqdm(total=len(remaining_samples), desc=\"Downloading\") as pbar:\n",
    "            for future in as_completed(future_to_row):\n",
    "                result = future.result()\n",
    "                results.append(result)\n",
    "                pbar.update(1)\n",
    "                \n",
    "                # 定期保存\n",
    "                if len(results) % CONFIG['save_interval'] == 0:\n",
    "                    temp_df = pd.concat([progress_df, pd.DataFrame(results)], ignore_index=True)\n",
    "                    save_checkpoint(temp_df)\n",
    "                    \n",
    "                    # 显示统计\n",
    "                    success_count = sum(1 for r in results if r['status'] == 'success')\n",
    "                    cached_count = sum(1 for r in results if r['status'] == 'cached')\n",
    "                    failed_count = sum(1 for r in results if r['status'] == 'failed')\n",
    "                    \n",
    "                    pbar.set_postfix({\n",
    "                        'success': success_count,\n",
    "                        'cached': cached_count,\n",
    "                        'failed': failed_count\n",
    "                    })\n",
    "    \n",
    "    # 最终保存\n",
    "    if len(results) > 0:\n",
    "        progress_df = pd.concat([progress_df, pd.DataFrame(results)], ignore_index=True)\n",
    "        save_checkpoint(progress_df)\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n🎉 Download complete!\")\n",
    "    print(f\"   Total time: {elapsed / 3600:.2f} hours\")\n",
    "    print(f\"   Average: {elapsed / len(results):.1f} sec/sample\")\n",
    "\n",
    "# 最终统计\n",
    "print(f\"\\n📊 Final Statistics:\")\n",
    "status_counts = progress_df['status'].value_counts()\n",
    "for status, count in status_counts.items():\n",
    "    print(f\"   {status}: {count:,}\")\n",
    "\n",
    "success_rate = (status_counts.get('success', 0) + status_counts.get('cached', 0)) / len(progress_df) * 100\n",
    "print(f\"\\n   Success rate: {success_rate:.1f}%\")\n",
    "print(f\"   Total lightcurves: {len(list(LIGHTCURVE_DIR.glob('*.pkl'))):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: 验证下载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 验证随机样本\n",
    "print(\"🔍 Verifying downloaded data...\\n\")\n",
    "\n",
    "pkl_files = list(LIGHTCURVE_DIR.glob('*.pkl'))\n",
    "if len(pkl_files) == 0:\n",
    "    print(\"❌ No lightcurve files found!\")\n",
    "else:\n",
    "    # 随机选择 3 个文件验证\n",
    "    sample_files = np.random.choice(pkl_files, min(3, len(pkl_files)), replace=False)\n",
    "    \n",
    "    for pkl_file in sample_files:\n",
    "        try:\n",
    "            data = joblib.load(pkl_file)\n",
    "            print(f\"✅ {pkl_file.name}\")\n",
    "            print(f\"   TIC ID: {data['tic_id']}\")\n",
    "            print(f\"   Sectors: {data['n_sectors']} ({data['sectors']})\")\n",
    "            print(f\"   Downloaded: {data['download_time']}\")\n",
    "            \n",
    "            # 检查第一个光曲线\n",
    "            lc = data['lc_collection'][0]\n",
    "            print(f\"   Data points: {len(lc.time):,}\")\n",
    "            print(f\"   Time span: {float(lc.time[-1] - lc.time[0]):.1f} days\")\n",
    "            print()\n",
    "        except Exception as e:\n",
    "            print(f\"❌ {pkl_file.name}: {e}\\n\")\n",
    "    \n",
    "    print(f\"\\n📦 Storage:\")\n",
    "    total_size = sum(f.stat().st_size for f in pkl_files) / 1024 / 1024 / 1024\n",
    "    print(f\"   Total files: {len(pkl_files):,}\")\n",
    "    print(f\"   Total size: {total_size:.2f} GB\")\n",
    "    print(f\"   Average size: {total_size * 1024 / len(pkl_files):.1f} MB/file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: 生成下载报告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成详细报告\n",
    "report = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'total_samples': len(samples_df),\n",
    "    'downloaded': int(status_counts.get('success', 0) + status_counts.get('cached', 0)),\n",
    "    'failed': int(status_counts.get('failed', 0)),\n",
    "    'success_rate': float(success_rate),\n",
    "    'config': CONFIG,\n",
    "    'storage': {\n",
    "        'directory': str(LIGHTCURVE_DIR),\n",
    "        'total_files': len(pkl_files),\n",
    "        'total_size_gb': float(total_size)\n",
    "    },\n",
    "    'errors': progress_df[progress_df['status'] == 'failed']['error'].value_counts().to_dict()\n",
    "}\n",
    "\n",
    "report_path = CHECKPOINT_DIR / 'download_report.json'\n",
    "with open(report_path, 'w') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "print(f\"✅ Download report saved: {report_path}\")\n",
    "print(f\"\\n📋 Summary:\")\n",
    "print(f\"   Downloaded: {report['downloaded']:,} / {report['total_samples']:,}\")\n",
    "print(f\"   Success rate: {report['success_rate']:.1f}%\")\n",
    "print(f\"   Storage: {report['storage']['total_size_gb']:.2f} GB\")\n",
    "\n",
    "if report['errors']:\n",
    "    print(f\"\\n⚠️ Error breakdown:\")\n",
    "    for error, count in report['errors'].items():\n",
    "        print(f\"   {error}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✅ 下载完成！\n",
    "\n",
    "### 下一步:\n",
    "1. 运行 `02b_extract_features.ipynb` 进行特征提取\n",
    "2. 特征提取可以多次运行，不需要重新下载\n",
    "3. 可以尝试不同的特征提取策略\n",
    "\n",
    "### 文件位置:\n",
    "- **光曲线数据**: `{LIGHTCURVE_DIR}`\n",
    "- **下载进度**: `checkpoints/download_progress.parquet`\n",
    "- **下载报告**: `checkpoints/download_report.json`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
