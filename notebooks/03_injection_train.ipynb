{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 Â· åˆæˆæ³¨å…¥è¨“ç·´ Â· Logistic + Isotonic\n",
    "å»ºç«‹ï¼ˆæ­£/è² ï¼‰æ¨£æœ¬ â†’ ç‰¹å¾µ â†’ è¨“ç·´ â†’ å¯é åº¦æ ¡æº–"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# ç’°å¢ƒè¨­å®šèˆ‡ä¾è³´å®‰è£ï¼ˆColabï¼‰\nimport sys, subprocess, pkgutil\n\ndef pipi(*pkgs):\n    \"\"\"å®‰è£å¥—ä»¶çš„è¼”åŠ©å‡½å¼\"\"\"\n    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", *pkgs])\n\n# å®‰è£å¿…è¦å¥—ä»¶ï¼ˆé¿å… numpy 2.0 ç›¸å®¹æ€§å•é¡Œï¼‰\nprint(\"ğŸš€ æ­£åœ¨å®‰è£ä¾è³´å¥—ä»¶...\")\ntry:\n    import numpy as np\n    import lightkurve as lk\n    import sklearn\n    print(\"âœ… åŸºç¤å¥—ä»¶å·²å®‰è£\")\nexcept Exception:\n    pipi(\"numpy<2\", \"lightkurve\", \"astroquery\", \"scikit-learn\", \"matplotlib\", \n         \"wotan\", \"transitleastsquares\", \"joblib\", \"torch\")\n    print(\"âœ… ä¾è³´å¥—ä»¶å®‰è£å®Œæˆ\")\n\n# æª¢æŸ¥ GPU è³‡è¨Š\nimport torch if 'torch' in [m.name for m in pkgutil.iter_modules()] else None\ngpu_available = False\nis_l4_gpu = False\n\nif torch is not None and torch.cuda.is_available():\n    gpu_name = torch.cuda.get_device_name(0)\n    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n    print(f\"ğŸ–¥ï¸ GPU å‹è™Ÿ: {gpu_name}\")\n    print(f\"   è¨˜æ†¶é«”: {gpu_memory:.2f} GB\")\n    gpu_available = True\n    \n    # å¦‚æœæ˜¯ NVIDIA L4ï¼Œæä¾› BF16 å„ªåŒ–å»ºè­°\n    if \"L4\" in gpu_name:\n        is_l4_gpu = True\n        print(\"ğŸ’¡ åµæ¸¬åˆ° NVIDIA L4 GPU - æ”¯æ´é«˜æ•ˆèƒ½ BF16 é‹ç®—\")\n        print(\"   å»ºè­°åœ¨è¨“ç·´æ™‚ä½¿ç”¨ torch.autocast('cuda', dtype=torch.bfloat16)\")\n        print(\"\\n   BF16 ç¯„ä¾‹ç¨‹å¼ç¢¼ï¼š\")\n        print(\"   ```python\")\n        print(\"   with torch.autocast('cuda', dtype=torch.bfloat16):\")\n        print(\"       output = model(input)\")\n        print(\"       loss = criterion(output, target)\")\n        print(\"   ```\")\nelse:\n    try:\n        # ä½¿ç”¨ nvidia-smi æª¢æŸ¥ GPU\n        result = subprocess.run(['nvidia-smi', '--query-gpu=name', '--format=csv,noheader'], \n                              capture_output=True, text=True, check=False)\n        if result.returncode == 0:\n            gpu_name = result.stdout.strip()\n            print(f\"ğŸ–¥ï¸ GPU å‹è™Ÿ: {gpu_name}\")\n            gpu_available = True\n            if \"L4\" in gpu_name:\n                is_l4_gpu = True\n                print(\"ğŸ’¡ åµæ¸¬åˆ° NVIDIA L4 GPU - æ”¯æ´é«˜æ•ˆèƒ½ BF16 é‹ç®—\")\n    except:\n        print(\"âš ï¸ æœªåµæ¸¬åˆ° GPUï¼Œå°‡ä½¿ç”¨ CPU é‹ç®—\")\n\nprint(\"\\nç’°å¢ƒè¨­å®šå®Œæˆï¼\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import lightkurve as lk, numpy as np, pandas as pd, matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.metrics import average_precision_score, precision_recall_curve\nimport json, os, joblib\n\n# ========== å¯¦éš›è³‡æ–™ç²å– ==========\nprint(\"ğŸ“¡ å¾ NASA è³‡æ–™åº«ç²å–å¯¦éš›è³‡æ–™...\")\n\n# æ–¹æ³• 1: ä½¿ç”¨ç¢ºèªçš„ TESS è¡Œæ˜Ÿä½œç‚ºæ­£æ¨£æœ¬\nfrom astroquery.ipac.nexsci.nasa_exoplanet_archive import NasaExoplanetArchive\n\ntry:\n    # ç²å–å·²ç¢ºèªçš„ TESS å‡Œæ—¥è¡Œæ˜Ÿ\n    confirmed = NasaExoplanetArchive.query_criteria(\n        table=\"ps\",\n        select=\"pl_name,tic_id,pl_orbper,pl_trandep\",\n        where=\"discoverymethod='Transit' and disc_facility like '%TESS%' and tic_id is not null\",\n        format=\"table\"\n    )\n    print(f\"âœ… æ‰¾åˆ° {len(confirmed)} å€‹ç¢ºèªçš„ TESS è¡Œæ˜Ÿ\")\n    \n    # ç²å– TOI å‡é™½æ€§ä½œç‚ºè² æ¨£æœ¬\n    false_positives = NasaExoplanetArchive.query_criteria(\n        table=\"toi\",\n        select=\"tid,tfopwg_disp,toi_period\",\n        where=\"tfopwg_disp='FP'\",\n        format=\"table\"\n    )\n    print(f\"âœ… æ‰¾åˆ° {len(false_positives)} å€‹ TOI å‡é™½æ€§\")\nexcept Exception as e:\n    print(f\"âš ï¸ ç„¡æ³•é€£æ¥ NASA Archiveï¼Œä½¿ç”¨æ¨¡æ“¬è³‡æ–™: {e}\")\n    confirmed = None\n    false_positives = None\n\n# ========== å»ºç«‹è¨“ç·´è³‡æ–™é›† ==========\n# å¦‚æœæœ‰çœŸå¯¦è³‡æ–™ï¼Œå„ªå…ˆä½¿ç”¨ï¼›å¦å‰‡ä½¿ç”¨åˆæˆè³‡æ–™\nif confirmed is not None and len(confirmed) > 0:\n    print(\"\\nğŸ¯ ä½¿ç”¨çœŸå¯¦ TESS è³‡æ–™è¨“ç·´...\")\n    # é€™è£¡ç°¡åŒ–è™•ç†ï¼Œå¯¦éš›æ‡‰ç”¨éœ€è¦ä¸‹è¼‰å®Œæ•´å…‰æ›²ç·š\n    # ä»¥ä¸‹ä»ä½¿ç”¨åˆæˆè³‡æ–™ç¤ºç¯„ï¼Œä½†åƒæ•¸åŸºæ–¼çœŸå¯¦è¡Œæ˜Ÿ\n    real_periods = confirmed['pl_orbper'][confirmed['pl_orbper'].mask == False].data[:10]\n    real_depths = confirmed['pl_trandep'][confirmed['pl_trandep'].mask == False].data[:10]\nelse:\n    print(\"\\nğŸ”§ ä½¿ç”¨åˆæˆè³‡æ–™è¨“ç·´ï¼ˆæ¨¡æ“¬çœŸå¯¦åƒæ•¸åˆ†å¸ƒï¼‰...\")\n    real_periods = None\n    real_depths = None\n\n# ä¸‹è¼‰ä¸€æ¢åŸºæº–å…‰æ›²ç·š\ntarget = \"TIC 25155310\"  # WASP-121 b - ç¢ºèªçš„ç†±æœ¨æ˜Ÿ\ntry:\n    lc = lk.search_lightcurve(target, mission=\"TESS\", author=\"SPOC\").download().remove_nans()\n    flat = lc.flatten(window_length=401)\n    t = flat.time.value\n    y = flat.flux.value\n    print(f\"âœ… æˆåŠŸä¸‹è¼‰ {target} å…‰æ›²ç·šä½œç‚ºåŸºåº•\")\nexcept:\n    # å‚™ç”¨ï¼šç”Ÿæˆæ¨¡æ“¬å…‰æ›²ç·š\n    t = np.linspace(0, 27, 20000)  # 27å¤© TESS è§€æ¸¬\n    y = 1.0 + np.random.normal(0, 0.001, len(t))\n    print(\"âš ï¸ ä½¿ç”¨æ¨¡æ“¬å…‰æ›²ç·š\")\n\n# å»ºç«‹è³‡æ–™é›†ï¼šæ³¨å…¥æ­£æ¨£æœ¬ + è² æ¨£æœ¬\nrng = np.random.default_rng(42)\n\ndef inject_box(time, flux, period, depth, duration, t0):\n    \"\"\"æ³¨å…¥ç®±å‹å‡Œæ—¥ä¿¡è™Ÿ\"\"\"\n    model = flux.copy()\n    phase = ((time - t0) % period) / period\n    in_transit = (phase < (duration/period))\n    model[in_transit] *= (1.0 - depth)\n    return model\n\ndef bls_feats(time, flux):\n    \"\"\"æå– BLS ç‰¹å¾µ\"\"\"\n    try:\n        bls = lk.LightCurve(time=time, flux=flux).to_periodogram(\n            method=\"bls\", minimum_period=0.5, maximum_period=20\n        )\n        return dict(\n            bls_period=bls.period_at_max_power.value,\n            bls_t0=bls.transit_time_at_max_power.value,\n            bls_duration=bls.duration_at_max_power.value,\n            bls_snr=bls.max_power.value\n        )\n    except:\n        return dict(bls_period=1.0, bls_t0=0.0, bls_duration=0.1, bls_snr=0.0)\n\nX, ylab = [], []\n\n# ç”Ÿæˆ 200 å€‹æ­£æ¨£æœ¬ï¼ˆä½¿ç”¨çœŸå¯¦åƒæ•¸åˆ†å¸ƒï¼‰\nprint(\"\\nç”Ÿæˆè¨“ç·´æ¨£æœ¬...\")\nfor i in range(200):\n    if real_periods is not None and i < len(real_periods):\n        # ä½¿ç”¨çœŸå¯¦è¡Œæ˜Ÿåƒæ•¸\n        P = float(real_periods[i])\n        D = float(real_depths[i]) / 1e6 if real_depths is not None and i < len(real_depths) else rng.uniform(0.0005, 0.02)\n    else:\n        # ä½¿ç”¨æ¨¡æ“¬åƒæ•¸ï¼ˆåŸºæ–¼ TESS è¡Œæ˜Ÿçµ±è¨ˆï¼‰\n        P = rng.uniform(0.6, 10)  # å…¸å‹ TESS è¡Œæ˜Ÿé€±æœŸ\n        D = rng.uniform(0.0005, 0.02)  # 0.05%~2% æ·±åº¦\n    \n    W = rng.uniform(0.02, 0.1)  # é€±æœŸæ¯”ä¾‹æŒçºŒæ™‚é–“\n    T0 = t.min() + rng.uniform(0, P)\n    fx = inject_box(t, y, P, D, W*P, T0)\n    X.append(bls_feats(t, fx))\n    ylab.append(1)\n\n# ç”Ÿæˆ 200 å€‹è² æ¨£æœ¬\nfor _ in range(200):\n    # è² æ¨£æœ¬ï¼šåŸæ›²ç·šæˆ–åŠ å™ª\n    noise = rng.normal(0, np.std(y)*0.2, size=y.size)\n    fx = y + noise\n    X.append(bls_feats(t, fx))\n    ylab.append(0)\n\ndf = pd.DataFrame(X)\ndf['label'] = ylab\nprint(f\"âœ… ç”Ÿæˆ {len(df)} å€‹è¨“ç·´æ¨£æœ¬\")\nprint(f\"   æ­£æ¨£æœ¬ï¼ˆè¡Œæ˜Ÿï¼‰: {(df['label']==1).sum()}\")\nprint(f\"   è² æ¨£æœ¬ï¼ˆéè¡Œæ˜Ÿï¼‰: {(df['label']==0).sum()}\")\nprint(\"\\nç‰¹å¾µçµ±è¨ˆ:\")\nprint(df.describe())",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# è¨“ç·´ + æ ¡æº–\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\n\nX = df[['bls_period','bls_duration','bls_snr']].values\ny = df['label'].values\nXtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n\n# åŸºç¤æ¨¡å‹è¨“ç·´ï¼ˆscikit-learnï¼‰\nbase = LogisticRegression(max_iter=200)\nclf = CalibratedClassifierCV(base, method=\"isotonic\", cv=3)\npipe = make_pipeline(StandardScaler(with_mean=False), clf)\npipe.fit(Xtr, ytr)\nprobs = pipe.predict_proba(Xte)[:,1]\nap = average_precision_score(yte, probs)\nprint(f\"Average Precision Score: {ap:.3f}\")\n\n# è‹¥ä½¿ç”¨ PyTorch ç¥ç¶“ç¶²è·¯é€²è¡Œæ·±åº¦å­¸ç¿’ï¼ˆç¯„ä¾‹ï¼‰\n# åœ¨ NVIDIA L4 GPU ä¸Šä½¿ç”¨ BF16 åŠ é€Ÿ\nif 'is_l4_gpu' in locals() and is_l4_gpu and 'torch' in sys.modules:\n    import torch\n    import torch.nn as nn\n    \n    print(\"\\nğŸš€ PyTorch BF16 è¨“ç·´ç¯„ä¾‹ï¼ˆé‡å° NVIDIA L4 å„ªåŒ–ï¼‰:\")\n    \n    class SimpleNN(nn.Module):\n        def __init__(self, input_dim=3):\n            super().__init__()\n            self.fc1 = nn.Linear(input_dim, 64)\n            self.fc2 = nn.Linear(64, 32)\n            self.fc3 = nn.Linear(32, 1)\n            self.relu = nn.ReLU()\n            self.sigmoid = nn.Sigmoid()\n        \n        def forward(self, x):\n            x = self.relu(self.fc1(x))\n            x = self.relu(self.fc2(x))\n            x = self.sigmoid(self.fc3(x))\n            return x\n    \n    # ç¤ºç¯„ BF16 è‡ªå‹•æ··åˆç²¾åº¦è¨“ç·´\n    model = SimpleNN().cuda()\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n    criterion = nn.BCELoss()\n    \n    # è½‰æ›è³‡æ–™åˆ° PyTorch tensors\n    X_tensor = torch.FloatTensor(Xtr).cuda()\n    y_tensor = torch.FloatTensor(ytr).unsqueeze(1).cuda()\n    \n    # ä½¿ç”¨ BF16 autocast é€²è¡Œè¨“ç·´ï¼ˆNVIDIA L4 å„ªåŒ–ï¼‰\n    print(\"ä½¿ç”¨ BF16 æ··åˆç²¾åº¦è¨“ç·´...\")\n    model.train()\n    for epoch in range(10):\n        with torch.autocast('cuda', dtype=torch.bfloat16):\n            outputs = model(X_tensor)\n            loss = criterion(outputs, y_tensor)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if epoch % 5 == 0:\n            print(f\"  Epoch {epoch}, Loss: {loss.item():.4f}\")\n    \n    print(\"âœ… BF16 è¨“ç·´å®Œæˆï¼ˆä½¿ç”¨ NVIDIA L4 ç¡¬é«”åŠ é€Ÿï¼‰\")\nelse:\n    print(\"\\nğŸ“ æç¤ºï¼šè‹¥éœ€è¦ä½¿ç”¨æ·±åº¦å­¸ç¿’æ¨¡å‹ï¼Œå¯å®‰è£ PyTorch ä¸¦åœ¨ GPU ä¸ŠåŸ·è¡Œ\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# å¯é åº¦æ›²ç·š\n",
    "from sklearn.calibration import calibration_curve\n",
    "prob_true, prob_pred = calibration_curve(yte, probs, n_bins=10)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(prob_pred, prob_true, marker=\"o\"); plt.plot([0,1],[0,1],'--'); plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.title(\"Calibration\");"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "mojyq8ry3ng",
   "source": "## Performance Tips\n\n### BF16 vs FP16 vs FP32 ç²¾åº¦æ¯”è¼ƒ\n\nç•¶ä½¿ç”¨ GPU é€²è¡Œæ·±åº¦å­¸ç¿’è¨“ç·´æ™‚ï¼Œé¸æ“‡é©ç•¶çš„æ•¸å€¼ç²¾åº¦å¯ä»¥é¡¯è‘—å½±éŸ¿è¨“ç·´é€Ÿåº¦èˆ‡æ¨¡å‹ç²¾ç¢ºåº¦ï¼š\n\n| ç²¾åº¦é¡å‹ | ä½å…ƒæ•¸ | å„ªé» | ç¼ºé» | å»ºè­°ä½¿ç”¨æƒ…å¢ƒ |\n|---------|-------|------|------|------------|\n| **FP32** | 32-bit | â€¢ æœ€é«˜ç²¾åº¦<br>â€¢ æœ€ä½³æ•¸å€¼ç©©å®šæ€§ | â€¢ è¨˜æ†¶é«”ä½¿ç”¨é‡å¤§<br>â€¢ é‹ç®—é€Ÿåº¦æ…¢ | â€¢ å°å‹æ¨¡å‹<br>â€¢ éœ€è¦æœ€é«˜ç²¾åº¦çš„ç§‘å­¸è¨ˆç®— |\n| **FP16** | 16-bit | â€¢ è¨˜æ†¶é«”æ¸›åŠ<br>â€¢ 2-4x åŠ é€Ÿï¼ˆæ”¯æ´ç¡¬é«”ï¼‰ | â€¢ å¯èƒ½æº¢ä½/æ¬ ä½<br>â€¢ æ¢¯åº¦æ¶ˆå¤±é¢¨éšª | â€¢ å½±åƒåˆ†é¡<br>â€¢ å·²èª¿æ ¡è‰¯å¥½çš„æ¨¡å‹ |\n| **BF16** | 16-bit | â€¢ èˆ‡ FP32 ç›¸åŒçš„æŒ‡æ•¸ç¯„åœ<br>â€¢ æ›´å¥½çš„æ•¸å€¼ç©©å®šæ€§<br>â€¢ 2-4x åŠ é€Ÿï¼ˆL4/A100ï¼‰ | â€¢ ç²¾åº¦ç•¥ä½æ–¼ FP32<br>â€¢ éœ€è¦æ–°ç¡¬é«”æ”¯æ´ | â€¢ **æ¨è–¦ç”¨æ–¼ NVIDIA L4**<br>â€¢ å¤§å‹èªè¨€æ¨¡å‹<br>â€¢ å¤©æ–‡è³‡æ–™è™•ç† |\n\n### NVIDIA L4 GPU å„ªåŒ–å»ºè­°\n\nNVIDIA L4 GPU ç‰¹åˆ¥å„ªåŒ–äº† BF16 é‹ç®—ï¼Œåœ¨ä¿æŒæ•¸å€¼ç©©å®šæ€§çš„åŒæ™‚æä¾›é¡¯è‘—çš„æ•ˆèƒ½æå‡ï¼š\n\n```python\n# BF16 è‡ªå‹•æ··åˆç²¾åº¦è¨“ç·´ï¼ˆæ¨è–¦ï¼‰\nwith torch.autocast('cuda', dtype=torch.bfloat16):\n    outputs = model(inputs)\n    loss = criterion(outputs, targets)\nloss.backward()\noptimizer.step()\n```\n\n### ä½•æ™‚æ”¹å› FP32\n\nåœ¨ä»¥ä¸‹æƒ…æ³å»ºè­°æ”¹å› FP32 ç²¾åº¦ï¼š\n\n1. **æœ€çµ‚æ¨è«–éšæ®µ**ï¼šç•¶éœ€è¦æœ€ç²¾ç¢ºçš„é æ¸¬çµæœæ™‚\n2. **å°æ‰¹æ¬¡è¨“ç·´**ï¼šbatch_size < 8 æ™‚ï¼ŒåŠ é€Ÿæ•ˆæœä¸æ˜é¡¯\n3. **æ•¸å€¼ä¸ç©©å®š**ï¼šå‡ºç¾ NaN æˆ– Inf æ™‚\n4. **ç²¾å¯†ç§‘å­¸è¨ˆç®—**ï¼šä¾‹å¦‚è»Œé“åƒæ•¸è¨ˆç®—ã€å‡Œæ—¥æ™‚é–“ç²¾ç¢ºé æ¸¬\n\n```python\n# åˆ‡æ›å› FP32 ç²¾åº¦\nmodel.float()  # å°‡æ¨¡å‹è½‰å› FP32\nwith torch.no_grad():\n    outputs = model(inputs.float())\n```\n\n### å¤–è¡Œæ˜Ÿåµæ¸¬ç‰¹å®šå„ªåŒ–\n\nå°æ–¼å¤–è¡Œæ˜Ÿå‡Œæ—¥åµæ¸¬ä»»å‹™ï¼š\n- **ç‰¹å¾µæå–**ï¼šä½¿ç”¨ FP32 ä»¥ä¿æŒå…‰æ›²ç·šè³‡æ–™ç²¾åº¦\n- **ç¥ç¶“ç¶²è·¯è¨“ç·´**ï¼šä½¿ç”¨ BF16 åŠ é€Ÿè¨“ç·´éç¨‹\n- **BLS/TLS é€±æœŸæœå°‹**ï¼šç¶­æŒ FP64 ä»¥ç²å¾—æº–ç¢ºçš„é€±æœŸä¼°è¨ˆ\n- **æœ€çµ‚æ©Ÿç‡æ ¡æº–**ï¼šä½¿ç”¨ FP32 ç¢ºä¿å¯é åº¦åˆ†æ•¸æº–ç¢º",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# æŒä¹…åŒ–æ¨¡å‹\n",
    "os.makedirs(\"/content/model\", exist_ok=True)\n",
    "import joblib, json\n",
    "joblib.dump(pipe, \"/content/model/ranker.joblib\")\n",
    "with open(\"/content/model/feature_schema.json\",\"w\") as f:\n",
    "    json.dump({\"features\": ['bls_period','bls_duration','bls_snr']}, f)\n",
    "print(\"Saved to /content/model/\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}