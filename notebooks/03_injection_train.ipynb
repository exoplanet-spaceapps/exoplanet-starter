{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 · 合成注入訓練 · Logistic + Isotonic\n",
    "建立（正/負）樣本 → 特徵 → 訓練 → 可靠度校準"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# 環境設定與依賴安裝（Colab）\nimport sys, subprocess, pkgutil\n\ndef pipi(*pkgs):\n    \"\"\"安裝套件的輔助函式\"\"\"\n    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", *pkgs])\n\n# 安裝必要套件（避免 numpy 2.0 相容性問題）\nprint(\"🚀 正在安裝依賴套件...\")\ntry:\n    import numpy as np\n    import lightkurve as lk\n    import sklearn\n    print(\"✅ 基礎套件已安裝\")\nexcept Exception:\n    pipi(\"numpy<2\", \"lightkurve\", \"astroquery\", \"scikit-learn\", \"matplotlib\", \n         \"wotan\", \"transitleastsquares\", \"joblib\", \"torch\")\n    print(\"✅ 依賴套件安裝完成\")\n\n# 檢查 GPU 資訊\nimport torch if 'torch' in [m.name for m in pkgutil.iter_modules()] else None\ngpu_available = False\nis_l4_gpu = False\n\nif torch is not None and torch.cuda.is_available():\n    gpu_name = torch.cuda.get_device_name(0)\n    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n    print(f\"🖥️ GPU 型號: {gpu_name}\")\n    print(f\"   記憶體: {gpu_memory:.2f} GB\")\n    gpu_available = True\n    \n    # 如果是 NVIDIA L4，提供 BF16 優化建議\n    if \"L4\" in gpu_name:\n        is_l4_gpu = True\n        print(\"💡 偵測到 NVIDIA L4 GPU - 支援高效能 BF16 運算\")\n        print(\"   建議在訓練時使用 torch.autocast('cuda', dtype=torch.bfloat16)\")\n        print(\"\\n   BF16 範例程式碼：\")\n        print(\"   ```python\")\n        print(\"   with torch.autocast('cuda', dtype=torch.bfloat16):\")\n        print(\"       output = model(input)\")\n        print(\"       loss = criterion(output, target)\")\n        print(\"   ```\")\nelse:\n    try:\n        # 使用 nvidia-smi 檢查 GPU\n        result = subprocess.run(['nvidia-smi', '--query-gpu=name', '--format=csv,noheader'], \n                              capture_output=True, text=True, check=False)\n        if result.returncode == 0:\n            gpu_name = result.stdout.strip()\n            print(f\"🖥️ GPU 型號: {gpu_name}\")\n            gpu_available = True\n            if \"L4\" in gpu_name:\n                is_l4_gpu = True\n                print(\"💡 偵測到 NVIDIA L4 GPU - 支援高效能 BF16 運算\")\n    except:\n        print(\"⚠️ 未偵測到 GPU，將使用 CPU 運算\")\n\nprint(\"\\n環境設定完成！\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import lightkurve as lk, numpy as np, pandas as pd, matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.metrics import average_precision_score, precision_recall_curve\nimport json, os, joblib\n\n# ========== 實際資料獲取 ==========\nprint(\"📡 從 NASA 資料庫獲取實際資料...\")\n\n# 方法 1: 使用確認的 TESS 行星作為正樣本\nfrom astroquery.ipac.nexsci.nasa_exoplanet_archive import NasaExoplanetArchive\n\ntry:\n    # 獲取已確認的 TESS 凌日行星\n    confirmed = NasaExoplanetArchive.query_criteria(\n        table=\"ps\",\n        select=\"pl_name,tic_id,pl_orbper,pl_trandep\",\n        where=\"discoverymethod='Transit' and disc_facility like '%TESS%' and tic_id is not null\",\n        format=\"table\"\n    )\n    print(f\"✅ 找到 {len(confirmed)} 個確認的 TESS 行星\")\n    \n    # 獲取 TOI 假陽性作為負樣本\n    false_positives = NasaExoplanetArchive.query_criteria(\n        table=\"toi\",\n        select=\"tid,tfopwg_disp,toi_period\",\n        where=\"tfopwg_disp='FP'\",\n        format=\"table\"\n    )\n    print(f\"✅ 找到 {len(false_positives)} 個 TOI 假陽性\")\nexcept Exception as e:\n    print(f\"⚠️ 無法連接 NASA Archive，使用模擬資料: {e}\")\n    confirmed = None\n    false_positives = None\n\n# ========== 建立訓練資料集 ==========\n# 如果有真實資料，優先使用；否則使用合成資料\nif confirmed is not None and len(confirmed) > 0:\n    print(\"\\n🎯 使用真實 TESS 資料訓練...\")\n    # 這裡簡化處理，實際應用需要下載完整光曲線\n    # 以下仍使用合成資料示範，但參數基於真實行星\n    real_periods = confirmed['pl_orbper'][confirmed['pl_orbper'].mask == False].data[:10]\n    real_depths = confirmed['pl_trandep'][confirmed['pl_trandep'].mask == False].data[:10]\nelse:\n    print(\"\\n🔧 使用合成資料訓練（模擬真實參數分布）...\")\n    real_periods = None\n    real_depths = None\n\n# 下載一條基準光曲線\ntarget = \"TIC 25155310\"  # WASP-121 b - 確認的熱木星\ntry:\n    lc = lk.search_lightcurve(target, mission=\"TESS\", author=\"SPOC\").download().remove_nans()\n    flat = lc.flatten(window_length=401)\n    t = flat.time.value\n    y = flat.flux.value\n    print(f\"✅ 成功下載 {target} 光曲線作為基底\")\nexcept:\n    # 備用：生成模擬光曲線\n    t = np.linspace(0, 27, 20000)  # 27天 TESS 觀測\n    y = 1.0 + np.random.normal(0, 0.001, len(t))\n    print(\"⚠️ 使用模擬光曲線\")\n\n# 建立資料集：注入正樣本 + 負樣本\nrng = np.random.default_rng(42)\n\ndef inject_box(time, flux, period, depth, duration, t0):\n    \"\"\"注入箱型凌日信號\"\"\"\n    model = flux.copy()\n    phase = ((time - t0) % period) / period\n    in_transit = (phase < (duration/period))\n    model[in_transit] *= (1.0 - depth)\n    return model\n\ndef bls_feats(time, flux):\n    \"\"\"提取 BLS 特徵\"\"\"\n    try:\n        bls = lk.LightCurve(time=time, flux=flux).to_periodogram(\n            method=\"bls\", minimum_period=0.5, maximum_period=20\n        )\n        return dict(\n            bls_period=bls.period_at_max_power.value,\n            bls_t0=bls.transit_time_at_max_power.value,\n            bls_duration=bls.duration_at_max_power.value,\n            bls_snr=bls.max_power.value\n        )\n    except:\n        return dict(bls_period=1.0, bls_t0=0.0, bls_duration=0.1, bls_snr=0.0)\n\nX, ylab = [], []\n\n# 生成 200 個正樣本（使用真實參數分布）\nprint(\"\\n生成訓練樣本...\")\nfor i in range(200):\n    if real_periods is not None and i < len(real_periods):\n        # 使用真實行星參數\n        P = float(real_periods[i])\n        D = float(real_depths[i]) / 1e6 if real_depths is not None and i < len(real_depths) else rng.uniform(0.0005, 0.02)\n    else:\n        # 使用模擬參數（基於 TESS 行星統計）\n        P = rng.uniform(0.6, 10)  # 典型 TESS 行星週期\n        D = rng.uniform(0.0005, 0.02)  # 0.05%~2% 深度\n    \n    W = rng.uniform(0.02, 0.1)  # 週期比例持續時間\n    T0 = t.min() + rng.uniform(0, P)\n    fx = inject_box(t, y, P, D, W*P, T0)\n    X.append(bls_feats(t, fx))\n    ylab.append(1)\n\n# 生成 200 個負樣本\nfor _ in range(200):\n    # 負樣本：原曲線或加噪\n    noise = rng.normal(0, np.std(y)*0.2, size=y.size)\n    fx = y + noise\n    X.append(bls_feats(t, fx))\n    ylab.append(0)\n\ndf = pd.DataFrame(X)\ndf['label'] = ylab\nprint(f\"✅ 生成 {len(df)} 個訓練樣本\")\nprint(f\"   正樣本（行星）: {(df['label']==1).sum()}\")\nprint(f\"   負樣本（非行星）: {(df['label']==0).sum()}\")\nprint(\"\\n特徵統計:\")\nprint(df.describe())",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# 訓練 + 校準\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\n\nX = df[['bls_period','bls_duration','bls_snr']].values\ny = df['label'].values\nXtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n\n# 基礎模型訓練（scikit-learn）\nbase = LogisticRegression(max_iter=200)\nclf = CalibratedClassifierCV(base, method=\"isotonic\", cv=3)\npipe = make_pipeline(StandardScaler(with_mean=False), clf)\npipe.fit(Xtr, ytr)\nprobs = pipe.predict_proba(Xte)[:,1]\nap = average_precision_score(yte, probs)\nprint(f\"Average Precision Score: {ap:.3f}\")\n\n# 若使用 PyTorch 神經網路進行深度學習（範例）\n# 在 NVIDIA L4 GPU 上使用 BF16 加速\nif 'is_l4_gpu' in locals() and is_l4_gpu and 'torch' in sys.modules:\n    import torch\n    import torch.nn as nn\n    \n    print(\"\\n🚀 PyTorch BF16 訓練範例（針對 NVIDIA L4 優化）:\")\n    \n    class SimpleNN(nn.Module):\n        def __init__(self, input_dim=3):\n            super().__init__()\n            self.fc1 = nn.Linear(input_dim, 64)\n            self.fc2 = nn.Linear(64, 32)\n            self.fc3 = nn.Linear(32, 1)\n            self.relu = nn.ReLU()\n            self.sigmoid = nn.Sigmoid()\n        \n        def forward(self, x):\n            x = self.relu(self.fc1(x))\n            x = self.relu(self.fc2(x))\n            x = self.sigmoid(self.fc3(x))\n            return x\n    \n    # 示範 BF16 自動混合精度訓練\n    model = SimpleNN().cuda()\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n    criterion = nn.BCELoss()\n    \n    # 轉換資料到 PyTorch tensors\n    X_tensor = torch.FloatTensor(Xtr).cuda()\n    y_tensor = torch.FloatTensor(ytr).unsqueeze(1).cuda()\n    \n    # 使用 BF16 autocast 進行訓練（NVIDIA L4 優化）\n    print(\"使用 BF16 混合精度訓練...\")\n    model.train()\n    for epoch in range(10):\n        with torch.autocast('cuda', dtype=torch.bfloat16):\n            outputs = model(X_tensor)\n            loss = criterion(outputs, y_tensor)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if epoch % 5 == 0:\n            print(f\"  Epoch {epoch}, Loss: {loss.item():.4f}\")\n    \n    print(\"✅ BF16 訓練完成（使用 NVIDIA L4 硬體加速）\")\nelse:\n    print(\"\\n📝 提示：若需要使用深度學習模型，可安裝 PyTorch 並在 GPU 上執行\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 可靠度曲線\n",
    "from sklearn.calibration import calibration_curve\n",
    "prob_true, prob_pred = calibration_curve(yte, probs, n_bins=10)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(prob_pred, prob_true, marker=\"o\"); plt.plot([0,1],[0,1],'--'); plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.title(\"Calibration\");"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "mojyq8ry3ng",
   "source": "## Performance Tips\n\n### BF16 vs FP16 vs FP32 精度比較\n\n當使用 GPU 進行深度學習訓練時，選擇適當的數值精度可以顯著影響訓練速度與模型精確度：\n\n| 精度類型 | 位元數 | 優點 | 缺點 | 建議使用情境 |\n|---------|-------|------|------|------------|\n| **FP32** | 32-bit | • 最高精度<br>• 最佳數值穩定性 | • 記憶體使用量大<br>• 運算速度慢 | • 小型模型<br>• 需要最高精度的科學計算 |\n| **FP16** | 16-bit | • 記憶體減半<br>• 2-4x 加速（支援硬體） | • 可能溢位/欠位<br>• 梯度消失風險 | • 影像分類<br>• 已調校良好的模型 |\n| **BF16** | 16-bit | • 與 FP32 相同的指數範圍<br>• 更好的數值穩定性<br>• 2-4x 加速（L4/A100） | • 精度略低於 FP32<br>• 需要新硬體支援 | • **推薦用於 NVIDIA L4**<br>• 大型語言模型<br>• 天文資料處理 |\n\n### NVIDIA L4 GPU 優化建議\n\nNVIDIA L4 GPU 特別優化了 BF16 運算，在保持數值穩定性的同時提供顯著的效能提升：\n\n```python\n# BF16 自動混合精度訓練（推薦）\nwith torch.autocast('cuda', dtype=torch.bfloat16):\n    outputs = model(inputs)\n    loss = criterion(outputs, targets)\nloss.backward()\noptimizer.step()\n```\n\n### 何時改回 FP32\n\n在以下情況建議改回 FP32 精度：\n\n1. **最終推論階段**：當需要最精確的預測結果時\n2. **小批次訓練**：batch_size < 8 時，加速效果不明顯\n3. **數值不穩定**：出現 NaN 或 Inf 時\n4. **精密科學計算**：例如軌道參數計算、凌日時間精確預測\n\n```python\n# 切換回 FP32 精度\nmodel.float()  # 將模型轉回 FP32\nwith torch.no_grad():\n    outputs = model(inputs.float())\n```\n\n### 外行星偵測特定優化\n\n對於外行星凌日偵測任務：\n- **特徵提取**：使用 FP32 以保持光曲線資料精度\n- **神經網路訓練**：使用 BF16 加速訓練過程\n- **BLS/TLS 週期搜尋**：維持 FP64 以獲得準確的週期估計\n- **最終機率校準**：使用 FP32 確保可靠度分數準確",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 持久化模型\n",
    "os.makedirs(\"/content/model\", exist_ok=True)\n",
    "import joblib, json\n",
    "joblib.dump(pipe, \"/content/model/ranker.joblib\")\n",
    "with open(\"/content/model/feature_schema.json\",\"w\") as f:\n",
    "    json.dump({\"features\": ['bls_period','bls_duration','bls_snr']}, f)\n",
    "print(\"Saved to /content/model/\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}