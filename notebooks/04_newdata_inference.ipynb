{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 Â· æ–°è³‡æ–™æ¨è«–ç®¡ç·šï¼ˆTIC â†’ MAST â†’ BLS/TLS â†’ æ©Ÿç‡ï¼‰\n",
    "\n",
    "## å·¥ä½œæµç¨‹\n",
    "1. **å–®ç›®æ¨™æ¨è«–**ï¼šè¼¸å…¥å–®å€‹ TIC â†’ ä¸‹è¼‰å…‰æ›²ç·š â†’ é æ¸¬æ©Ÿç‡\n",
    "2. **æ‰¹æ¬¡è™•ç†**ï¼šè¼¸å…¥ TIC åˆ—è¡¨ â†’ æ‰¹æ¬¡é æ¸¬ â†’ æ’åºè¼¸å‡º\n",
    "3. **è¦–è¦ºåŒ–**ï¼šæ‘ºç–Šå…‰æ›²ç·šã€BLS åŠŸç‡è­œã€é æ¸¬åˆ†æ•¸\n",
    "4. **GPU å„ªåŒ–**ï¼šåµæ¸¬ L4 GPU ä¸¦ç¤ºç¯„ bfloat16 autocast\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç’°å¢ƒè¨­å®šèˆ‡ä¾è³´å®‰è£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# æ­¥é©Ÿ 1: å®‰è£å¥—ä»¶ (éœ€è¦æ‰‹å‹•é‡å•Ÿ Runtime)\n# âš ï¸ é‡è¦: åŸ·è¡Œæ­¤ cell å¾Œï¼Œè«‹æ‰‹å‹•é‡å•Ÿ Runtime (Runtime â†’ Restart runtime)\n\n!pip install -q numpy==1.26.4 pandas astropy scipy'<1.13' matplotlib scikit-learn\n!pip install -q lightkurve astroquery xgboost joblib seaborn\n\nprint(\"âœ… å¥—ä»¶å®‰è£å®Œæˆ!\")\nprint(\"âš ï¸ è«‹ç¾åœ¨æ‰‹å‹•é‡å•Ÿ Runtime: Runtime â†’ Restart runtime\")\nprint(\"   ç„¶å¾Œç¹¼çºŒåŸ·è¡Œä¸‹ä¸€å€‹ cell\")"
  },
  {
   "cell_type": "code",
   "source": "# æ­¥é©Ÿ 2: é©—è­‰ç’°å¢ƒ (Runtime é‡å•Ÿå¾ŒåŸ·è¡Œ)\nimport numpy as np\nimport sys\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# æª¢æŸ¥ NumPy ç‰ˆæœ¬\nprint(f\"NumPy ç‰ˆæœ¬: {np.__version__}\")\nprint(f\"Python ç‰ˆæœ¬: {sys.version}\")\n\nif np.__version__.startswith('2.'):\n    print(\"âŒ NumPy 2.0 æª¢æ¸¬åˆ°ï¼è«‹ç¢ºèªå·²åŸ·è¡Œæ­¥é©Ÿ 1 ä¸¦é‡å•Ÿ Runtime\")\n    raise RuntimeError(\"è«‹å…ˆä¿®å¾© NumPy ç‰ˆæœ¬å•é¡Œ\")\nelse:\n    print(\"âœ… NumPy ç‰ˆæœ¬æ­£ç¢º (< 2.0)\")\n    \n# æª¢æŸ¥æ˜¯å¦åœ¨ Colab ç’°å¢ƒ\nIN_COLAB = 'google.colab' in sys.modules\n\nif IN_COLAB:\n    print(\"ğŸ“ åœ¨ Google Colab ç’°å¢ƒåŸ·è¡Œ\")\n    # Clone repository if needed\n    import os\n    if not os.path.exists('/content/exoplanet-starter'):\n        !git clone https://github.com/exoplanet-spaceapps/exoplanet-starter.git /content/exoplanet-starter\n        os.chdir('/content/exoplanet-starter')\n    sys.path.append('/content/exoplanet-starter')\nelse:\n    print(\"ğŸ’» åœ¨æœ¬åœ°ç’°å¢ƒåŸ·è¡Œ\")\n    import os\n    os.chdir(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n    sys.path.append(os.getcwd())\n\nprint(\"\\nâœ… ç’°å¢ƒè¨­å®šå®Œæˆï¼å¯ä»¥ç¹¼çºŒåŸ·è¡Œå¾ŒçºŒ cells\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. GPU åµæ¸¬èˆ‡å„ªåŒ–è¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU åµæ¸¬èˆ‡å„ªåŒ–è¨­å®š\n",
    "gpu_info = {\n",
    "    'available': False,\n",
    "    'device_name': None,\n",
    "    'is_l4': False,\n",
    "    'supports_bfloat16': False\n",
    "}\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        gpu_info['available'] = True\n",
    "        gpu_info['device_name'] = torch.cuda.get_device_name(0)\n",
    "        gpu_props = torch.cuda.get_device_properties(0)\n",
    "        \n",
    "        print(f\"ğŸ–¥ï¸ GPU åµæ¸¬çµæœ:\")\n",
    "        print(f\"   å‹è™Ÿ: {gpu_info['device_name']}\")\n",
    "        print(f\"   è¨˜æ†¶é«”: {gpu_props.total_memory / 1024**3:.2f} GB\")\n",
    "        print(f\"   CUDA é‹ç®—èƒ½åŠ›: {gpu_props.major}.{gpu_props.minor}\")\n",
    "        \n",
    "        # æª¢æŸ¥æ˜¯å¦ç‚º L4 GPU\n",
    "        if 'L4' in gpu_info['device_name']:\n",
    "            gpu_info['is_l4'] = True\n",
    "            gpu_info['supports_bfloat16'] = True\n",
    "            print(\"\\nğŸ’¡ åµæ¸¬åˆ° NVIDIA L4 GPUï¼\")\n",
    "            print(\"   â€¢ æ”¯æ´é«˜æ•ˆèƒ½ BF16 æ¨è«–\")\n",
    "            print(\"   â€¢ å»ºè­°ä½¿ç”¨ autocast é€²è¡ŒåŠ é€Ÿ\")\n",
    "        \n",
    "        # æª¢æŸ¥ bfloat16 æ”¯æ´\n",
    "        if hasattr(torch.cuda, 'is_bf16_supported'):\n",
    "            gpu_info['supports_bfloat16'] = torch.cuda.is_bf16_supported()\n",
    "            \n",
    "    else:\n",
    "        print(\"âš ï¸ æœªåµæ¸¬åˆ° CUDA GPU\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"âš ï¸ PyTorch æœªå®‰è£ï¼Œç„¡æ³•ä½¿ç”¨ GPU åŠ é€Ÿ\")\n",
    "    # å˜—è©¦ä½¿ç”¨ nvidia-smi\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'],\n",
    "            capture_output=True, text=True, check=False\n",
    "        )\n",
    "        if result.returncode == 0:\n",
    "            gpu_name, gpu_memory = result.stdout.strip().split(', ')\n",
    "            print(f\"\\nğŸ–¥ï¸ é€šé nvidia-smi åµæ¸¬åˆ° GPU:\")\n",
    "            print(f\"   å‹è™Ÿ: {gpu_name}\")\n",
    "            print(f\"   è¨˜æ†¶é«”: {gpu_memory}\")\n",
    "            if 'L4' in gpu_name:\n",
    "                gpu_info['is_l4'] = True\n",
    "                print(\"   ğŸ’¡ L4 GPU æ”¯æ´ BF16 åŠ é€Ÿ\")\n",
    "    except:\n",
    "        print(\"   å°‡ä½¿ç”¨ CPU é€²è¡Œæ¨è«–\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. è¼‰å…¥è¨“ç·´å¥½çš„æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¼‰å…¥æ¨¡å‹å’Œç›¸é—œæª”æ¡ˆ\n",
    "import joblib\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# æ¨¡å‹è·¯å¾‘\n",
    "model_dir = Path(\"model\")\n",
    "\n",
    "# æª¢æŸ¥æ¨¡å‹æª”æ¡ˆæ˜¯å¦å­˜åœ¨\n",
    "if not model_dir.exists():\n",
    "    print(\"âš ï¸ æ‰¾ä¸åˆ°æ¨¡å‹ç›®éŒ„ï¼Œè«‹å…ˆåŸ·è¡Œ 03_injection_train.ipynb è¨“ç·´æ¨¡å‹\")\n",
    "    print(\"   æˆ–ä¸‹è¼‰é è¨“ç·´æ¨¡å‹è‡³ model/ ç›®éŒ„\")\n",
    "else:\n",
    "    # è¼‰å…¥æ¨¡å‹\n",
    "    model_path = model_dir / \"ranker.joblib\"\n",
    "    scaler_path = model_dir / \"scaler.joblib\"\n",
    "    schema_path = model_dir / \"feature_schema.json\"\n",
    "    \n",
    "    if model_path.exists():\n",
    "        model = joblib.load(model_path)\n",
    "        print(f\"âœ… è¼‰å…¥æ¨¡å‹: {model_path}\")\n",
    "    else:\n",
    "        print(f\"âŒ æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆ: {model_path}\")\n",
    "        model = None\n",
    "    \n",
    "    if scaler_path.exists():\n",
    "        scaler = joblib.load(scaler_path)\n",
    "        print(f\"âœ… è¼‰å…¥æ¨™æº–åŒ–å™¨: {scaler_path}\")\n",
    "    else:\n",
    "        print(f\"âŒ æ‰¾ä¸åˆ°æ¨™æº–åŒ–å™¨: {scaler_path}\")\n",
    "        scaler = None\n",
    "    \n",
    "    if schema_path.exists():\n",
    "        with open(schema_path, 'r') as f:\n",
    "            schema = json.load(f)\n",
    "        feature_order = schema['feature_order']\n",
    "        print(f\"âœ… è¼‰å…¥ç‰¹å¾µæ¶æ§‹: {len(feature_order)} å€‹ç‰¹å¾µ\")\n",
    "    else:\n",
    "        print(f\"âŒ æ‰¾ä¸åˆ°ç‰¹å¾µæ¶æ§‹: {schema_path}\")\n",
    "        schema = None\n",
    "        feature_order = None\n",
    "\n",
    "# æª¢æŸ¥æ˜¯å¦æœ‰ç›£ç£å¼æ¨¡å‹\n",
    "supervised_model_path = model_dir / \"supervised\" / \"ranker_supervised.joblib\"\n",
    "if supervised_model_path.exists():\n",
    "    print(f\"\\nğŸ“¦ ç™¼ç¾ç›£ç£å¼æ¨¡å‹: {supervised_model_path}\")\n",
    "    print(\"   å¯é¸æ“‡ä½¿ç”¨ç›£ç£å¼æ¨¡å‹é€²è¡Œæ¨è«–\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. å°å…¥æ¨è«–æ¨¡çµ„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å°å…¥æ¨è«–æ¨¡çµ„\n",
    "from app.infer import (\n",
    "    predict_from_tic,\n",
    "    predict_batch,\n",
    "    create_folded_lightcurve_plot,\n",
    "    save_inference_results,\n",
    "    check_gpu_availability\n",
    ")\n",
    "\n",
    "from app.bls_features import run_bls, extract_features\n",
    "\n",
    "# å°å…¥è¦–è¦ºåŒ–å¥—ä»¶\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"ğŸ“š æ¨¡çµ„è¼‰å…¥å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. å–®ç›®æ¨™æ¨è«–ç¤ºç¯„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å–®å€‹ TIC æ¨è«–ç¤ºç¯„\n",
    "print(\"ğŸ¯ å–®ç›®æ¨™æ¨è«–ç¤ºç¯„\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ç›®æ¨™ TICï¼ˆå¯æ›´æ›ï¼‰\n",
    "tic_id = \"TIC 25155310\"  # TOI-431ï¼Œå·²çŸ¥çš„å¤šè¡Œæ˜Ÿç³»çµ±\n",
    "\n",
    "# åŸ·è¡Œæ¨è«–\n",
    "result = predict_from_tic(\n",
    "    tic_id,\n",
    "    model_path=\"model/ranker.joblib\",\n",
    "    scaler_path=\"model/scaler.joblib\",\n",
    "    feature_schema_path=\"model/feature_schema.json\",\n",
    "    mission=\"TESS\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# é¡¯ç¤ºçµæœ\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š æ¨è«–çµæœ:\")\n",
    "print(f\"   ç›®æ¨™: {result['tic_id']}\")\n",
    "print(f\"   æˆåŠŸ: {result['success']}\")\n",
    "\n",
    "if result['success']:\n",
    "    print(f\"\\nğŸ¯ é æ¸¬æ©Ÿç‡: {result['probability']:.3f}\")\n",
    "    print(f\"\\nğŸ“ˆ BLS çµæœ:\")\n",
    "    print(f\"   é€±æœŸ: {result['bls_period']:.3f} å¤©\")\n",
    "    print(f\"   æ·±åº¦: {result['bls_depth']*1e6:.0f} ppm\")\n",
    "    print(f\"   SNR: {result['bls_snr']:.1f}\")\n",
    "    \n",
    "    # åˆ¤æ–·æ˜¯å¦ç‚ºé«˜ä¿¡å¿ƒå€™é¸\n",
    "    if result['probability'] > 0.8:\n",
    "        print(\"\\nâœ¨ é«˜ä¿¡å¿ƒè¡Œæ˜Ÿå€™é¸ï¼\")\n",
    "    elif result['probability'] > 0.5:\n",
    "        print(\"\\nğŸ“ ä¸­ç­‰ä¿¡å¿ƒå€™é¸\")\n",
    "    else:\n",
    "        print(\"\\nâ“ ä½ä¿¡å¿ƒå€™é¸\")\n",
    "else:\n",
    "    print(f\"\\nâŒ éŒ¯èª¤: {result['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. è¦–è¦ºåŒ–å…‰æ›²ç·š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¦–è¦ºåŒ–å…‰æ›²ç·šå’Œ BLS çµæœ\n",
    "if result['success'] and result['lightcurve'] is not None:\n",
    "    import lightkurve as lk\n",
    "    \n",
    "    # ç²å–å…‰æ›²ç·šè³‡æ–™\n",
    "    time = np.array(result['lightcurve']['time'])\n",
    "    flux = np.array(result['lightcurve']['flux'])\n",
    "    period = result['bls_period']\n",
    "    \n",
    "    # å‰µå»ºåœ–è¡¨\n",
    "    fig = plt.figure(figsize=(15, 12))\n",
    "    \n",
    "    # 1. åŸå§‹å…‰æ›²ç·š\n",
    "    ax1 = plt.subplot(3, 2, 1)\n",
    "    ax1.plot(time, flux, 'k.', alpha=0.3, markersize=1)\n",
    "    ax1.set_xlabel('æ™‚é–“ (å¤©)')\n",
    "    ax1.set_ylabel('ç›¸å°æµé‡')\n",
    "    ax1.set_title(f'{result[\"tic_id\"]} - å»è¶¨å‹¢å¾Œå…‰æ›²ç·š')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. BLS åŠŸç‡è­œ\n",
    "    ax2 = plt.subplot(3, 2, 2)\n",
    "    # é‡æ–°è¨ˆç®— BLS ä»¥ç²å¾—å®Œæ•´åŠŸç‡è­œ\n",
    "    lc_obj = lk.LightCurve(time=time, flux=flux)\n",
    "    bls = lc_obj.to_periodogram(method=\"bls\", minimum_period=0.5, maximum_period=20)\n",
    "    bls.plot(ax=ax2)\n",
    "    ax2.axvline(period, color='red', linestyle='--', alpha=0.7, label=f'æœ€ä½³é€±æœŸ: {period:.3f} å¤©')\n",
    "    ax2.set_title('BLS åŠŸç‡è­œ')\n",
    "    ax2.legend()\n",
    "    \n",
    "    # 3. æ‘ºç–Šå…‰æ›²ç·š\n",
    "    ax3 = plt.subplot(3, 2, 3)\n",
    "    folded_data = create_folded_lightcurve_plot(time, flux, period)\n",
    "    phase = np.array(folded_data['phase'])\n",
    "    flux_folded = np.array(folded_data['flux'])\n",
    "    \n",
    "    # ç¹ªè£½æ•£é»åœ–\n",
    "    ax3.plot(phase, flux_folded, 'k.', alpha=0.2, markersize=1)\n",
    "    \n",
    "    # ç¹ªè£½åˆ†ç®±å¹³å‡\n",
    "    if folded_data['binned_phase']:\n",
    "        ax3.plot(folded_data['binned_phase'], folded_data['binned_flux'], \n",
    "                'ro-', markersize=4, linewidth=1.5, label='åˆ†ç®±å¹³å‡')\n",
    "    \n",
    "    ax3.set_xlabel('ç›¸ä½')\n",
    "    ax3.set_ylabel('ç›¸å°æµé‡')\n",
    "    ax3.set_title(f'æ‘ºç–Šå…‰æ›²ç·š (P = {period:.3f} å¤©)')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.legend()\n",
    "    \n",
    "    # 4. æ”¾å¤§å‡Œæ—¥å€åŸŸ\n",
    "    ax4 = plt.subplot(3, 2, 4)\n",
    "    transit_mask = np.abs(phase) < 0.1  # åªé¡¯ç¤ºç›¸ä½ Â±0.1 çš„å€åŸŸ\n",
    "    ax4.plot(phase[transit_mask], flux_folded[transit_mask], 'k.', alpha=0.3, markersize=2)\n",
    "    ax4.set_xlabel('ç›¸ä½')\n",
    "    ax4.set_ylabel('ç›¸å°æµé‡')\n",
    "    ax4.set_title('å‡Œæ—¥å€åŸŸæ”¾å¤§')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    ax4.set_xlim(-0.1, 0.1)\n",
    "    \n",
    "    # 5. é æ¸¬æ©Ÿç‡æ¢å½¢åœ–\n",
    "    ax5 = plt.subplot(3, 2, 5)\n",
    "    prob = result['probability']\n",
    "    color = 'green' if prob > 0.8 else 'orange' if prob > 0.5 else 'red'\n",
    "    bars = ax5.bar(['è¡Œæ˜Ÿå€™é¸æ©Ÿç‡'], [prob], color=color, alpha=0.7)\n",
    "    ax5.set_ylim(0, 1)\n",
    "    ax5.set_ylabel('æ©Ÿç‡')\n",
    "    ax5.set_title(f'é æ¸¬æ©Ÿç‡: {prob:.3f}')\n",
    "    ax5.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # æ·»åŠ æ•¸å€¼æ¨™ç±¤\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax5.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.3f}',\n",
    "                ha='center', va='bottom', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 6. ç‰¹å¾µé‡è¦æ€§\n",
    "    ax6 = plt.subplot(3, 2, 6)\n",
    "    # é¡¯ç¤ºé—œéµç‰¹å¾µ\n",
    "    features = result['features']\n",
    "    key_features = {\n",
    "        'BLS SNR': features.get('bls_snr', 0),\n",
    "        'é€±æœŸ': features.get('bls_period', 0),\n",
    "        'æ·±åº¦ (ppm)': features.get('bls_depth', 0) * 1e6,\n",
    "        'å¥‡å¶å·®ç•°': features.get('odd_even_depth_diff', 0) * 1e6,\n",
    "        'å°ç¨±æ€§': features.get('transit_symmetry', 0)\n",
    "    }\n",
    "    \n",
    "    y_pos = np.arange(len(key_features))\n",
    "    values = list(key_features.values())\n",
    "    labels = list(key_features.keys())\n",
    "    \n",
    "    ax6.barh(y_pos, values, color='skyblue', alpha=0.7)\n",
    "    ax6.set_yticks(y_pos)\n",
    "    ax6.set_yticklabels(labels)\n",
    "    ax6.set_xlabel('æ•¸å€¼')\n",
    "    ax6.set_title('é—œéµç‰¹å¾µå€¼')\n",
    "    ax6.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    plt.suptitle(f'{result[\"tic_id\"]} æ¨è«–çµæœè¦–è¦ºåŒ–', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nğŸ“ˆ è¦–è¦ºåŒ–å®Œæˆ\")\n",
    "else:\n",
    "    print(\"âš ï¸ ç„¡æ³•è¦–è¦ºåŒ–ï¼ˆæ¨è«–å¤±æ•—æˆ–ç„¡å…‰æ›²ç·šè³‡æ–™ï¼‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. æ‰¹æ¬¡æ¨è«–å¤šå€‹ç›®æ¨™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‰¹æ¬¡æ¨è«–å¤šå€‹ TIC\n",
    "print(\"ğŸ¯ æ‰¹æ¬¡æ¨è«–ç¤ºç¯„\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ç›®æ¨™åˆ—è¡¨ï¼ˆå¯è‡ªè¡Œä¿®æ”¹æˆ–æ“´å……ï¼‰\n",
    "tic_list = [\n",
    "    \"TIC 25155310\",  # TOI-431 (å·²çŸ¥å¤šè¡Œæ˜Ÿç³»çµ±)\n",
    "    \"TIC 307210830\", # TOI-270 (å·²çŸ¥ä¸‰è¡Œæ˜Ÿç³»çµ±)\n",
    "    \"TIC 260004324\", # TOI-178 (å·²çŸ¥å…­è¡Œæ˜Ÿç³»çµ±)\n",
    "    \"TIC 55652896\",  # TOI-125 (å·²çŸ¥ä¸‰è¡Œæ˜Ÿç³»çµ±)\n",
    "    \"TIC 441462736\", # å¯èƒ½çš„å‡é™½æ€§\n",
    "]\n",
    "\n",
    "print(f\"ğŸ“‹ æº–å‚™è™•ç† {len(tic_list)} å€‹ç›®æ¨™:\\n\")\n",
    "for i, tic in enumerate(tic_list, 1):\n",
    "    print(f\"   {i}. {tic}\")\n",
    "\n",
    "print(\"\\né–‹å§‹æ‰¹æ¬¡æ¨è«–...\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# åŸ·è¡Œæ‰¹æ¬¡æ¨è«–\n",
    "results_df = predict_batch(\n",
    "    tic_list,\n",
    "    model_path=\"model/ranker.joblib\",\n",
    "    scaler_path=\"model/scaler.joblib\",\n",
    "    feature_schema_path=\"model/feature_schema.json\",\n",
    "    mission=\"TESS\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. çµæœè¡¨æ ¼èˆ‡æ’åº"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é¡¯ç¤ºçµæœè¡¨æ ¼\n",
    "if len(results_df) > 0:\n",
    "    print(\"\\nğŸ“Š æ‰¹æ¬¡æ¨è«–çµæœï¼ˆæŒ‰æ©Ÿç‡æ’åºï¼‰:\\n\")\n",
    "    \n",
    "    # æ ¼å¼åŒ–é¡¯ç¤º\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    \n",
    "    # åªé¡¯ç¤ºé—œéµæ¬„ä½\n",
    "    display_columns = ['tic_id', 'probability', 'bls_period', 'bls_snr', 'bls_depth', 'success']\n",
    "    display_df = results_df[display_columns].copy()\n",
    "    \n",
    "    # æ ¼å¼åŒ–æ•¸å€¼\n",
    "    if 'probability' in display_df.columns:\n",
    "        display_df['probability'] = display_df['probability'].apply(lambda x: f\"{x:.3f}\" if pd.notna(x) else \"N/A\")\n",
    "    if 'bls_period' in display_df.columns:\n",
    "        display_df['bls_period'] = display_df['bls_period'].apply(lambda x: f\"{x:.3f}\" if pd.notna(x) else \"N/A\")\n",
    "    if 'bls_snr' in display_df.columns:\n",
    "        display_df['bls_snr'] = display_df['bls_snr'].apply(lambda x: f\"{x:.1f}\" if pd.notna(x) else \"N/A\")\n",
    "    if 'bls_depth' in display_df.columns:\n",
    "        display_df['bls_depth'] = display_df['bls_depth'].apply(lambda x: f\"{x*1e6:.0f}\" if pd.notna(x) else \"N/A\")\n",
    "        display_df = display_df.rename(columns={'bls_depth': 'bls_depth_ppm'})\n",
    "    \n",
    "    print(display_df.to_string(index=False))\n",
    "    \n",
    "    # çµ±è¨ˆæ‘˜è¦\n",
    "    success_count = results_df['success'].sum()\n",
    "    high_conf = len(results_df[(results_df['success']) & (results_df['probability'] > 0.8)])\n",
    "    med_conf = len(results_df[(results_df['success']) & (results_df['probability'] > 0.5) & (results_df['probability'] <= 0.8)])\n",
    "    \n",
    "    print(\"\\nğŸ“ˆ çµ±è¨ˆæ‘˜è¦:\")\n",
    "    print(f\"   æˆåŠŸè™•ç†: {success_count}/{len(results_df)}\")\n",
    "    print(f\"   é«˜ä¿¡å¿ƒå€™é¸ (>0.8): {high_conf}\")\n",
    "    print(f\"   ä¸­ä¿¡å¿ƒå€™é¸ (0.5-0.8): {med_conf}\")\n",
    "    \n",
    "    # å„²å­˜çµæœ\n",
    "    output_path = save_inference_results(\n",
    "        results_df,\n",
    "        output_path=\"results/batch_inference.csv\",\n",
    "        include_metadata=True\n",
    "    )\n",
    "    print(f\"\\nğŸ’¾ çµæœå·²å„²å­˜è‡³: {output_path}\")\n",
    "else:\n",
    "    print(\"âš ï¸ ç„¡æ¨è«–çµæœ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. æ‰¹æ¬¡çµæœè¦–è¦ºåŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‰¹æ¬¡çµæœè¦–è¦ºåŒ–\n",
    "if len(results_df) > 0 and results_df['success'].any():\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # åªé¸æ“‡æˆåŠŸçš„çµæœ\n",
    "    success_df = results_df[results_df['success']].copy()\n",
    "    \n",
    "    # 1. æ©Ÿç‡åˆ†å¸ƒ\n",
    "    ax1 = axes[0, 0]\n",
    "    if 'probability' in success_df.columns:\n",
    "        probs = success_df['probability'].dropna()\n",
    "        bars = ax1.bar(range(len(probs)), probs.values, color='skyblue', alpha=0.7)\n",
    "        \n",
    "        # æ ¹æ“šæ©Ÿç‡è‘—è‰²\n",
    "        for i, (bar, prob) in enumerate(zip(bars, probs.values)):\n",
    "            if prob > 0.8:\n",
    "                bar.set_color('green')\n",
    "            elif prob > 0.5:\n",
    "                bar.set_color('orange')\n",
    "            else:\n",
    "                bar.set_color('red')\n",
    "        \n",
    "        ax1.set_xticks(range(len(probs)))\n",
    "        ax1.set_xticklabels([tid.replace('TIC ', '') for tid in success_df['tic_id'].values], rotation=45)\n",
    "        ax1.set_ylabel('æ©Ÿç‡')\n",
    "        ax1.set_title('é æ¸¬æ©Ÿç‡åˆ†å¸ƒ')\n",
    "        ax1.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "        ax1.axhline(y=0.8, color='gray', linestyle='--', alpha=0.5)\n",
    "        ax1.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # 2. é€±æœŸåˆ†å¸ƒ\n",
    "    ax2 = axes[0, 1]\n",
    "    if 'bls_period' in success_df.columns:\n",
    "        periods = success_df['bls_period'].dropna()\n",
    "        if len(periods) > 0:\n",
    "            ax2.scatter(periods.values, success_df.loc[periods.index, 'probability'].values,\n",
    "                       s=100, alpha=0.7, c=success_df.loc[periods.index, 'probability'].values,\n",
    "                       cmap='RdYlGn', vmin=0, vmax=1)\n",
    "            ax2.set_xlabel('BLS é€±æœŸ (å¤©)')\n",
    "            ax2.set_ylabel('é æ¸¬æ©Ÿç‡')\n",
    "            ax2.set_title('é€±æœŸ vs æ©Ÿç‡')\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "            # æ·»åŠ é¡è‰²æ¢\n",
    "            cbar = plt.colorbar(ax2.collections[0], ax=ax2)\n",
    "            cbar.set_label('æ©Ÿç‡')\n",
    "    \n",
    "    # 3. SNR åˆ†å¸ƒ\n",
    "    ax3 = axes[1, 0]\n",
    "    if 'bls_snr' in success_df.columns:\n",
    "        snrs = success_df['bls_snr'].dropna()\n",
    "        if len(snrs) > 0:\n",
    "            ax3.scatter(snrs.values, success_df.loc[snrs.index, 'probability'].values,\n",
    "                       s=100, alpha=0.7, c=success_df.loc[snrs.index, 'probability'].values,\n",
    "                       cmap='RdYlGn', vmin=0, vmax=1)\n",
    "            ax3.set_xlabel('BLS SNR')\n",
    "            ax3.set_ylabel('é æ¸¬æ©Ÿç‡')\n",
    "            ax3.set_title('SNR vs æ©Ÿç‡')\n",
    "            ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. æ·±åº¦åˆ†å¸ƒ\n",
    "    ax4 = axes[1, 1]\n",
    "    if 'bls_depth' in success_df.columns:\n",
    "        depths = success_df['bls_depth'].dropna() * 1e6  # è½‰æ›ç‚º ppm\n",
    "        if len(depths) > 0:\n",
    "            ax4.scatter(depths.values, success_df.loc[depths.index, 'probability'].values,\n",
    "                       s=100, alpha=0.7, c=success_df.loc[depths.index, 'probability'].values,\n",
    "                       cmap='RdYlGn', vmin=0, vmax=1)\n",
    "            ax4.set_xlabel('å‡Œæ—¥æ·±åº¦ (ppm)')\n",
    "            ax4.set_ylabel('é æ¸¬æ©Ÿç‡')\n",
    "            ax4.set_title('æ·±åº¦ vs æ©Ÿç‡')\n",
    "            ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('æ‰¹æ¬¡æ¨è«–çµæœåˆ†æ', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nğŸ“ˆ æ‰¹æ¬¡è¦–è¦ºåŒ–å®Œæˆ\")\n",
    "else:\n",
    "    print(\"âš ï¸ ç„¡æˆåŠŸçš„æ¨è«–çµæœå¯è¦–è¦ºåŒ–\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. GPU åŠ é€Ÿç¤ºç¯„ï¼ˆå¦‚æœ‰ L4ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU åŠ é€Ÿç¤ºç¯„ï¼ˆåƒ…ç•¶åµæ¸¬åˆ° L4 GPU æ™‚åŸ·è¡Œï¼‰\n",
    "if gpu_info['is_l4'] and gpu_info['supports_bfloat16']:\n",
    "    print(\"ğŸš€ L4 GPU BFloat16 åŠ é€Ÿç¤ºç¯„\\n\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        import torch\n",
    "        import torch.nn as nn\n",
    "        \n",
    "        # å‰µå»ºç¤ºç¯„ç¥ç¶“ç¶²è·¯\n",
    "        class ExoplanetNet(nn.Module):\n",
    "            def __init__(self, input_dim=14):\n",
    "                super().__init__()\n",
    "                self.fc1 = nn.Linear(input_dim, 64)\n",
    "                self.fc2 = nn.Linear(64, 32)\n",
    "                self.fc3 = nn.Linear(32, 1)\n",
    "                self.relu = nn.ReLU()\n",
    "                self.sigmoid = nn.Sigmoid()\n",
    "            \n",
    "            def forward(self, x):\n",
    "                x = self.relu(self.fc1(x))\n",
    "                x = self.relu(self.fc2(x))\n",
    "                x = self.sigmoid(self.fc3(x))\n",
    "                return x\n",
    "        \n",
    "        # åˆå§‹åŒ–æ¨¡å‹\n",
    "        device = torch.device('cuda')\n",
    "        model = ExoplanetNet().to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        # æº–å‚™ç¤ºç¯„è³‡æ–™\n",
    "        batch_size = 100\n",
    "        input_features = torch.randn(batch_size, 14).to(device)\n",
    "        \n",
    "        # æ¯”è¼ƒæ¨è«–é€Ÿåº¦\n",
    "        import time\n",
    "        \n",
    "        # 1. æ¨™æº– FP32 æ¨è«–\n",
    "        print(\"â±ï¸ FP32 æ¨è«–:\")\n",
    "        start_time = time.time()\n",
    "        with torch.no_grad():\n",
    "            for _ in range(1000):\n",
    "                output_fp32 = model(input_features)\n",
    "        torch.cuda.synchronize()\n",
    "        fp32_time = time.time() - start_time\n",
    "        print(f\"   è€—æ™‚: {fp32_time:.3f} ç§’\")\n",
    "        \n",
    "        # 2. BFloat16 autocast æ¨è«–\n",
    "        print(\"\\nâš¡ BFloat16 æ¨è«– (with autocast):\")\n",
    "        start_time = time.time()\n",
    "        with torch.no_grad():\n",
    "            with torch.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "                for _ in range(1000):\n",
    "                    output_bf16 = model(input_features)\n",
    "        torch.cuda.synchronize()\n",
    "        bf16_time = time.time() - start_time\n",
    "        print(f\"   è€—æ™‚: {bf16_time:.3f} ç§’\")\n",
    "        \n",
    "        # è¨ˆç®—åŠ é€Ÿæ¯”\n",
    "        speedup = fp32_time / bf16_time\n",
    "        print(f\"\\nğŸ† BFloat16 åŠ é€Ÿæ¯”: {speedup:.2f}x\")\n",
    "        \n",
    "        # æª¢æŸ¥æ•¸å€¼èª¤å·®\n",
    "        diff = torch.abs(output_fp32 - output_bf16.float()).mean().item()\n",
    "        print(f\"   å¹³å‡çµ•å°èª¤å·®: {diff:.6f}\")\n",
    "        \n",
    "        print(\"\\nğŸ’¡ çµè«–:\")\n",
    "        print(\"   â€¢ L4 GPU çš„ BFloat16 å¯é¡¯è‘—åŠ é€Ÿæ¨è«–\")\n",
    "        print(\"   â€¢ æ•¸å€¼ç²¾åº¦æå¤±æ¥µå°ï¼Œé©åˆç”Ÿç”¢éƒ¨ç½²\")\n",
    "        print(\"   â€¢ å»ºè­°åœ¨å¤§è¦æ¨¡æ‰¹æ¬¡æ¨è«–æ™‚ä½¿ç”¨\")\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"âš ï¸ éœ€è¦å®‰è£ PyTorch æ‰èƒ½åŸ·è¡Œ GPU åŠ é€Ÿç¤ºç¯„\")\n",
    "        print(\"   åŸ·è¡Œ: pip install torch\")\n",
    "else:\n",
    "    print(\"â„¹ï¸ GPU åŠ é€Ÿç¤ºç¯„\")\n",
    "    print(\"   â€¢ æœªåµæ¸¬åˆ° L4 GPU æˆ–ä¸æ”¯æ´ BFloat16\")\n",
    "    print(\"   â€¢ ç•¶å‰ä½¿ç”¨æ¨™æº– CPU/GPU æ¨è«–\")\n",
    "    print(\"   â€¢ è‹¥éœ€è¦åŠ é€Ÿï¼Œå»ºè­°ä½¿ç”¨ Google Colab L4 åŸ·è¡Œç’°å¢ƒ\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. ç¸½çµèˆ‡ä¸‹ä¸€æ­¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"ğŸ“Š æ¨è«–ç®¡ç·šåŸ·è¡Œç¸½çµ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "ğŸ¯ åŸ·è¡Œçµ±è¨ˆ:\n",
    "   â€¢ è™•ç†ç›®æ¨™æ•¸: {len(results_df) if 'results_df' in locals() else 0}\n",
    "   â€¢ æˆåŠŸæ¨è«–: {results_df['success'].sum() if 'results_df' in locals() else 0}\n",
    "   â€¢ é«˜ä¿¡å¿ƒå€™é¸: {len(results_df[(results_df['success']) & (results_df['probability'] > 0.8)]) if 'results_df' in locals() else 0}\n",
    "\n",
    "ğŸ–¥ï¸ é‹ç®—ç’°å¢ƒ:\n",
    "   â€¢ GPU: {'å¯ç”¨ - ' + gpu_info['device_name'] if gpu_info['available'] else 'ä¸å¯ç”¨'}\n",
    "   â€¢ L4 å„ªåŒ–: {'æ”¯æ´' if gpu_info['is_l4'] else 'ä¸æ”¯æ´'}\n",
    "   â€¢ BFloat16: {'æ”¯æ´' if gpu_info['supports_bfloat16'] else 'ä¸æ”¯æ´'}\n",
    "\n",
    "ğŸ“¦ è¼¸å‡ºæª”æ¡ˆ:\n",
    "   â€¢ æ‰¹æ¬¡çµæœ: results/batch_inference.csv\n",
    "   â€¢ å…ƒè³‡æ–™: results/batch_inference_metadata.json\n",
    "\n",
    "ğŸš€ ä¸‹ä¸€æ­¥å»ºè­°:\n",
    "   1. å°é«˜ä¿¡å¿ƒå€™é¸é€²è¡Œäººå·¥å¯©æŸ¥\n",
    "   2. æŸ¥è©¢ NASA Exoplanet Archive ç¢ºèªå·²çŸ¥è¡Œæ˜Ÿ\n",
    "   3. ä½¿ç”¨æ›´å¤š TESS æ‰‡å€è³‡æ–™é€²è¡Œé©—è­‰\n",
    "   4. ç”Ÿæˆå€™é¸åˆ¤è®€å¡ï¼ˆåŸ·è¡Œ app/report.pyï¼‰\n",
    "   5. éƒ¨ç½²ç‚º Web æ‡‰ç”¨ï¼ˆåŸ·è¡Œ web/app.pyï¼‰\n",
    "\n",
    "ğŸ“š ç›¸é—œè³‡æº:\n",
    "   â€¢ NASA Exoplanet Archive: https://exoplanetarchive.ipac.caltech.edu/\n",
    "   â€¢ TESS è³‡æ–™å…¥å£: https://mast.stsci.edu/portal/Mashup/Clients/Mast/Portal.html\n",
    "   â€¢ Lightkurve æ–‡ä»¶: https://docs.lightkurve.org/\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"âœ… æ¨è«–ç®¡ç·šå®Œæˆï¼\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}