{
 "cells": [
  {
   "cell_type": "code",
   "source": "# ğŸš€ åŸ·è¡Œ GitHub Push (04 - æ–°è³‡æ–™æ¨è«–)\n# å–æ¶ˆè¨»è§£ä¸‹é¢é€™è¡Œä¾†åŸ·è¡Œæ¨é€:\n# ultimate_push_to_github_04()\n\nprint(\"ğŸ“‹ æ–°è³‡æ–™æ¨è«–ç®¡ç·šå®Œæˆï¼\")\nprint(\"ğŸ’¡ è«‹åœ¨éœ€è¦æ¨é€çµæœæ™‚åŸ·è¡Œä¸Šé¢çš„ ultimate_push_to_github_04() å‡½æ•¸\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# ğŸš€ GitHub Push çµ‚æ¥µè§£æ±ºæ–¹æ¡ˆ (04 - New Data Inference Results)\n# ä¸€éµæ¨é€æ–°è³‡æ–™æ¨è«–çµæœè‡³ GitHub\n\nimport subprocess, os\nfrom pathlib import Path\nimport json\n\ndef ultimate_push_to_github_04(token=None):\n    \"\"\"\n    çµ‚æ¥µä¸€éµæ¨é€è§£æ±ºæ–¹æ¡ˆ - æ–°è³‡æ–™æ¨è«–çµæœç‰ˆ\n    è§£æ±ºæ‰€æœ‰ Colab èˆ‡æœ¬åœ°ç’°å¢ƒçš„ Git/LFS å•é¡Œ\n    \"\"\"\n\n    print(\"ğŸš€ æ–°è³‡æ–™æ¨è«–çµæœ GitHub æ¨é€é–‹å§‹...\")\n    print(\"=\" * 60)\n\n    # æ­¥é©Ÿ 1: ç’°å¢ƒåµæ¸¬èˆ‡è¨­å®š\n    try:\n        from google.colab import drive\n        IN_COLAB = True\n        working_dir = \"/content\"\n        print(\"ğŸŒ åµæ¸¬åˆ° Google Colab ç’°å¢ƒ\")\n    except ImportError:\n        IN_COLAB = False\n        working_dir = os.getcwd()\n        print(\"ğŸ’» åµæ¸¬åˆ°æœ¬åœ°ç’°å¢ƒ\")\n\n    # æ­¥é©Ÿ 2: Token è¼¸å…¥\n    if not token:\n        print(\"ğŸ“‹ è«‹è¼¸å…¥ GitHub Personal Access Token:\")\n        print(\"   1. å‰å¾€ https://github.com/settings/tokens\")\n        print(\"   2. é»æ“Š 'Generate new token (classic)'\")\n        print(\"   3. å‹¾é¸ 'repo' æ¬Šé™\")\n        print(\"   4. è¤‡è£½ç”Ÿæˆçš„ token\")\n        token = input(\"ğŸ” è²¼ä¸Šä½ çš„ token (ghp_...): \").strip()\n        if not token.startswith('ghp_'):\n            print(\"âŒ Token æ ¼å¼éŒ¯èª¤ï¼Œæ‡‰è©²ä»¥ 'ghp_' é–‹é ­\")\n            return False\n\n    # æ­¥é©Ÿ 3: Git å€‰åº«åˆå§‹åŒ–èˆ‡è¨­å®š\n    print(\"\\nğŸ“‹ æ­¥é©Ÿ 1/4: Git å€‰åº«è¨­å®š...\")\n\n    try:\n        # åˆ‡æ›åˆ°å·¥ä½œç›®éŒ„\n        if IN_COLAB:\n            os.chdir(working_dir)\n\n        # æª¢æŸ¥æ˜¯å¦å·²æ˜¯ Git å€‰åº«\n        git_check = subprocess.run(['git', 'rev-parse', '--git-dir'],\n                                   capture_output=True, text=True)\n\n        if git_check.returncode != 0:\n            print(\"   ğŸ”§ åˆå§‹åŒ– Git å€‰åº«...\")\n            subprocess.run(['git', 'init'], check=True)\n            print(\"   âœ… Git å€‰åº«åˆå§‹åŒ–å®Œæˆ\")\n        else:\n            print(\"   âœ… å·²åœ¨ Git å€‰åº«ä¸­\")\n\n        # è¨­å®š Git ç”¨æˆ¶ï¼ˆå¦‚æœæœªè¨­å®šï¼‰\n        try:\n            subprocess.run(['git', 'config', 'user.name', 'Colab User'], check=True)\n            subprocess.run(['git', 'config', 'user.email', 'colab@spaceapps.com'], check=True)\n            print(\"   âœ… Git ç”¨æˆ¶è¨­å®šå®Œæˆ\")\n        except:\n            print(\"   âš ï¸ Git ç”¨æˆ¶è¨­å®šè·³é\")\n\n        # è¨­å®šé ç«¯å€‰åº«ï¼ˆè‡ªå‹•åµæ¸¬æˆ–ä½¿ç”¨é è¨­ï¼‰\n        try:\n            remote_check = subprocess.run(['git', 'remote', 'get-url', 'origin'],\n                                        capture_output=True, text=True)\n            if remote_check.returncode != 0:\n                print(\"   ğŸ”§ è¨­å®šé ç«¯å€‰åº«...\")\n                # ä½¿ç”¨é è¨­å€‰åº« URLï¼ˆç”¨æˆ¶éœ€è¦ä¿®æ”¹ç‚ºè‡ªå·±çš„å€‰åº«ï¼‰\n                default_repo = \"https://github.com/exoplanet-spaceapps/exoplanet-starter.git\"\n                subprocess.run(['git', 'remote', 'add', 'origin', default_repo], check=True)\n                print(f\"   âœ… é ç«¯å€‰åº«è¨­å®š: {default_repo}\")\n                print(\"   ğŸ’¡ è«‹ç¢ºä¿ä½ æœ‰è©²å€‰åº«çš„å¯«å…¥æ¬Šé™ï¼Œæˆ–ä¿®æ”¹ç‚ºä½ çš„å€‰åº«\")\n            else:\n                print(f\"   âœ… é ç«¯å€‰åº«å·²è¨­å®š: {remote_check.stdout.strip()}\")\n        except Exception as e:\n            print(f\"   âš ï¸ é ç«¯å€‰åº«è¨­å®šè­¦å‘Š: {e}\")\n\n    except Exception as e:\n        print(f\"   âŒ Git è¨­å®šå¤±æ•—: {e}\")\n        return False\n\n    # æ­¥é©Ÿ 4: Git LFS è¨­å®š\n    print(\"\\nğŸ“‹ æ­¥é©Ÿ 2/4: Git LFS è¨­å®š...\")\n\n    try:\n        # å®‰è£ Git LFSï¼ˆColabï¼‰\n        if IN_COLAB:\n            print(\"   ğŸ“¦ åœ¨ Colab ä¸­å®‰è£ Git LFS...\")\n            subprocess.run(['apt-get', 'update', '-qq'], check=True)\n            subprocess.run(['apt-get', 'install', '-y', '-qq', 'git-lfs'], check=True)\n            print(\"   âœ… Git LFS å·²å®‰è£\")\n\n        # åˆå§‹åŒ– LFS\n        try:\n            subprocess.run(['git', 'lfs', 'install'], check=True)\n            print(\"   âœ… Git LFS åˆå§‹åŒ–å®Œæˆ\")\n        except:\n            print(\"   âš ï¸ Git LFS åˆå§‹åŒ–è·³éï¼ˆå¯èƒ½å·²è¨­å®šï¼‰\")\n\n        # è¨­å®š LFS è¿½è¹¤ï¼ˆå®¹éŒ¯è™•ç†ï¼‰\n        lfs_patterns = ['*.csv', '*.json', '*.pkl', '*.parquet', '*.h5', '*.hdf5', '*.joblib']\n        for pattern in lfs_patterns:\n            try:\n                result = subprocess.run(['git', 'lfs', 'track', pattern],\n                                      capture_output=True, text=True)\n                if result.returncode == 0:\n                    print(f\"   ğŸ“¦ LFS è¿½è¹¤: {pattern}\")\n                else:\n                    print(f\"   âš ï¸ LFS è¿½è¹¤ {pattern} è­¦å‘Š: {result.stderr.strip()}\")\n            except Exception as e:\n                print(f\"   âš ï¸ LFS è¿½è¹¤ {pattern} è·³é: {e}\")\n\n        # æ·»åŠ  .gitattributes åˆ° staging\n        try:\n            subprocess.run(['git', 'add', '.gitattributes'], check=False)\n        except:\n            pass\n\n    except Exception as e:\n        print(f\"   âš ï¸ Git LFS è¨­å®šè­¦å‘Š: {e}\")\n        print(\"   ğŸ’¡ ç¹¼çºŒåŸ·è¡Œï¼Œä½†å¤§æª”æ¡ˆå¯èƒ½ç„¡æ³•æ­£ç¢ºè¿½è¹¤\")\n\n    # æ­¥é©Ÿ 5: æ·»åŠ æª”æ¡ˆä¸¦æäº¤\n    print(\"\\nğŸ“‹ æ­¥é©Ÿ 3/4: æ·»åŠ æª”æ¡ˆèˆ‡æäº¤...\")\n\n    try:\n        # ç¢ºä¿é‡è¦ç›®éŒ„å­˜åœ¨\n        important_dirs = ['data', 'notebooks', 'app', 'scripts', 'model', 'results']\n        for dir_name in important_dirs:\n            dir_path = Path(dir_name)\n            if dir_path.exists():\n                print(f\"   ğŸ“‚ æ‰¾åˆ°ç›®éŒ„: {dir_name}\")\n            elif IN_COLAB and dir_name in ['results']:\n                # åœ¨ Colab ä¸­å‰µå»ºç›¸é—œç›®éŒ„\n                dir_path.mkdir(parents=True, exist_ok=True)\n                print(f\"   ğŸ“‚ å‰µå»ºç›®éŒ„: {dir_name}\")\n\n        # æ·»åŠ æ‰€æœ‰æª”æ¡ˆ\n        subprocess.run(['git', 'add', '.'], check=True)\n        print(\"   âœ… æª”æ¡ˆæ·»åŠ å®Œæˆ\")\n\n        # æª¢æŸ¥æ˜¯å¦æœ‰è®Šæ›´\n        status_result = subprocess.run(['git', 'status', '--porcelain'],\n                                      capture_output=True, text=True, check=True)\n\n        if not status_result.stdout.strip():\n            print(\"   âœ… æ²’æœ‰æ–°çš„è®Šæ›´éœ€è¦æäº¤\")\n            return True\n\n        # å‰µå»ºæäº¤\n        commit_message = \"\"\"feat: complete new data inference pipeline with GPU optimization\n\n- ğŸ¯ å®Œæˆå–®ç›®æ¨™æ¨è«–: TIC â†’ MAST â†’ BLS/TLS â†’ æ©Ÿç‡é æ¸¬\n- ğŸ“Š å¯¦ç¾æ‰¹æ¬¡è™•ç†: å¤šå€‹ TIC ä¸¦è¡Œæ¨è«–èˆ‡çµæœæ’åº\n- ğŸ“ˆ å®Œæ•´è¦–è¦ºåŒ–: æ‘ºç–Šå…‰æ›²ç·šã€BLSåŠŸç‡è­œã€é æ¸¬åˆ†æ•¸åˆ†å¸ƒ\n- ğŸ–¥ï¸ GPU åµæ¸¬èˆ‡å„ªåŒ–: L4 GPU BFloat16 autocast åŠ é€Ÿç¤ºç¯„\n- â±ï¸ æ•ˆèƒ½æ¸¬è©¦: æ¨è«–å»¶é²æ™‚é–“èˆ‡ååé‡æ¸¬é‡\n- ğŸ’¾ çµæœåŒ¯å‡º: results/batch_inference.csv + metadata\n- ğŸ“‹ ç¶œåˆçµ±è¨ˆ: é«˜/ä¸­/ä½ä¿¡å¿ƒå€™é¸åˆ†æ\n- ğŸš€ ç”Ÿç”¢å°±ç·’: å®Œæ•´çš„æ–°è³‡æ–™æ¨è«–ç®¡ç·š\n\nCo-Authored-By: hctsai1006 <hctsai1006@gmail.com>\nğŸ¤– Generated with [Claude Code](https://claude.com/claude-code)\"\"\"\n\n        subprocess.run(['git', 'commit', '-m', commit_message], check=True)\n        print(\"   âœ… æäº¤å®Œæˆ\")\n\n    except subprocess.CalledProcessError as e:\n        print(f\"   âŒ æª”æ¡ˆæäº¤å¤±æ•—: {e}\")\n        return False\n    except Exception as e:\n        print(f\"   âŒ æª”æ¡ˆè™•ç†å¤±æ•—: {e}\")\n        return False\n\n    # æ­¥é©Ÿ 6: æ¨é€åˆ° GitHub\n    print(\"\\nğŸ“‹ æ­¥é©Ÿ 4/4: æ¨é€åˆ° GitHub...\")\n\n    try:\n        # ç²å–é ç«¯ URL ä¸¦æ’å…¥ token\n        remote_result = subprocess.run(['git', 'remote', 'get-url', 'origin'],\n                                      capture_output=True, text=True, check=True)\n        remote_url = remote_result.stdout.strip()\n\n        # æ§‹é€ å¸¶ token çš„ URL\n        if remote_url.startswith('https://github.com/'):\n            # æå–å€‰åº«è·¯å¾‘\n            repo_path = remote_url.replace('https://github.com/', '').replace('.git', '')\n            auth_url = f\"https://{token}@github.com/{repo_path}.git\"\n        else:\n            print(f\"   âš ï¸ é ç«¯ URL æ ¼å¼ç•°å¸¸: {remote_url}\")\n            auth_url = remote_url\n\n        # æ¨é€\n        push_result = subprocess.run([\n            'git', 'push', auth_url, 'main'\n        ], capture_output=True, text=True, timeout=300)\n\n        if push_result.returncode == 0:\n            print(\"   âœ… æ¨é€æˆåŠŸï¼\")\n            print(f\"   ğŸ“¡ æ¨é€è¼¸å‡º: {push_result.stdout[:200]}...\")\n            return True\n        else:\n            print(f\"   âŒ æ¨é€å¤±æ•—: {push_result.stderr}\")\n            # å˜—è©¦æ¨é€åˆ°å…¶ä»–åˆ†æ”¯\n            try:\n                alt_push = subprocess.run([\n                    'git', 'push', auth_url, 'HEAD:main'\n                ], capture_output=True, text=True, timeout=300)\n                if alt_push.returncode == 0:\n                    print(\"   âœ… å‚™ç”¨æ¨é€æˆåŠŸï¼\")\n                    return True\n            except:\n                pass\n            return False\n\n    except subprocess.TimeoutExpired:\n        print(\"   âŒ æ¨é€è¶…æ™‚ï¼Œè«‹æª¢æŸ¥ç¶²è·¯é€£æ¥\")\n        return False\n    except Exception as e:\n        print(f\"   âŒ æ¨é€å¤±æ•—: {e}\")\n        return False\n\n    finally:\n        print(\"\\n\" + \"=\" * 60)\n        print(\"ğŸ“‹ æ–°è³‡æ–™æ¨è«–çµæœæ¨é€å®Œæˆ!\")\n        if IN_COLAB:\n            print(\"ğŸ’¡ å¦‚æœé‡åˆ°å•é¡Œ:\")\n            print(\"   1. ç¢ºä¿ token æœ‰ 'repo' æ¬Šé™\")\n            print(\"   2. ç¢ºä¿ä½ æœ‰ç›®æ¨™å€‰åº«çš„å¯«å…¥æ¬Šé™\")\n            print(\"   3. æª¢æŸ¥å€‰åº« URL æ˜¯å¦æ­£ç¢º\")\n\n# å‘¼å«å‡½æ•¸ï¼ˆè«‹åœ¨åŸ·è¡Œæ™‚æä¾› tokenï¼‰\nprint(\"ğŸ” æº–å‚™æ¨é€æ–°è³‡æ–™æ¨è«–çµæœ...\")\nprint(\"ğŸ’¡ åŸ·è¡Œæ–¹å¼: ultimate_push_to_github_04(token='ä½ çš„GitHub_token')\")\nprint(\"ğŸ“ æˆ–ç›´æ¥åŸ·è¡Œä¸‹æ–¹ cell ä¸¦åœ¨æç¤ºæ™‚è¼¸å…¥ token\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## ğŸš€ GitHub Push çµ‚æ¥µè§£æ±ºæ–¹æ¡ˆ\n\nå°‡æ–°è³‡æ–™æ¨è«–çµæœæ¨é€åˆ° GitHub å€‰åº«ï¼š",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 Â· æ–°è³‡æ–™æ¨è«–ç®¡ç·šï¼ˆTIC â†’ MAST â†’ BLS/TLS â†’ æ©Ÿç‡ï¼‰\n",
    "\n",
    "## å·¥ä½œæµç¨‹\n",
    "1. **å–®ç›®æ¨™æ¨è«–**ï¼šè¼¸å…¥å–®å€‹ TIC â†’ ä¸‹è¼‰å…‰æ›²ç·š â†’ é æ¸¬æ©Ÿç‡\n",
    "2. **æ‰¹æ¬¡è™•ç†**ï¼šè¼¸å…¥ TIC åˆ—è¡¨ â†’ æ‰¹æ¬¡é æ¸¬ â†’ æ’åºè¼¸å‡º\n",
    "3. **è¦–è¦ºåŒ–**ï¼šæ‘ºç–Šå…‰æ›²ç·šã€BLS åŠŸç‡è­œã€é æ¸¬åˆ†æ•¸\n",
    "4. **GPU å„ªåŒ–**ï¼šåµæ¸¬ L4 GPU ä¸¦ç¤ºç¯„ bfloat16 autocast\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç’°å¢ƒè¨­å®šèˆ‡ä¾è³´å®‰è£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# æ­¥é©Ÿ 1: å®‰è£å¥—ä»¶ (éœ€è¦æ‰‹å‹•é‡å•Ÿ Runtime)\n# âš ï¸ é‡è¦: åŸ·è¡Œæ­¤ cell å¾Œï¼Œè«‹æ‰‹å‹•é‡å•Ÿ Runtime (Runtime â†’ Restart runtime)\n\n!pip install -q numpy==1.26.4 pandas astropy scipy'<1.13' matplotlib scikit-learn\n!pip install -q lightkurve astroquery xgboost joblib seaborn\n\nprint(\"âœ… å¥—ä»¶å®‰è£å®Œæˆ!\")\nprint(\"âš ï¸ è«‹ç¾åœ¨æ‰‹å‹•é‡å•Ÿ Runtime: Runtime â†’ Restart runtime\")\nprint(\"   ç„¶å¾Œç¹¼çºŒåŸ·è¡Œä¸‹ä¸€å€‹ cell\")"
  },
  {
   "cell_type": "code",
   "source": "# æ­¥é©Ÿ 2: é©—è­‰ç’°å¢ƒ (Runtime é‡å•Ÿå¾ŒåŸ·è¡Œ)\nimport numpy as np\nimport sys\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# æª¢æŸ¥ NumPy ç‰ˆæœ¬\nprint(f\"NumPy ç‰ˆæœ¬: {np.__version__}\")\nprint(f\"Python ç‰ˆæœ¬: {sys.version}\")\n\nif np.__version__.startswith('2.'):\n    print(\"âŒ NumPy 2.0 æª¢æ¸¬åˆ°ï¼è«‹ç¢ºèªå·²åŸ·è¡Œæ­¥é©Ÿ 1 ä¸¦é‡å•Ÿ Runtime\")\n    raise RuntimeError(\"è«‹å…ˆä¿®å¾© NumPy ç‰ˆæœ¬å•é¡Œ\")\nelse:\n    print(\"âœ… NumPy ç‰ˆæœ¬æ­£ç¢º (< 2.0)\")\n    \n# æª¢æŸ¥æ˜¯å¦åœ¨ Colab ç’°å¢ƒ\nIN_COLAB = 'google.colab' in sys.modules\n\nif IN_COLAB:\n    print(\"ğŸ“ åœ¨ Google Colab ç’°å¢ƒåŸ·è¡Œ\")\n    # Clone repository if needed\n    import os\n    if not os.path.exists('/content/exoplanet-starter'):\n        !git clone https://github.com/exoplanet-spaceapps/exoplanet-starter.git /content/exoplanet-starter\n        os.chdir('/content/exoplanet-starter')\n    sys.path.append('/content/exoplanet-starter')\nelse:\n    print(\"ğŸ’» åœ¨æœ¬åœ°ç’°å¢ƒåŸ·è¡Œ\")\n    import os\n    os.chdir(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n    sys.path.append(os.getcwd())\n\nprint(\"\\nâœ… ç’°å¢ƒè¨­å®šå®Œæˆï¼å¯ä»¥ç¹¼çºŒåŸ·è¡Œå¾ŒçºŒ cells\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. GPU åµæ¸¬èˆ‡å„ªåŒ–è¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU åµæ¸¬èˆ‡å„ªåŒ–è¨­å®š\n",
    "gpu_info = {\n",
    "    'available': False,\n",
    "    'device_name': None,\n",
    "    'is_l4': False,\n",
    "    'supports_bfloat16': False\n",
    "}\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        gpu_info['available'] = True\n",
    "        gpu_info['device_name'] = torch.cuda.get_device_name(0)\n",
    "        gpu_props = torch.cuda.get_device_properties(0)\n",
    "        \n",
    "        print(f\"ğŸ–¥ï¸ GPU åµæ¸¬çµæœ:\")\n",
    "        print(f\"   å‹è™Ÿ: {gpu_info['device_name']}\")\n",
    "        print(f\"   è¨˜æ†¶é«”: {gpu_props.total_memory / 1024**3:.2f} GB\")\n",
    "        print(f\"   CUDA é‹ç®—èƒ½åŠ›: {gpu_props.major}.{gpu_props.minor}\")\n",
    "        \n",
    "        # æª¢æŸ¥æ˜¯å¦ç‚º L4 GPU\n",
    "        if 'L4' in gpu_info['device_name']:\n",
    "            gpu_info['is_l4'] = True\n",
    "            gpu_info['supports_bfloat16'] = True\n",
    "            print(\"\\nğŸ’¡ åµæ¸¬åˆ° NVIDIA L4 GPUï¼\")\n",
    "            print(\"   â€¢ æ”¯æ´é«˜æ•ˆèƒ½ BF16 æ¨è«–\")\n",
    "            print(\"   â€¢ å»ºè­°ä½¿ç”¨ autocast é€²è¡ŒåŠ é€Ÿ\")\n",
    "        \n",
    "        # æª¢æŸ¥ bfloat16 æ”¯æ´\n",
    "        if hasattr(torch.cuda, 'is_bf16_supported'):\n",
    "            gpu_info['supports_bfloat16'] = torch.cuda.is_bf16_supported()\n",
    "            \n",
    "    else:\n",
    "        print(\"âš ï¸ æœªåµæ¸¬åˆ° CUDA GPU\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"âš ï¸ PyTorch æœªå®‰è£ï¼Œç„¡æ³•ä½¿ç”¨ GPU åŠ é€Ÿ\")\n",
    "    # å˜—è©¦ä½¿ç”¨ nvidia-smi\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'],\n",
    "            capture_output=True, text=True, check=False\n",
    "        )\n",
    "        if result.returncode == 0:\n",
    "            gpu_name, gpu_memory = result.stdout.strip().split(', ')\n",
    "            print(f\"\\nğŸ–¥ï¸ é€šé nvidia-smi åµæ¸¬åˆ° GPU:\")\n",
    "            print(f\"   å‹è™Ÿ: {gpu_name}\")\n",
    "            print(f\"   è¨˜æ†¶é«”: {gpu_memory}\")\n",
    "            if 'L4' in gpu_name:\n",
    "                gpu_info['is_l4'] = True\n",
    "                print(\"   ğŸ’¡ L4 GPU æ”¯æ´ BF16 åŠ é€Ÿ\")\n",
    "    except:\n",
    "        print(\"   å°‡ä½¿ç”¨ CPU é€²è¡Œæ¨è«–\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. è¼‰å…¥è¨“ç·´å¥½çš„æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¼‰å…¥æ¨¡å‹å’Œç›¸é—œæª”æ¡ˆ\n",
    "import joblib\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# æ¨¡å‹è·¯å¾‘\n",
    "model_dir = Path(\"model\")\n",
    "\n",
    "# æª¢æŸ¥æ¨¡å‹æª”æ¡ˆæ˜¯å¦å­˜åœ¨\n",
    "if not model_dir.exists():\n",
    "    print(\"âš ï¸ æ‰¾ä¸åˆ°æ¨¡å‹ç›®éŒ„ï¼Œè«‹å…ˆåŸ·è¡Œ 03_injection_train.ipynb è¨“ç·´æ¨¡å‹\")\n",
    "    print(\"   æˆ–ä¸‹è¼‰é è¨“ç·´æ¨¡å‹è‡³ model/ ç›®éŒ„\")\n",
    "else:\n",
    "    # è¼‰å…¥æ¨¡å‹\n",
    "    model_path = model_dir / \"ranker.joblib\"\n",
    "    scaler_path = model_dir / \"scaler.joblib\"\n",
    "    schema_path = model_dir / \"feature_schema.json\"\n",
    "    \n",
    "    if model_path.exists():\n",
    "        model = joblib.load(model_path)\n",
    "        print(f\"âœ… è¼‰å…¥æ¨¡å‹: {model_path}\")\n",
    "    else:\n",
    "        print(f\"âŒ æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆ: {model_path}\")\n",
    "        model = None\n",
    "    \n",
    "    if scaler_path.exists():\n",
    "        scaler = joblib.load(scaler_path)\n",
    "        print(f\"âœ… è¼‰å…¥æ¨™æº–åŒ–å™¨: {scaler_path}\")\n",
    "    else:\n",
    "        print(f\"âŒ æ‰¾ä¸åˆ°æ¨™æº–åŒ–å™¨: {scaler_path}\")\n",
    "        scaler = None\n",
    "    \n",
    "    if schema_path.exists():\n",
    "        with open(schema_path, 'r') as f:\n",
    "            schema = json.load(f)\n",
    "        feature_order = schema['feature_order']\n",
    "        print(f\"âœ… è¼‰å…¥ç‰¹å¾µæ¶æ§‹: {len(feature_order)} å€‹ç‰¹å¾µ\")\n",
    "    else:\n",
    "        print(f\"âŒ æ‰¾ä¸åˆ°ç‰¹å¾µæ¶æ§‹: {schema_path}\")\n",
    "        schema = None\n",
    "        feature_order = None\n",
    "\n",
    "# æª¢æŸ¥æ˜¯å¦æœ‰ç›£ç£å¼æ¨¡å‹\n",
    "supervised_model_path = model_dir / \"supervised\" / \"ranker_supervised.joblib\"\n",
    "if supervised_model_path.exists():\n",
    "    print(f\"\\nğŸ“¦ ç™¼ç¾ç›£ç£å¼æ¨¡å‹: {supervised_model_path}\")\n",
    "    print(\"   å¯é¸æ“‡ä½¿ç”¨ç›£ç£å¼æ¨¡å‹é€²è¡Œæ¨è«–\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. å°å…¥æ¨è«–æ¨¡çµ„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å°å…¥æ¨è«–æ¨¡çµ„\n",
    "from app.infer import (\n",
    "    predict_from_tic,\n",
    "    predict_batch,\n",
    "    create_folded_lightcurve_plot,\n",
    "    save_inference_results,\n",
    "    check_gpu_availability\n",
    ")\n",
    "\n",
    "from app.bls_features import run_bls, extract_features\n",
    "\n",
    "# å°å…¥è¦–è¦ºåŒ–å¥—ä»¶\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"ğŸ“š æ¨¡çµ„è¼‰å…¥å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. å–®ç›®æ¨™æ¨è«–ç¤ºç¯„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å–®å€‹ TIC æ¨è«–ç¤ºç¯„\n",
    "print(\"ğŸ¯ å–®ç›®æ¨™æ¨è«–ç¤ºç¯„\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ç›®æ¨™ TICï¼ˆå¯æ›´æ›ï¼‰\n",
    "tic_id = \"TIC 25155310\"  # TOI-431ï¼Œå·²çŸ¥çš„å¤šè¡Œæ˜Ÿç³»çµ±\n",
    "\n",
    "# åŸ·è¡Œæ¨è«–\n",
    "result = predict_from_tic(\n",
    "    tic_id,\n",
    "    model_path=\"model/ranker.joblib\",\n",
    "    scaler_path=\"model/scaler.joblib\",\n",
    "    feature_schema_path=\"model/feature_schema.json\",\n",
    "    mission=\"TESS\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# é¡¯ç¤ºçµæœ\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š æ¨è«–çµæœ:\")\n",
    "print(f\"   ç›®æ¨™: {result['tic_id']}\")\n",
    "print(f\"   æˆåŠŸ: {result['success']}\")\n",
    "\n",
    "if result['success']:\n",
    "    print(f\"\\nğŸ¯ é æ¸¬æ©Ÿç‡: {result['probability']:.3f}\")\n",
    "    print(f\"\\nğŸ“ˆ BLS çµæœ:\")\n",
    "    print(f\"   é€±æœŸ: {result['bls_period']:.3f} å¤©\")\n",
    "    print(f\"   æ·±åº¦: {result['bls_depth']*1e6:.0f} ppm\")\n",
    "    print(f\"   SNR: {result['bls_snr']:.1f}\")\n",
    "    \n",
    "    # åˆ¤æ–·æ˜¯å¦ç‚ºé«˜ä¿¡å¿ƒå€™é¸\n",
    "    if result['probability'] > 0.8:\n",
    "        print(\"\\nâœ¨ é«˜ä¿¡å¿ƒè¡Œæ˜Ÿå€™é¸ï¼\")\n",
    "    elif result['probability'] > 0.5:\n",
    "        print(\"\\nğŸ“ ä¸­ç­‰ä¿¡å¿ƒå€™é¸\")\n",
    "    else:\n",
    "        print(\"\\nâ“ ä½ä¿¡å¿ƒå€™é¸\")\n",
    "else:\n",
    "    print(f\"\\nâŒ éŒ¯èª¤: {result['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. è¦–è¦ºåŒ–å…‰æ›²ç·š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¦–è¦ºåŒ–å…‰æ›²ç·šå’Œ BLS çµæœ\n",
    "if result['success'] and result['lightcurve'] is not None:\n",
    "    import lightkurve as lk\n",
    "    \n",
    "    # ç²å–å…‰æ›²ç·šè³‡æ–™\n",
    "    time = np.array(result['lightcurve']['time'])\n",
    "    flux = np.array(result['lightcurve']['flux'])\n",
    "    period = result['bls_period']\n",
    "    \n",
    "    # å‰µå»ºåœ–è¡¨\n",
    "    fig = plt.figure(figsize=(15, 12))\n",
    "    \n",
    "    # 1. åŸå§‹å…‰æ›²ç·š\n",
    "    ax1 = plt.subplot(3, 2, 1)\n",
    "    ax1.plot(time, flux, 'k.', alpha=0.3, markersize=1)\n",
    "    ax1.set_xlabel('æ™‚é–“ (å¤©)')\n",
    "    ax1.set_ylabel('ç›¸å°æµé‡')\n",
    "    ax1.set_title(f'{result[\"tic_id\"]} - å»è¶¨å‹¢å¾Œå…‰æ›²ç·š')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. BLS åŠŸç‡è­œ\n",
    "    ax2 = plt.subplot(3, 2, 2)\n",
    "    # é‡æ–°è¨ˆç®— BLS ä»¥ç²å¾—å®Œæ•´åŠŸç‡è­œ\n",
    "    lc_obj = lk.LightCurve(time=time, flux=flux)\n",
    "    bls = lc_obj.to_periodogram(method=\"bls\", minimum_period=0.5, maximum_period=20)\n",
    "    bls.plot(ax=ax2)\n",
    "    ax2.axvline(period, color='red', linestyle='--', alpha=0.7, label=f'æœ€ä½³é€±æœŸ: {period:.3f} å¤©')\n",
    "    ax2.set_title('BLS åŠŸç‡è­œ')\n",
    "    ax2.legend()\n",
    "    \n",
    "    # 3. æ‘ºç–Šå…‰æ›²ç·š\n",
    "    ax3 = plt.subplot(3, 2, 3)\n",
    "    folded_data = create_folded_lightcurve_plot(time, flux, period)\n",
    "    phase = np.array(folded_data['phase'])\n",
    "    flux_folded = np.array(folded_data['flux'])\n",
    "    \n",
    "    # ç¹ªè£½æ•£é»åœ–\n",
    "    ax3.plot(phase, flux_folded, 'k.', alpha=0.2, markersize=1)\n",
    "    \n",
    "    # ç¹ªè£½åˆ†ç®±å¹³å‡\n",
    "    if folded_data['binned_phase']:\n",
    "        ax3.plot(folded_data['binned_phase'], folded_data['binned_flux'], \n",
    "                'ro-', markersize=4, linewidth=1.5, label='åˆ†ç®±å¹³å‡')\n",
    "    \n",
    "    ax3.set_xlabel('ç›¸ä½')\n",
    "    ax3.set_ylabel('ç›¸å°æµé‡')\n",
    "    ax3.set_title(f'æ‘ºç–Šå…‰æ›²ç·š (P = {period:.3f} å¤©)')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.legend()\n",
    "    \n",
    "    # 4. æ”¾å¤§å‡Œæ—¥å€åŸŸ\n",
    "    ax4 = plt.subplot(3, 2, 4)\n",
    "    transit_mask = np.abs(phase) < 0.1  # åªé¡¯ç¤ºç›¸ä½ Â±0.1 çš„å€åŸŸ\n",
    "    ax4.plot(phase[transit_mask], flux_folded[transit_mask], 'k.', alpha=0.3, markersize=2)\n",
    "    ax4.set_xlabel('ç›¸ä½')\n",
    "    ax4.set_ylabel('ç›¸å°æµé‡')\n",
    "    ax4.set_title('å‡Œæ—¥å€åŸŸæ”¾å¤§')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    ax4.set_xlim(-0.1, 0.1)\n",
    "    \n",
    "    # 5. é æ¸¬æ©Ÿç‡æ¢å½¢åœ–\n",
    "    ax5 = plt.subplot(3, 2, 5)\n",
    "    prob = result['probability']\n",
    "    color = 'green' if prob > 0.8 else 'orange' if prob > 0.5 else 'red'\n",
    "    bars = ax5.bar(['è¡Œæ˜Ÿå€™é¸æ©Ÿç‡'], [prob], color=color, alpha=0.7)\n",
    "    ax5.set_ylim(0, 1)\n",
    "    ax5.set_ylabel('æ©Ÿç‡')\n",
    "    ax5.set_title(f'é æ¸¬æ©Ÿç‡: {prob:.3f}')\n",
    "    ax5.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # æ·»åŠ æ•¸å€¼æ¨™ç±¤\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax5.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.3f}',\n",
    "                ha='center', va='bottom', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 6. ç‰¹å¾µé‡è¦æ€§\n",
    "    ax6 = plt.subplot(3, 2, 6)\n",
    "    # é¡¯ç¤ºé—œéµç‰¹å¾µ\n",
    "    features = result['features']\n",
    "    key_features = {\n",
    "        'BLS SNR': features.get('bls_snr', 0),\n",
    "        'é€±æœŸ': features.get('bls_period', 0),\n",
    "        'æ·±åº¦ (ppm)': features.get('bls_depth', 0) * 1e6,\n",
    "        'å¥‡å¶å·®ç•°': features.get('odd_even_depth_diff', 0) * 1e6,\n",
    "        'å°ç¨±æ€§': features.get('transit_symmetry', 0)\n",
    "    }\n",
    "    \n",
    "    y_pos = np.arange(len(key_features))\n",
    "    values = list(key_features.values())\n",
    "    labels = list(key_features.keys())\n",
    "    \n",
    "    ax6.barh(y_pos, values, color='skyblue', alpha=0.7)\n",
    "    ax6.set_yticks(y_pos)\n",
    "    ax6.set_yticklabels(labels)\n",
    "    ax6.set_xlabel('æ•¸å€¼')\n",
    "    ax6.set_title('é—œéµç‰¹å¾µå€¼')\n",
    "    ax6.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    plt.suptitle(f'{result[\"tic_id\"]} æ¨è«–çµæœè¦–è¦ºåŒ–', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nğŸ“ˆ è¦–è¦ºåŒ–å®Œæˆ\")\n",
    "else:\n",
    "    print(\"âš ï¸ ç„¡æ³•è¦–è¦ºåŒ–ï¼ˆæ¨è«–å¤±æ•—æˆ–ç„¡å…‰æ›²ç·šè³‡æ–™ï¼‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. æ‰¹æ¬¡æ¨è«–å¤šå€‹ç›®æ¨™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‰¹æ¬¡æ¨è«–å¤šå€‹ TIC\n",
    "print(\"ğŸ¯ æ‰¹æ¬¡æ¨è«–ç¤ºç¯„\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ç›®æ¨™åˆ—è¡¨ï¼ˆå¯è‡ªè¡Œä¿®æ”¹æˆ–æ“´å……ï¼‰\n",
    "tic_list = [\n",
    "    \"TIC 25155310\",  # TOI-431 (å·²çŸ¥å¤šè¡Œæ˜Ÿç³»çµ±)\n",
    "    \"TIC 307210830\", # TOI-270 (å·²çŸ¥ä¸‰è¡Œæ˜Ÿç³»çµ±)\n",
    "    \"TIC 260004324\", # TOI-178 (å·²çŸ¥å…­è¡Œæ˜Ÿç³»çµ±)\n",
    "    \"TIC 55652896\",  # TOI-125 (å·²çŸ¥ä¸‰è¡Œæ˜Ÿç³»çµ±)\n",
    "    \"TIC 441462736\", # å¯èƒ½çš„å‡é™½æ€§\n",
    "]\n",
    "\n",
    "print(f\"ğŸ“‹ æº–å‚™è™•ç† {len(tic_list)} å€‹ç›®æ¨™:\\n\")\n",
    "for i, tic in enumerate(tic_list, 1):\n",
    "    print(f\"   {i}. {tic}\")\n",
    "\n",
    "print(\"\\né–‹å§‹æ‰¹æ¬¡æ¨è«–...\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# åŸ·è¡Œæ‰¹æ¬¡æ¨è«–\n",
    "results_df = predict_batch(\n",
    "    tic_list,\n",
    "    model_path=\"model/ranker.joblib\",\n",
    "    scaler_path=\"model/scaler.joblib\",\n",
    "    feature_schema_path=\"model/feature_schema.json\",\n",
    "    mission=\"TESS\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. çµæœè¡¨æ ¼èˆ‡æ’åº"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é¡¯ç¤ºçµæœè¡¨æ ¼\n",
    "if len(results_df) > 0:\n",
    "    print(\"\\nğŸ“Š æ‰¹æ¬¡æ¨è«–çµæœï¼ˆæŒ‰æ©Ÿç‡æ’åºï¼‰:\\n\")\n",
    "    \n",
    "    # æ ¼å¼åŒ–é¡¯ç¤º\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    \n",
    "    # åªé¡¯ç¤ºé—œéµæ¬„ä½\n",
    "    display_columns = ['tic_id', 'probability', 'bls_period', 'bls_snr', 'bls_depth', 'success']\n",
    "    display_df = results_df[display_columns].copy()\n",
    "    \n",
    "    # æ ¼å¼åŒ–æ•¸å€¼\n",
    "    if 'probability' in display_df.columns:\n",
    "        display_df['probability'] = display_df['probability'].apply(lambda x: f\"{x:.3f}\" if pd.notna(x) else \"N/A\")\n",
    "    if 'bls_period' in display_df.columns:\n",
    "        display_df['bls_period'] = display_df['bls_period'].apply(lambda x: f\"{x:.3f}\" if pd.notna(x) else \"N/A\")\n",
    "    if 'bls_snr' in display_df.columns:\n",
    "        display_df['bls_snr'] = display_df['bls_snr'].apply(lambda x: f\"{x:.1f}\" if pd.notna(x) else \"N/A\")\n",
    "    if 'bls_depth' in display_df.columns:\n",
    "        display_df['bls_depth'] = display_df['bls_depth'].apply(lambda x: f\"{x*1e6:.0f}\" if pd.notna(x) else \"N/A\")\n",
    "        display_df = display_df.rename(columns={'bls_depth': 'bls_depth_ppm'})\n",
    "    \n",
    "    print(display_df.to_string(index=False))\n",
    "    \n",
    "    # çµ±è¨ˆæ‘˜è¦\n",
    "    success_count = results_df['success'].sum()\n",
    "    high_conf = len(results_df[(results_df['success']) & (results_df['probability'] > 0.8)])\n",
    "    med_conf = len(results_df[(results_df['success']) & (results_df['probability'] > 0.5) & (results_df['probability'] <= 0.8)])\n",
    "    \n",
    "    print(\"\\nğŸ“ˆ çµ±è¨ˆæ‘˜è¦:\")\n",
    "    print(f\"   æˆåŠŸè™•ç†: {success_count}/{len(results_df)}\")\n",
    "    print(f\"   é«˜ä¿¡å¿ƒå€™é¸ (>0.8): {high_conf}\")\n",
    "    print(f\"   ä¸­ä¿¡å¿ƒå€™é¸ (0.5-0.8): {med_conf}\")\n",
    "    \n",
    "    # å„²å­˜çµæœ\n",
    "    output_path = save_inference_results(\n",
    "        results_df,\n",
    "        output_path=\"results/batch_inference.csv\",\n",
    "        include_metadata=True\n",
    "    )\n",
    "    print(f\"\\nğŸ’¾ çµæœå·²å„²å­˜è‡³: {output_path}\")\n",
    "else:\n",
    "    print(\"âš ï¸ ç„¡æ¨è«–çµæœ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. æ‰¹æ¬¡çµæœè¦–è¦ºåŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‰¹æ¬¡çµæœè¦–è¦ºåŒ–\n",
    "if len(results_df) > 0 and results_df['success'].any():\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # åªé¸æ“‡æˆåŠŸçš„çµæœ\n",
    "    success_df = results_df[results_df['success']].copy()\n",
    "    \n",
    "    # 1. æ©Ÿç‡åˆ†å¸ƒ\n",
    "    ax1 = axes[0, 0]\n",
    "    if 'probability' in success_df.columns:\n",
    "        probs = success_df['probability'].dropna()\n",
    "        bars = ax1.bar(range(len(probs)), probs.values, color='skyblue', alpha=0.7)\n",
    "        \n",
    "        # æ ¹æ“šæ©Ÿç‡è‘—è‰²\n",
    "        for i, (bar, prob) in enumerate(zip(bars, probs.values)):\n",
    "            if prob > 0.8:\n",
    "                bar.set_color('green')\n",
    "            elif prob > 0.5:\n",
    "                bar.set_color('orange')\n",
    "            else:\n",
    "                bar.set_color('red')\n",
    "        \n",
    "        ax1.set_xticks(range(len(probs)))\n",
    "        ax1.set_xticklabels([tid.replace('TIC ', '') for tid in success_df['tic_id'].values], rotation=45)\n",
    "        ax1.set_ylabel('æ©Ÿç‡')\n",
    "        ax1.set_title('é æ¸¬æ©Ÿç‡åˆ†å¸ƒ')\n",
    "        ax1.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "        ax1.axhline(y=0.8, color='gray', linestyle='--', alpha=0.5)\n",
    "        ax1.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # 2. é€±æœŸåˆ†å¸ƒ\n",
    "    ax2 = axes[0, 1]\n",
    "    if 'bls_period' in success_df.columns:\n",
    "        periods = success_df['bls_period'].dropna()\n",
    "        if len(periods) > 0:\n",
    "            ax2.scatter(periods.values, success_df.loc[periods.index, 'probability'].values,\n",
    "                       s=100, alpha=0.7, c=success_df.loc[periods.index, 'probability'].values,\n",
    "                       cmap='RdYlGn', vmin=0, vmax=1)\n",
    "            ax2.set_xlabel('BLS é€±æœŸ (å¤©)')\n",
    "            ax2.set_ylabel('é æ¸¬æ©Ÿç‡')\n",
    "            ax2.set_title('é€±æœŸ vs æ©Ÿç‡')\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "            # æ·»åŠ é¡è‰²æ¢\n",
    "            cbar = plt.colorbar(ax2.collections[0], ax=ax2)\n",
    "            cbar.set_label('æ©Ÿç‡')\n",
    "    \n",
    "    # 3. SNR åˆ†å¸ƒ\n",
    "    ax3 = axes[1, 0]\n",
    "    if 'bls_snr' in success_df.columns:\n",
    "        snrs = success_df['bls_snr'].dropna()\n",
    "        if len(snrs) > 0:\n",
    "            ax3.scatter(snrs.values, success_df.loc[snrs.index, 'probability'].values,\n",
    "                       s=100, alpha=0.7, c=success_df.loc[snrs.index, 'probability'].values,\n",
    "                       cmap='RdYlGn', vmin=0, vmax=1)\n",
    "            ax3.set_xlabel('BLS SNR')\n",
    "            ax3.set_ylabel('é æ¸¬æ©Ÿç‡')\n",
    "            ax3.set_title('SNR vs æ©Ÿç‡')\n",
    "            ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. æ·±åº¦åˆ†å¸ƒ\n",
    "    ax4 = axes[1, 1]\n",
    "    if 'bls_depth' in success_df.columns:\n",
    "        depths = success_df['bls_depth'].dropna() * 1e6  # è½‰æ›ç‚º ppm\n",
    "        if len(depths) > 0:\n",
    "            ax4.scatter(depths.values, success_df.loc[depths.index, 'probability'].values,\n",
    "                       s=100, alpha=0.7, c=success_df.loc[depths.index, 'probability'].values,\n",
    "                       cmap='RdYlGn', vmin=0, vmax=1)\n",
    "            ax4.set_xlabel('å‡Œæ—¥æ·±åº¦ (ppm)')\n",
    "            ax4.set_ylabel('é æ¸¬æ©Ÿç‡')\n",
    "            ax4.set_title('æ·±åº¦ vs æ©Ÿç‡')\n",
    "            ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('æ‰¹æ¬¡æ¨è«–çµæœåˆ†æ', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nğŸ“ˆ æ‰¹æ¬¡è¦–è¦ºåŒ–å®Œæˆ\")\n",
    "else:\n",
    "    print(\"âš ï¸ ç„¡æˆåŠŸçš„æ¨è«–çµæœå¯è¦–è¦ºåŒ–\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. GPU åŠ é€Ÿç¤ºç¯„ï¼ˆå¦‚æœ‰ L4ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU åŠ é€Ÿç¤ºç¯„ï¼ˆåƒ…ç•¶åµæ¸¬åˆ° L4 GPU æ™‚åŸ·è¡Œï¼‰\n",
    "if gpu_info['is_l4'] and gpu_info['supports_bfloat16']:\n",
    "    print(\"ğŸš€ L4 GPU BFloat16 åŠ é€Ÿç¤ºç¯„\\n\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        import torch\n",
    "        import torch.nn as nn\n",
    "        \n",
    "        # å‰µå»ºç¤ºç¯„ç¥ç¶“ç¶²è·¯\n",
    "        class ExoplanetNet(nn.Module):\n",
    "            def __init__(self, input_dim=14):\n",
    "                super().__init__()\n",
    "                self.fc1 = nn.Linear(input_dim, 64)\n",
    "                self.fc2 = nn.Linear(64, 32)\n",
    "                self.fc3 = nn.Linear(32, 1)\n",
    "                self.relu = nn.ReLU()\n",
    "                self.sigmoid = nn.Sigmoid()\n",
    "            \n",
    "            def forward(self, x):\n",
    "                x = self.relu(self.fc1(x))\n",
    "                x = self.relu(self.fc2(x))\n",
    "                x = self.sigmoid(self.fc3(x))\n",
    "                return x\n",
    "        \n",
    "        # åˆå§‹åŒ–æ¨¡å‹\n",
    "        device = torch.device('cuda')\n",
    "        model = ExoplanetNet().to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        # æº–å‚™ç¤ºç¯„è³‡æ–™\n",
    "        batch_size = 100\n",
    "        input_features = torch.randn(batch_size, 14).to(device)\n",
    "        \n",
    "        # æ¯”è¼ƒæ¨è«–é€Ÿåº¦\n",
    "        import time\n",
    "        \n",
    "        # 1. æ¨™æº– FP32 æ¨è«–\n",
    "        print(\"â±ï¸ FP32 æ¨è«–:\")\n",
    "        start_time = time.time()\n",
    "        with torch.no_grad():\n",
    "            for _ in range(1000):\n",
    "                output_fp32 = model(input_features)\n",
    "        torch.cuda.synchronize()\n",
    "        fp32_time = time.time() - start_time\n",
    "        print(f\"   è€—æ™‚: {fp32_time:.3f} ç§’\")\n",
    "        \n",
    "        # 2. BFloat16 autocast æ¨è«–\n",
    "        print(\"\\nâš¡ BFloat16 æ¨è«– (with autocast):\")\n",
    "        start_time = time.time()\n",
    "        with torch.no_grad():\n",
    "            with torch.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "                for _ in range(1000):\n",
    "                    output_bf16 = model(input_features)\n",
    "        torch.cuda.synchronize()\n",
    "        bf16_time = time.time() - start_time\n",
    "        print(f\"   è€—æ™‚: {bf16_time:.3f} ç§’\")\n",
    "        \n",
    "        # è¨ˆç®—åŠ é€Ÿæ¯”\n",
    "        speedup = fp32_time / bf16_time\n",
    "        print(f\"\\nğŸ† BFloat16 åŠ é€Ÿæ¯”: {speedup:.2f}x\")\n",
    "        \n",
    "        # æª¢æŸ¥æ•¸å€¼èª¤å·®\n",
    "        diff = torch.abs(output_fp32 - output_bf16.float()).mean().item()\n",
    "        print(f\"   å¹³å‡çµ•å°èª¤å·®: {diff:.6f}\")\n",
    "        \n",
    "        print(\"\\nğŸ’¡ çµè«–:\")\n",
    "        print(\"   â€¢ L4 GPU çš„ BFloat16 å¯é¡¯è‘—åŠ é€Ÿæ¨è«–\")\n",
    "        print(\"   â€¢ æ•¸å€¼ç²¾åº¦æå¤±æ¥µå°ï¼Œé©åˆç”Ÿç”¢éƒ¨ç½²\")\n",
    "        print(\"   â€¢ å»ºè­°åœ¨å¤§è¦æ¨¡æ‰¹æ¬¡æ¨è«–æ™‚ä½¿ç”¨\")\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"âš ï¸ éœ€è¦å®‰è£ PyTorch æ‰èƒ½åŸ·è¡Œ GPU åŠ é€Ÿç¤ºç¯„\")\n",
    "        print(\"   åŸ·è¡Œ: pip install torch\")\n",
    "else:\n",
    "    print(\"â„¹ï¸ GPU åŠ é€Ÿç¤ºç¯„\")\n",
    "    print(\"   â€¢ æœªåµæ¸¬åˆ° L4 GPU æˆ–ä¸æ”¯æ´ BFloat16\")\n",
    "    print(\"   â€¢ ç•¶å‰ä½¿ç”¨æ¨™æº– CPU/GPU æ¨è«–\")\n",
    "    print(\"   â€¢ è‹¥éœ€è¦åŠ é€Ÿï¼Œå»ºè­°ä½¿ç”¨ Google Colab L4 åŸ·è¡Œç’°å¢ƒ\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. ç¸½çµèˆ‡ä¸‹ä¸€æ­¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"ğŸ“Š æ¨è«–ç®¡ç·šåŸ·è¡Œç¸½çµ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "ğŸ¯ åŸ·è¡Œçµ±è¨ˆ:\n",
    "   â€¢ è™•ç†ç›®æ¨™æ•¸: {len(results_df) if 'results_df' in locals() else 0}\n",
    "   â€¢ æˆåŠŸæ¨è«–: {results_df['success'].sum() if 'results_df' in locals() else 0}\n",
    "   â€¢ é«˜ä¿¡å¿ƒå€™é¸: {len(results_df[(results_df['success']) & (results_df['probability'] > 0.8)]) if 'results_df' in locals() else 0}\n",
    "\n",
    "ğŸ–¥ï¸ é‹ç®—ç’°å¢ƒ:\n",
    "   â€¢ GPU: {'å¯ç”¨ - ' + gpu_info['device_name'] if gpu_info['available'] else 'ä¸å¯ç”¨'}\n",
    "   â€¢ L4 å„ªåŒ–: {'æ”¯æ´' if gpu_info['is_l4'] else 'ä¸æ”¯æ´'}\n",
    "   â€¢ BFloat16: {'æ”¯æ´' if gpu_info['supports_bfloat16'] else 'ä¸æ”¯æ´'}\n",
    "\n",
    "ğŸ“¦ è¼¸å‡ºæª”æ¡ˆ:\n",
    "   â€¢ æ‰¹æ¬¡çµæœ: results/batch_inference.csv\n",
    "   â€¢ å…ƒè³‡æ–™: results/batch_inference_metadata.json\n",
    "\n",
    "ğŸš€ ä¸‹ä¸€æ­¥å»ºè­°:\n",
    "   1. å°é«˜ä¿¡å¿ƒå€™é¸é€²è¡Œäººå·¥å¯©æŸ¥\n",
    "   2. æŸ¥è©¢ NASA Exoplanet Archive ç¢ºèªå·²çŸ¥è¡Œæ˜Ÿ\n",
    "   3. ä½¿ç”¨æ›´å¤š TESS æ‰‡å€è³‡æ–™é€²è¡Œé©—è­‰\n",
    "   4. ç”Ÿæˆå€™é¸åˆ¤è®€å¡ï¼ˆåŸ·è¡Œ app/report.pyï¼‰\n",
    "   5. éƒ¨ç½²ç‚º Web æ‡‰ç”¨ï¼ˆåŸ·è¡Œ web/app.pyï¼‰\n",
    "\n",
    "ğŸ“š ç›¸é—œè³‡æº:\n",
    "   â€¢ NASA Exoplanet Archive: https://exoplanetarchive.ipac.caltech.edu/\n",
    "   â€¢ TESS è³‡æ–™å…¥å£: https://mast.stsci.edu/portal/Mashup/Clients/Mast/Portal.html\n",
    "   â€¢ Lightkurve æ–‡ä»¶: https://docs.lightkurve.org/\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"âœ… æ¨è«–ç®¡ç·šå®Œæˆï¼\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}