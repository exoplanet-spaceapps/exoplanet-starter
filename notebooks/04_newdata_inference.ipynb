{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 Â· æ–°è³‡æ–™æ¨è«–ï¼ˆTIC -> æ©Ÿç‡ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# ç’°å¢ƒè¨­å®šèˆ‡ä¾è³´å®‰è£ï¼ˆColabï¼‰\nimport sys, subprocess, pkgutil, joblib, json\n\ndef pipi(*pkgs):\n    \"\"\"å®‰è£å¥—ä»¶çš„è¼”åŠ©å‡½å¼\"\"\"\n    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", *pkgs])\n\n# å®‰è£å¿…è¦å¥—ä»¶ï¼ˆé¿å… numpy 2.0 ç›¸å®¹æ€§å•é¡Œï¼‰\nprint(\"ğŸš€ æ­£åœ¨å®‰è£ä¾è³´å¥—ä»¶...\")\ntry:\n    import numpy as np\n    import lightkurve as lk\n    print(\"âœ… åŸºç¤å¥—ä»¶å·²å®‰è£\")\nexcept Exception:\n    pipi(\"numpy<2\", \"lightkurve\", \"astroquery\", \"scikit-learn\", \"matplotlib\", \"joblib\")\n    print(\"âœ… ä¾è³´å¥—ä»¶å®‰è£å®Œæˆ\")\n\n# æª¢æŸ¥ GPU è³‡è¨Š\nimport torch if 'torch' in [m.name for m in pkgutil.iter_modules()] else None\nif torch is not None and torch.cuda.is_available():\n    gpu_name = torch.cuda.get_device_name(0)\n    print(f\"ğŸ–¥ï¸ GPU å‹è™Ÿ: {gpu_name}\")\n    print(f\"   è¨˜æ†¶é«”: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n    \n    # å¦‚æœæ˜¯ NVIDIA L4ï¼Œæä¾›æ¨è«–å„ªåŒ–å»ºè­°\n    if \"L4\" in gpu_name:\n        print(\"ğŸ’¡ åµæ¸¬åˆ° NVIDIA L4 GPU - æ”¯æ´é«˜æ•ˆèƒ½ BF16 æ¨è«–\")\n        print(\"   è‹¥ä½¿ç”¨æ·±åº¦å­¸ç¿’æ¨¡å‹ï¼Œå»ºè­°ä½¿ç”¨ï¼š\")\n        print(\"   ```python\")\n        print(\"   with torch.autocast('cuda', dtype=torch.bfloat16):\")\n        print(\"       predictions = model(inputs)\")\n        print(\"   ```\")\nelse:\n    try:\n        # ä½¿ç”¨ nvidia-smi æª¢æŸ¥ GPU\n        result = subprocess.run(['nvidia-smi', '--query-gpu=name', '--format=csv,noheader'], \n                              capture_output=True, text=True, check=False)\n        if result.returncode == 0:\n            gpu_name = result.stdout.strip()\n            print(f\"ğŸ–¥ï¸ GPU å‹è™Ÿ: {gpu_name}\")\n            if \"L4\" in gpu_name:\n                print(\"ğŸ’¡ åµæ¸¬åˆ° NVIDIA L4 GPU - æ”¯æ´é«˜æ•ˆèƒ½ BF16 æ¨è«–\")\n    except:\n        print(\"âš ï¸ æœªåµæ¸¬åˆ° GPUï¼Œå°‡ä½¿ç”¨ CPU é€²è¡Œæ¨è«–\")\n\nprint(\"\\nç’°å¢ƒè¨­å®šå®Œæˆï¼æº–å‚™è¼‰å…¥æ¨¡å‹èˆ‡æ¨è«–...\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import lightkurve as lk, numpy as np, json, joblib\n",
    "from pathlib import Path\n",
    "model_path = \"/content/model/ranker.joblib\"\n",
    "schema_path = \"/content/model/feature_schema.json\"\n",
    "assert Path(model_path).exists(), \"è«‹å…ˆåœ¨ 03_injection_train.ipynb ç”¢ç”Ÿæ¨¡å‹\"\n",
    "pipe = joblib.load(model_path)\n",
    "schema = json.load(open(schema_path))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# åƒæ•¸\n",
    "TIC = \"TIC 25155310\"  # å¯æ›´æ›\n",
    "sr = lk.search_lightcurve(TIC, mission=\"TESS\", author=\"SPOC\")\n",
    "lc = sr.download().remove_nans()\n",
    "flat = lc.flatten(window_length=401)\n",
    "bls = flat.to_periodogram(method=\"bls\", minimum_period=0.5, maximum_period=20)\n",
    "feat = [bls.period_at_max_power.value, bls.duration_at_max_power.value, bls.max_power.value]\n",
    "import numpy as np\n",
    "prob = float(pipe.predict_proba(np.array(feat).reshape(1,-1))[:,1])\n",
    "prob"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# è¦–è¦ºåŒ–\n",
    "ax = bls.plot(); ax.set_title(\"BLS Power Spectrum\")\n",
    "folded = flat.fold(bls.period_at_max_power, bls.transit_time_at_max_power)\n",
    "ax = folded.plot(); ax.set_title(\"Folded Light Curve\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}