{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46576e12",
   "metadata": {
    "papermill": {
     "duration": 0.010157,
     "end_time": "2025-09-29T23:43:00.138504",
     "exception": false,
     "start_time": "2025-09-29T23:43:00.128347",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 04 Â· æ–°è³‡æ–™æ¨è«–ç®¡ç·šï¼ˆTIC â†’ MAST â†’ BLS/TLS â†’ æ©Ÿç‡ï¼‰\n",
    "\n",
    "## å·¥ä½œæµç¨‹\n",
    "1. **å–®ç›®æ¨™æ¨è«–**ï¼šè¼¸å…¥å–®å€‹ TIC â†’ ä¸‹è¼‰å…‰æ›²ç·š â†’ é æ¸¬æ©Ÿç‡\n",
    "2. **æ‰¹æ¬¡è™•ç†**ï¼šè¼¸å…¥ TIC åˆ—è¡¨ â†’ æ‰¹æ¬¡é æ¸¬ â†’ æ’åºè¼¸å‡º\n",
    "3. **è¦–è¦ºåŒ–**ï¼šæ‘ºç–Šå…‰æ›²ç·šã€BLS åŠŸç‡è­œã€é æ¸¬åˆ†æ•¸\n",
    "4. **GPU å„ªåŒ–**ï¼šåµæ¸¬ L4 GPU ä¸¦ç¤ºç¯„ bfloat16 autocast\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d167043",
   "metadata": {
    "papermill": {
     "duration": 0.008172,
     "end_time": "2025-09-29T23:43:00.153740",
     "exception": false,
     "start_time": "2025-09-29T23:43:00.145568",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. ç’°å¢ƒè¨­å®šèˆ‡ä¾è³´å®‰è£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1971b4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T23:43:00.168402Z",
     "iopub.status.busy": "2025-09-29T23:43:00.167790Z",
     "iopub.status.idle": "2025-09-29T23:43:05.702497Z",
     "shell.execute_reply": "2025-09-29T23:43:05.701621Z"
    },
    "papermill": {
     "duration": 5.543415,
     "end_time": "2025-09-29T23:43:05.703677",
     "exception": false,
     "start_time": "2025-09-29T23:43:00.160262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ç³»çµ±æ‰¾ä¸åˆ°æŒ‡å®šçš„æª”æ¡ˆã€‚\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å¥—ä»¶å®‰è£å®Œæˆ!\n",
      "âš ï¸ è«‹ç¾åœ¨æ‰‹å‹•é‡å•Ÿ Runtime: Runtime â†’ Restart runtime\n",
      "   ç„¶å¾Œç¹¼çºŒåŸ·è¡Œä¸‹ä¸€å€‹ cell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: \"'xgboost\": Expected package name at the start of dependency specifier\n",
      "    'xgboost\n",
      "    ^\n"
     ]
    }
   ],
   "source": [
    "# æ­¥é©Ÿ 1: å®‰è£å¥—ä»¶ (éœ€è¦æ‰‹å‹•é‡å•Ÿ Runtime)\n",
    "# âš ï¸ é‡è¦: åŸ·è¡Œæ­¤ cell å¾Œï¼Œè«‹æ‰‹å‹•é‡å•Ÿ Runtime (Runtime â†’ Restart runtime)\n",
    "\n",
    "!pip install -q numpy==1.26.4 pandas astropy scipy'<1.13' matplotlib scikit-learn\n",
    "!pip install -q lightkurve astroquery joblib seaborn\n",
    "!pip install -q 'xgboost>=2.0.0' plotly pyyaml\n",
    "\n",
    "print(\"âœ… å¥—ä»¶å®‰è£å®Œæˆ!\")\n",
    "print(\"âš ï¸ è«‹ç¾åœ¨æ‰‹å‹•é‡å•Ÿ Runtime: Runtime â†’ Restart runtime\")\n",
    "print(\"   ç„¶å¾Œç¹¼çºŒåŸ·è¡Œä¸‹ä¸€å€‹ cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e87d098",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T23:43:05.714701Z",
     "iopub.status.busy": "2025-09-29T23:43:05.713972Z",
     "iopub.status.idle": "2025-09-29T23:43:05.723092Z",
     "shell.execute_reply": "2025-09-29T23:43:05.721945Z"
    },
    "papermill": {
     "duration": 0.015847,
     "end_time": "2025-09-29T23:43:05.724772",
     "exception": false,
     "start_time": "2025-09-29T23:43:05.708925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in: Local environment\n",
      "Project directory: C:\\Users\\thc1006\\Desktop\\dev\\exoplanet-starter\n"
     ]
    }
   ],
   "source": [
    "# Environment Detection\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Detect environment\n",
    "IN_COLAB = 'google.colab' in sys.modules or '/content' in os.getcwd()\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"Running in: Google Colab\")\n",
    "    \n",
    "    # Clone repo if needed\n",
    "    project_dir = Path('/content/exoplanet-starter')\n",
    "    if not project_dir.exists():\n",
    "        print(\"Cloning repository...\")\n",
    "        !git clone https://github.com/exoplanet-spaceapps/exoplanet-starter.git\n",
    "        print(\"Repository cloned\")\n",
    "    \n",
    "    # Change to project directory\n",
    "    os.chdir(str(project_dir))\n",
    "    \n",
    "    # Add to Python path\n",
    "    sys.path.insert(0, str(project_dir))\n",
    "    sys.path.insert(0, str(project_dir / 'src'))\n",
    "    sys.path.insert(0, str(project_dir / 'notebooks'))\n",
    "    \n",
    "    print(f\"Working directory: {os.getcwd()}\")\n",
    "    print(f\"Python path configured\")\n",
    "    \n",
    "else:\n",
    "    print(\"Running in: Local environment\")\n",
    "    # Local paths\n",
    "    project_dir = Path.cwd().parent if 'notebooks' in str(Path.cwd()) else Path.cwd()\n",
    "    sys.path.insert(0, str(project_dir / 'src'))\n",
    "    sys.path.insert(0, str(project_dir))\n",
    "\n",
    "print(f\"Project directory: {project_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "031a27b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T23:43:05.737254Z",
     "iopub.status.busy": "2025-09-29T23:43:05.736918Z",
     "iopub.status.idle": "2025-09-29T23:43:05.844154Z",
     "shell.execute_reply": "2025-09-29T23:43:05.842952Z"
    },
    "papermill": {
     "duration": 0.1157,
     "end_time": "2025-09-29T23:43:05.845733",
     "exception": false,
     "start_time": "2025-09-29T23:43:05.730033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy ç‰ˆæœ¬: 2.3.1\n",
      "Python ç‰ˆæœ¬: 3.13.5 (tags/v3.13.5:6cb20a2, Jun 11 2025, 16:15:46) [MSC v.1943 64 bit (AMD64)]\n",
      "âš ï¸ NumPy 2.0+ æª¢æ¸¬åˆ°ï¼æŸäº›å¥—ä»¶å¯èƒ½ä¸ç›¸å®¹\n",
      "   ç¹¼çºŒåŸ·è¡Œï¼Œä½†å¦‚é‡åˆ°éŒ¯èª¤è«‹è€ƒæ…®é™ç´šè‡³ NumPy 1.26.4\n",
      "ğŸ’» åœ¨æœ¬åœ°ç’°å¢ƒåŸ·è¡Œ\n",
      "\n",
      "âœ… ç’°å¢ƒè¨­å®šå®Œæˆï¼å¯ä»¥ç¹¼çºŒåŸ·è¡Œå¾ŒçºŒ cells\n"
     ]
    }
   ],
   "source": [
    "# æ­¥é©Ÿ 2: é©—è­‰ç’°å¢ƒ (Runtime é‡å•Ÿå¾ŒåŸ·è¡Œ)\n",
    "import numpy as np\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# æª¢æŸ¥ NumPy ç‰ˆæœ¬\n",
    "print(f\"NumPy ç‰ˆæœ¬: {np.__version__}\")\n",
    "print(f\"Python ç‰ˆæœ¬: {sys.version}\")\n",
    "\n",
    "# âš ï¸ NumPy 2.0+ compatibility: Continue with warning instead of failing\n",
    "if np.__version__.startswith('2.'):\n",
    "    print(\"âš ï¸ NumPy 2.0+ æª¢æ¸¬åˆ°ï¼æŸäº›å¥—ä»¶å¯èƒ½ä¸ç›¸å®¹\")\n",
    "    print(\"   ç¹¼çºŒåŸ·è¡Œï¼Œä½†å¦‚é‡åˆ°éŒ¯èª¤è«‹è€ƒæ…®é™ç´šè‡³ NumPy 1.26.4\")\n",
    "else:\n",
    "    print(\"âœ… NumPy ç‰ˆæœ¬æ­£ç¢º (< 2.0)\")\n",
    "    \n",
    "# æª¢æŸ¥æ˜¯å¦åœ¨ Colab ç’°å¢ƒ\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"ğŸ“ åœ¨ Google Colab ç’°å¢ƒåŸ·è¡Œ\")\n",
    "    # Clone repository if needed\n",
    "    import os\n",
    "    if not os.path.exists('/content/exoplanet-starter'):\n",
    "        !git clone https://github.com/exoplanet-spaceapps/exoplanet-starter.git /content/exoplanet-starter\n",
    "        os.chdir('/content/exoplanet-starter')\n",
    "    sys.path.append('/content/exoplanet-starter')\n",
    "else:\n",
    "    print(\"ğŸ’» åœ¨æœ¬åœ°ç’°å¢ƒåŸ·è¡Œ\")\n",
    "    import os\n",
    "    # Handle Windows paths properly\n",
    "    if '__file__' in globals():\n",
    "        parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "    else:\n",
    "        parent_dir = os.path.dirname(os.getcwd()) if 'notebooks' in os.getcwd() else os.getcwd()\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "print(\"\\nâœ… ç’°å¢ƒè¨­å®šå®Œæˆï¼å¯ä»¥ç¹¼çºŒåŸ·è¡Œå¾ŒçºŒ cells\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ed1c54",
   "metadata": {
    "papermill": {
     "duration": 0.010702,
     "end_time": "2025-09-29T23:43:05.863470",
     "exception": false,
     "start_time": "2025-09-29T23:43:05.852768",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. GPU åµæ¸¬èˆ‡å„ªåŒ–è¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a065451",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T23:43:05.887040Z",
     "iopub.status.busy": "2025-09-29T23:43:05.886333Z",
     "iopub.status.idle": "2025-09-29T23:43:08.427467Z",
     "shell.execute_reply": "2025-09-29T23:43:08.426943Z"
    },
    "papermill": {
     "duration": 2.552742,
     "end_time": "2025-09-29T23:43:08.428376",
     "exception": false,
     "start_time": "2025-09-29T23:43:05.875634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ–¥ï¸ GPU åµæ¸¬çµæœ:\n",
      "   å‹è™Ÿ: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "   è¨˜æ†¶é«”: 4.00 GB\n",
      "   CUDA é‹ç®—èƒ½åŠ›: 8.6\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# GPU åµæ¸¬èˆ‡å„ªåŒ–è¨­å®š\n",
    "gpu_info = {\n",
    "    'available': False,\n",
    "    'device_name': None,\n",
    "    'is_l4': False,\n",
    "    'supports_bfloat16': False\n",
    "}\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        gpu_info['available'] = True\n",
    "        gpu_info['device_name'] = torch.cuda.get_device_name(0)\n",
    "        gpu_props = torch.cuda.get_device_properties(0)\n",
    "        \n",
    "        print(f\"ğŸ–¥ï¸ GPU åµæ¸¬çµæœ:\")\n",
    "        print(f\"   å‹è™Ÿ: {gpu_info['device_name']}\")\n",
    "        print(f\"   è¨˜æ†¶é«”: {gpu_props.total_memory / 1024**3:.2f} GB\")\n",
    "        print(f\"   CUDA é‹ç®—èƒ½åŠ›: {gpu_props.major}.{gpu_props.minor}\")\n",
    "        \n",
    "        # æª¢æŸ¥æ˜¯å¦ç‚º L4 GPU\n",
    "        if 'L4' in gpu_info['device_name']:\n",
    "            gpu_info['is_l4'] = True\n",
    "            gpu_info['supports_bfloat16'] = True\n",
    "            print(\"\\nğŸ’¡ åµæ¸¬åˆ° NVIDIA L4 GPUï¼\")\n",
    "            print(\"   â€¢ æ”¯æ´é«˜æ•ˆèƒ½ BF16 æ¨è«–\")\n",
    "            print(\"   â€¢ å»ºè­°ä½¿ç”¨ autocast é€²è¡ŒåŠ é€Ÿ\")\n",
    "        \n",
    "        # æª¢æŸ¥ bfloat16 æ”¯æ´\n",
    "        if hasattr(torch.cuda, 'is_bf16_supported'):\n",
    "            gpu_info['supports_bfloat16'] = torch.cuda.is_bf16_supported()\n",
    "            \n",
    "    else:\n",
    "        print(\"âš ï¸ æœªåµæ¸¬åˆ° CUDA GPU\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"âš ï¸ PyTorch æœªå®‰è£ï¼Œç„¡æ³•ä½¿ç”¨ GPU åŠ é€Ÿ\")\n",
    "    # å˜—è©¦ä½¿ç”¨ nvidia-smi\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'],\n",
    "            capture_output=True, text=True, check=False\n",
    "        )\n",
    "        if result.returncode == 0:\n",
    "            gpu_name, gpu_memory = result.stdout.strip().split(', ')\n",
    "            print(f\"\\nğŸ–¥ï¸ é€šé nvidia-smi åµæ¸¬åˆ° GPU:\")\n",
    "            print(f\"   å‹è™Ÿ: {gpu_name}\")\n",
    "            print(f\"   è¨˜æ†¶é«”: {gpu_memory}\")\n",
    "            if 'L4' in gpu_name:\n",
    "                gpu_info['is_l4'] = True\n",
    "                print(\"   ğŸ’¡ L4 GPU æ”¯æ´ BF16 åŠ é€Ÿ\")\n",
    "    except:\n",
    "        print(\"   å°‡ä½¿ç”¨ CPU é€²è¡Œæ¨è«–\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e8e3b7",
   "metadata": {
    "papermill": {
     "duration": 0.003906,
     "end_time": "2025-09-29T23:43:08.436560",
     "exception": false,
     "start_time": "2025-09-29T23:43:08.432654",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. è¼‰å…¥è¨“ç·´å¥½çš„æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f129a6e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T23:43:08.445610Z",
     "iopub.status.busy": "2025-09-29T23:43:08.445271Z",
     "iopub.status.idle": "2025-09-29T23:43:10.072263Z",
     "shell.execute_reply": "2025-09-29T23:43:10.071230Z"
    },
    "papermill": {
     "duration": 1.637087,
     "end_time": "2025-09-29T23:43:10.077659",
     "exception": false,
     "start_time": "2025-09-29T23:43:08.440572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… è¼‰å…¥æ¨¡å‹: ..\\models\\xgboost_pipeline_cv.joblib\n",
      "âš ï¸ æ‰¾ä¸åˆ°ç‰¹å¾µæ¶æ§‹æª”æ¡ˆï¼Œå°‡ä½¿ç”¨é è¨­ç‰¹å¾µé †åº\n",
      "âœ… ä½¿ç”¨é è¨­ç‰¹å¾µæ¶æ§‹: 14 å€‹ç‰¹å¾µ\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# è¼‰å…¥æ¨¡å‹å’Œç›¸é—œæª”æ¡ˆ\n",
    "import joblib\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# æ¨¡å‹è·¯å¾‘ (ä¿®æ­£ç‚ºå¯¦éš›è·¯å¾‘)\n",
    "model_dir = Path(\"../models\")  # ä½¿ç”¨ models/ è€Œé model/\n",
    "\n",
    "# æª¢æŸ¥æ¨¡å‹æª”æ¡ˆæ˜¯å¦å­˜åœ¨\n",
    "if not model_dir.exists():\n",
    "    print(\"âš ï¸ æ‰¾ä¸åˆ°æ¨¡å‹ç›®éŒ„ï¼Œè«‹å…ˆåŸ·è¡Œ 03_injection_train.ipynb è¨“ç·´æ¨¡å‹\")\n",
    "    print(\"   æˆ–ä¸‹è¼‰é è¨“ç·´æ¨¡å‹è‡³ models/ ç›®éŒ„\")\n",
    "    model = None\n",
    "    scaler = None\n",
    "    schema = None\n",
    "    feature_order = None\n",
    "else:\n",
    "    # è¼‰å…¥æ¨¡å‹ (ä½¿ç”¨å¯¦éš›å­˜åœ¨çš„æ¨¡å‹æª”æ¡ˆ)\n",
    "    model_path = model_dir / \"xgboost_pipeline_cv.joblib\"\n",
    "    \n",
    "    if model_path.exists():\n",
    "        model = joblib.load(model_path)\n",
    "        print(f\"âœ… è¼‰å…¥æ¨¡å‹: {model_path}\")\n",
    "        \n",
    "        # XGBoost pipeline includes scaler, extract it\n",
    "        if hasattr(model, 'named_steps'):\n",
    "            scaler = model.named_steps.get('scaler', None)\n",
    "            if scaler:\n",
    "                print(f\"âœ… å¾ pipeline æå–æ¨™æº–åŒ–å™¨\")\n",
    "        else:\n",
    "            scaler = None\n",
    "            print(f\"âš ï¸ æ¨¡å‹ä¸åŒ…å«æ¨™æº–åŒ–å™¨\")\n",
    "        \n",
    "        # Try to infer feature order from model\n",
    "        feature_order = None\n",
    "        schema = None\n",
    "        print(f\"âš ï¸ æ‰¾ä¸åˆ°ç‰¹å¾µæ¶æ§‹æª”æ¡ˆï¼Œå°‡ä½¿ç”¨é è¨­ç‰¹å¾µé †åº\")\n",
    "        \n",
    "        # å‡è¨­ä½¿ç”¨æ¨™æº–çš„ BLS ç‰¹å¾µé †åº\n",
    "        feature_order = [\n",
    "            'bls_period', 'bls_duration', 'bls_depth', 'bls_snr', 'bls_power',\n",
    "            'odd_even_mismatch', 'secondary_power_ratio', 'harmonic_delta_chisq',\n",
    "            'periodicity_strength', 'transit_symmetry', 'odd_even_depth_diff',\n",
    "            'phase_coverage', 'ingress_egress_asymmetry', 'v_shape_indicator'\n",
    "        ]\n",
    "        print(f\"âœ… ä½¿ç”¨é è¨­ç‰¹å¾µæ¶æ§‹: {len(feature_order)} å€‹ç‰¹å¾µ\")\n",
    "    else:\n",
    "        print(f\"âŒ æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆ: {model_path}\")\n",
    "        model = None\n",
    "        scaler = None\n",
    "        schema = None\n",
    "        feature_order = None\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aaaa36",
   "metadata": {
    "papermill": {
     "duration": 0.007308,
     "end_time": "2025-09-29T23:43:10.094098",
     "exception": false,
     "start_time": "2025-09-29T23:43:10.086790",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. å°å…¥æ¨è«–æ¨¡çµ„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b19f21d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T23:43:10.118249Z",
     "iopub.status.busy": "2025-09-29T23:43:10.117472Z",
     "iopub.status.idle": "2025-09-29T23:43:12.311285Z",
     "shell.execute_reply": "2025-09-29T23:43:12.310779Z"
    },
    "papermill": {
     "duration": 2.209438,
     "end_time": "2025-09-29T23:43:12.312146",
     "exception": false,
     "start_time": "2025-09-29T23:43:10.102708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“š æ¨¡çµ„è¼‰å…¥å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# å°å…¥æ¨è«–æ¨¡çµ„\n",
    "from app.infer import (\n",
    "    predict_from_tic,\n",
    "    predict_batch,\n",
    "    create_folded_lightcurve_plot,\n",
    "    save_inference_results,\n",
    "    check_gpu_availability\n",
    ")\n",
    "\n",
    "from app.bls_features import run_bls, extract_features\n",
    "\n",
    "# å°å…¥è¦–è¦ºåŒ–å¥—ä»¶\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"ğŸ“š æ¨¡çµ„è¼‰å…¥å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee11728",
   "metadata": {
    "papermill": {
     "duration": 0.003431,
     "end_time": "2025-09-29T23:43:12.320370",
     "exception": false,
     "start_time": "2025-09-29T23:43:12.316939",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. å–®ç›®æ¨™æ¨è«–ç¤ºç¯„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dd29191",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T23:43:12.329139Z",
     "iopub.status.busy": "2025-09-29T23:43:12.328614Z",
     "iopub.status.idle": "2025-09-29T23:44:11.846046Z",
     "shell.execute_reply": "2025-09-29T23:44:11.845339Z"
    },
    "papermill": {
     "duration": 59.523169,
     "end_time": "2025-09-29T23:44:11.847494",
     "exception": false,
     "start_time": "2025-09-29T23:43:12.324325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ å–®ç›®æ¨™æ¨è«–ç¤ºç¯„\n",
      "\n",
      "============================================================\n",
      "ğŸ” è™•ç†ç›®æ¨™: TIC 25155310\n",
      "   ä¸‹è¼‰å…‰æ›²ç·š...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   æ¸…ç†å’Œå»è¶¨å‹¢...\n",
      "   åŸ·è¡Œ BLS æœå°‹...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   æå–ç‰¹å¾µ...\n",
      "   è¼‰å…¥æ¨¡å‹...\n",
      "   âš ï¸ æœªæ‰¾åˆ°æ¨™æº–åŒ–å™¨ï¼Œè·³éç‰¹å¾µæ¨™æº–åŒ–\n",
      "   ä½¿ç”¨é è¨­ç‰¹å¾µé †åº (14 å€‹ç‰¹å¾µ)\n",
      "   âŒ éŒ¯èª¤: X has 14 features, but ColumnTransformer is expecting 6 features as input.\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š æ¨è«–çµæœ:\n",
      "   ç›®æ¨™: TIC 25155310\n",
      "   æˆåŠŸ: False\n",
      "\n",
      "âŒ éŒ¯èª¤: X has 14 features, but ColumnTransformer is expecting 6 features as input.\n"
     ]
    }
   ],
   "source": [
    "# å–®å€‹ TIC æ¨è«–ç¤ºç¯„\n",
    "print(\"ğŸ¯ å–®ç›®æ¨™æ¨è«–ç¤ºç¯„\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ç›®æ¨™ TICï¼ˆå¯æ›´æ›ï¼‰\n",
    "tic_id = \"TIC 25155310\"  # TOI-431ï¼Œå·²çŸ¥çš„å¤šè¡Œæ˜Ÿç³»çµ±\n",
    "\n",
    "# åŸ·è¡Œæ¨è«– (ä½¿ç”¨æ­£ç¢ºçš„æ¨¡å‹è·¯å¾‘)\n",
    "result = predict_from_tic(\n",
    "    tic_id,\n",
    "    model_path=\"../models/xgboost_pipeline_cv.joblib\",\n",
    "    scaler_path=None,  # Scaler is in the pipeline\n",
    "    feature_schema_path=None,  # Use default feature order\n",
    "    mission=\"TESS\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# é¡¯ç¤ºçµæœ\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š æ¨è«–çµæœ:\")\n",
    "print(f\"   ç›®æ¨™: {result['tic_id']}\")\n",
    "print(f\"   æˆåŠŸ: {result['success']}\")\n",
    "\n",
    "if result['success']:\n",
    "    print(f\"\\nğŸ¯ é æ¸¬æ©Ÿç‡: {result['probability']:.3f}\")\n",
    "    print(f\"\\nğŸ“ˆ BLS çµæœ:\")\n",
    "    print(f\"   é€±æœŸ: {result['bls_period']:.3f} å¤©\")\n",
    "    print(f\"   æ·±åº¦: {result['bls_depth']*1e6:.0f} ppm\")\n",
    "    print(f\"   SNR: {result['bls_snr']:.1f}\")\n",
    "    \n",
    "    # åˆ¤æ–·æ˜¯å¦ç‚ºé«˜ä¿¡å¿ƒå€™é¸\n",
    "    if result['probability'] > 0.8:\n",
    "        print(\"\\nâœ¨ é«˜ä¿¡å¿ƒè¡Œæ˜Ÿå€™é¸ï¼\")\n",
    "    elif result['probability'] > 0.5:\n",
    "        print(\"\\nğŸ“ ä¸­ç­‰ä¿¡å¿ƒå€™é¸\")\n",
    "    else:\n",
    "        print(\"\\nâ“ ä½ä¿¡å¿ƒå€™é¸\")\n",
    "else:\n",
    "    print(f\"\\nâŒ éŒ¯èª¤: {result['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e174bdd",
   "metadata": {
    "papermill": {
     "duration": 0.005298,
     "end_time": "2025-09-29T23:44:11.859332",
     "exception": false,
     "start_time": "2025-09-29T23:44:11.854034",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6. è¦–è¦ºåŒ–å…‰æ›²ç·š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8af3a35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T23:44:11.874673Z",
     "iopub.status.busy": "2025-09-29T23:44:11.874225Z",
     "iopub.status.idle": "2025-09-29T23:44:11.885916Z",
     "shell.execute_reply": "2025-09-29T23:44:11.885333Z"
    },
    "papermill": {
     "duration": 0.019756,
     "end_time": "2025-09-29T23:44:11.886873",
     "exception": false,
     "start_time": "2025-09-29T23:44:11.867117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ ç„¡æ³•è¦–è¦ºåŒ–ï¼ˆæ¨è«–å¤±æ•—æˆ–ç„¡å…‰æ›²ç·šè³‡æ–™ï¼‰\n"
     ]
    }
   ],
   "source": [
    "# è¦–è¦ºåŒ–å…‰æ›²ç·šå’Œ BLS çµæœ\n",
    "if result['success'] and result['lightcurve'] is not None:\n",
    "    import lightkurve as lk\n",
    "    \n",
    "    # ç²å–å…‰æ›²ç·šè³‡æ–™\n",
    "    time = np.array(result['lightcurve']['time'])\n",
    "    flux = np.array(result['lightcurve']['flux'])\n",
    "    period = result['bls_period']\n",
    "    \n",
    "    # å‰µå»ºåœ–è¡¨\n",
    "    fig = plt.figure(figsize=(15, 12))\n",
    "    \n",
    "    # 1. åŸå§‹å…‰æ›²ç·š\n",
    "    ax1 = plt.subplot(3, 2, 1)\n",
    "    ax1.plot(time, flux, 'k.', alpha=0.3, markersize=1)\n",
    "    ax1.set_xlabel('æ™‚é–“ (å¤©)')\n",
    "    ax1.set_ylabel('ç›¸å°æµé‡')\n",
    "    ax1.set_title(f'{result[\"tic_id\"]} - å»è¶¨å‹¢å¾Œå…‰æ›²ç·š')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. BLS åŠŸç‡è­œ\n",
    "    ax2 = plt.subplot(3, 2, 2)\n",
    "    # é‡æ–°è¨ˆç®— BLS ä»¥ç²å¾—å®Œæ•´åŠŸç‡è­œ\n",
    "    lc_obj = lk.LightCurve(time=time, flux=flux)\n",
    "    bls = lc_obj.to_periodogram(method=\"bls\", minimum_period=0.5, maximum_period=20)\n",
    "    bls.plot(ax=ax2)\n",
    "    ax2.axvline(period, color='red', linestyle='--', alpha=0.7, label=f'æœ€ä½³é€±æœŸ: {period:.3f} å¤©')\n",
    "    ax2.set_title('BLS åŠŸç‡è­œ')\n",
    "    ax2.legend()\n",
    "    \n",
    "    # 3. æ‘ºç–Šå…‰æ›²ç·š\n",
    "    ax3 = plt.subplot(3, 2, 3)\n",
    "    folded_data = create_folded_lightcurve_plot(time, flux, period)\n",
    "    phase = np.array(folded_data['phase'])\n",
    "    flux_folded = np.array(folded_data['flux'])\n",
    "    \n",
    "    # ç¹ªè£½æ•£é»åœ–\n",
    "    ax3.plot(phase, flux_folded, 'k.', alpha=0.2, markersize=1)\n",
    "    \n",
    "    # ç¹ªè£½åˆ†ç®±å¹³å‡\n",
    "    if folded_data['binned_phase']:\n",
    "        ax3.plot(folded_data['binned_phase'], folded_data['binned_flux'], \n",
    "                'ro-', markersize=4, linewidth=1.5, label='åˆ†ç®±å¹³å‡')\n",
    "    \n",
    "    ax3.set_xlabel('ç›¸ä½')\n",
    "    ax3.set_ylabel('ç›¸å°æµé‡')\n",
    "    ax3.set_title(f'æ‘ºç–Šå…‰æ›²ç·š (P = {period:.3f} å¤©)')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.legend()\n",
    "    \n",
    "    # 4. æ”¾å¤§å‡Œæ—¥å€åŸŸ\n",
    "    ax4 = plt.subplot(3, 2, 4)\n",
    "    transit_mask = np.abs(phase) < 0.1  # åªé¡¯ç¤ºç›¸ä½ Â±0.1 çš„å€åŸŸ\n",
    "    ax4.plot(phase[transit_mask], flux_folded[transit_mask], 'k.', alpha=0.3, markersize=2)\n",
    "    ax4.set_xlabel('ç›¸ä½')\n",
    "    ax4.set_ylabel('ç›¸å°æµé‡')\n",
    "    ax4.set_title('å‡Œæ—¥å€åŸŸæ”¾å¤§')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    ax4.set_xlim(-0.1, 0.1)\n",
    "    \n",
    "    # 5. é æ¸¬æ©Ÿç‡æ¢å½¢åœ–\n",
    "    ax5 = plt.subplot(3, 2, 5)\n",
    "    prob = result['probability']\n",
    "    color = 'green' if prob > 0.8 else 'orange' if prob > 0.5 else 'red'\n",
    "    bars = ax5.bar(['è¡Œæ˜Ÿå€™é¸æ©Ÿç‡'], [prob], color=color, alpha=0.7)\n",
    "    ax5.set_ylim(0, 1)\n",
    "    ax5.set_ylabel('æ©Ÿç‡')\n",
    "    ax5.set_title(f'é æ¸¬æ©Ÿç‡: {prob:.3f}')\n",
    "    ax5.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # æ·»åŠ æ•¸å€¼æ¨™ç±¤\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax5.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.3f}',\n",
    "                ha='center', va='bottom', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 6. ç‰¹å¾µé‡è¦æ€§\n",
    "    ax6 = plt.subplot(3, 2, 6)\n",
    "    # é¡¯ç¤ºé—œéµç‰¹å¾µ\n",
    "    features = result['features']\n",
    "    key_features = {\n",
    "        'BLS SNR': features.get('bls_snr', 0),\n",
    "        'é€±æœŸ': features.get('bls_period', 0),\n",
    "        'æ·±åº¦ (ppm)': features.get('bls_depth', 0) * 1e6,\n",
    "        'å¥‡å¶å·®ç•°': features.get('odd_even_depth_diff', 0) * 1e6,\n",
    "        'å°ç¨±æ€§': features.get('transit_symmetry', 0)\n",
    "    }\n",
    "    \n",
    "    y_pos = np.arange(len(key_features))\n",
    "    values = list(key_features.values())\n",
    "    labels = list(key_features.keys())\n",
    "    \n",
    "    ax6.barh(y_pos, values, color='skyblue', alpha=0.7)\n",
    "    ax6.set_yticks(y_pos)\n",
    "    ax6.set_yticklabels(labels)\n",
    "    ax6.set_xlabel('æ•¸å€¼')\n",
    "    ax6.set_title('é—œéµç‰¹å¾µå€¼')\n",
    "    ax6.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    plt.suptitle(f'{result[\"tic_id\"]} æ¨è«–çµæœè¦–è¦ºåŒ–', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nğŸ“ˆ è¦–è¦ºåŒ–å®Œæˆ\")\n",
    "else:\n",
    "    print(\"âš ï¸ ç„¡æ³•è¦–è¦ºåŒ–ï¼ˆæ¨è«–å¤±æ•—æˆ–ç„¡å…‰æ›²ç·šè³‡æ–™ï¼‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1345729",
   "metadata": {
    "papermill": {
     "duration": 0.004996,
     "end_time": "2025-09-29T23:44:11.896765",
     "exception": false,
     "start_time": "2025-09-29T23:44:11.891769",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 7. æ‰¹æ¬¡æ¨è«–å¤šå€‹ç›®æ¨™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eba7e89f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T23:44:11.909689Z",
     "iopub.status.busy": "2025-09-29T23:44:11.909132Z",
     "iopub.status.idle": "2025-09-29T23:46:14.465413Z",
     "shell.execute_reply": "2025-09-29T23:46:14.464428Z"
    },
    "papermill": {
     "duration": 122.564536,
     "end_time": "2025-09-29T23:46:14.467095",
     "exception": false,
     "start_time": "2025-09-29T23:44:11.902559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ æ‰¹æ¬¡æ¨è«–ç¤ºç¯„\n",
      "\n",
      "============================================================\n",
      "ğŸ“‹ æº–å‚™è™•ç† 5 å€‹ç›®æ¨™:\n",
      "\n",
      "   1. TIC 25155310\n",
      "   2. TIC 307210830\n",
      "   3. TIC 260004324\n",
      "   4. TIC 55652896\n",
      "   5. TIC 441462736\n",
      "\n",
      "é–‹å§‹æ‰¹æ¬¡æ¨è«–...\n",
      "\n",
      "============================================================\n",
      "\n",
      "[1/5] è™•ç† TIC 25155310\n",
      "ğŸ” è™•ç†ç›®æ¨™: TIC 25155310\n",
      "   ä¸‹è¼‰å…‰æ›²ç·š...\n",
      "   æ¸…ç†å’Œå»è¶¨å‹¢...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   åŸ·è¡Œ BLS æœå°‹...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   æå–ç‰¹å¾µ...\n",
      "   è¼‰å…¥æ¨¡å‹...\n",
      "   âš ï¸ æœªæ‰¾åˆ°æ¨™æº–åŒ–å™¨ï¼Œè·³éç‰¹å¾µæ¨™æº–åŒ–\n",
      "   ä½¿ç”¨é è¨­ç‰¹å¾µé †åº (14 å€‹ç‰¹å¾µ)\n",
      "   âŒ éŒ¯èª¤: X has 14 features, but ColumnTransformer is expecting 6 features as input.\n",
      "\n",
      "[2/5] è™•ç† TIC 307210830\n",
      "ğŸ” è™•ç†ç›®æ¨™: TIC 307210830\n",
      "   ä¸‹è¼‰å…‰æ›²ç·š...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   æ¸…ç†å’Œå»è¶¨å‹¢...\n",
      "   åŸ·è¡Œ BLS æœå°‹...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   æå–ç‰¹å¾µ...\n",
      "   è¼‰å…¥æ¨¡å‹...\n",
      "   âš ï¸ æœªæ‰¾åˆ°æ¨™æº–åŒ–å™¨ï¼Œè·³éç‰¹å¾µæ¨™æº–åŒ–\n",
      "   ä½¿ç”¨é è¨­ç‰¹å¾µé †åº (14 å€‹ç‰¹å¾µ)\n",
      "   âŒ éŒ¯èª¤: X has 14 features, but ColumnTransformer is expecting 6 features as input.\n",
      "\n",
      "[3/5] è™•ç† TIC 260004324\n",
      "ğŸ” è™•ç†ç›®æ¨™: TIC 260004324\n",
      "   ä¸‹è¼‰å…‰æ›²ç·š...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   æ¸…ç†å’Œå»è¶¨å‹¢...\n",
      "   åŸ·è¡Œ BLS æœå°‹...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   æå–ç‰¹å¾µ...\n",
      "   è¼‰å…¥æ¨¡å‹...\n",
      "   âš ï¸ æœªæ‰¾åˆ°æ¨™æº–åŒ–å™¨ï¼Œè·³éç‰¹å¾µæ¨™æº–åŒ–\n",
      "   ä½¿ç”¨é è¨­ç‰¹å¾µé †åº (14 å€‹ç‰¹å¾µ)\n",
      "   âŒ éŒ¯èª¤: X has 14 features, but ColumnTransformer is expecting 6 features as input.\n",
      "\n",
      "[4/5] è™•ç† TIC 55652896\n",
      "ğŸ” è™•ç†ç›®æ¨™: TIC 55652896\n",
      "   ä¸‹è¼‰å…‰æ›²ç·š...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   æ¸…ç†å’Œå»è¶¨å‹¢...\n",
      "   åŸ·è¡Œ BLS æœå°‹...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   æå–ç‰¹å¾µ...\n",
      "   è¼‰å…¥æ¨¡å‹...\n",
      "   âš ï¸ æœªæ‰¾åˆ°æ¨™æº–åŒ–å™¨ï¼Œè·³éç‰¹å¾µæ¨™æº–åŒ–\n",
      "   ä½¿ç”¨é è¨­ç‰¹å¾µé †åº (14 å€‹ç‰¹å¾µ)\n",
      "   âŒ éŒ¯èª¤: X has 14 features, but ColumnTransformer is expecting 6 features as input.\n",
      "\n",
      "[5/5] è™•ç† TIC 441462736\n",
      "ğŸ” è™•ç†ç›®æ¨™: TIC 441462736\n",
      "   ä¸‹è¼‰å…‰æ›²ç·š...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   æ¸…ç†å’Œå»è¶¨å‹¢...\n",
      "   åŸ·è¡Œ BLS æœå°‹...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   æå–ç‰¹å¾µ...\n",
      "   è¼‰å…¥æ¨¡å‹...\n",
      "   âš ï¸ æœªæ‰¾åˆ°æ¨™æº–åŒ–å™¨ï¼Œè·³éç‰¹å¾µæ¨™æº–åŒ–\n",
      "   ä½¿ç”¨é è¨­ç‰¹å¾µé †åº (14 å€‹ç‰¹å¾µ)\n",
      "   âŒ éŒ¯èª¤: X has 14 features, but ColumnTransformer is expecting 6 features as input.\n",
      "\n",
      "âœ… æ‰¹æ¬¡è™•ç†å®Œæˆ: 5 å€‹ç›®æ¨™\n",
      "   æˆåŠŸ: 0\n",
      "   å¤±æ•—: 5\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# æ‰¹æ¬¡æ¨è«–å¤šå€‹ TIC\n",
    "print(\"ğŸ¯ æ‰¹æ¬¡æ¨è«–ç¤ºç¯„\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ç›®æ¨™åˆ—è¡¨ï¼ˆå¯è‡ªè¡Œä¿®æ”¹æˆ–æ“´å……ï¼‰\n",
    "tic_list = [\n",
    "    \"TIC 25155310\",  # TOI-431 (å·²çŸ¥å¤šè¡Œæ˜Ÿç³»çµ±)\n",
    "    \"TIC 307210830\", # TOI-270 (å·²çŸ¥ä¸‰è¡Œæ˜Ÿç³»çµ±)\n",
    "    \"TIC 260004324\", # TOI-178 (å·²çŸ¥å…­è¡Œæ˜Ÿç³»çµ±)\n",
    "    \"TIC 55652896\",  # TOI-125 (å·²çŸ¥ä¸‰è¡Œæ˜Ÿç³»çµ±)\n",
    "    \"TIC 441462736\", # å¯èƒ½çš„å‡é™½æ€§\n",
    "]\n",
    "\n",
    "print(f\"ğŸ“‹ æº–å‚™è™•ç† {len(tic_list)} å€‹ç›®æ¨™:\\n\")\n",
    "for i, tic in enumerate(tic_list, 1):\n",
    "    print(f\"   {i}. {tic}\")\n",
    "\n",
    "print(\"\\né–‹å§‹æ‰¹æ¬¡æ¨è«–...\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# åŸ·è¡Œæ‰¹æ¬¡æ¨è«– (ä½¿ç”¨æ­£ç¢ºçš„æ¨¡å‹è·¯å¾‘)\n",
    "results_df = predict_batch(\n",
    "    tic_list,\n",
    "    model_path=\"../models/xgboost_pipeline_cv.joblib\",\n",
    "    scaler_path=None,  # Scaler is in the pipeline\n",
    "    feature_schema_path=None,  # Use default feature order\n",
    "    mission=\"TESS\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8319c294",
   "metadata": {
    "papermill": {
     "duration": 0.006333,
     "end_time": "2025-09-29T23:46:14.480165",
     "exception": false,
     "start_time": "2025-09-29T23:46:14.473832",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 8. çµæœè¡¨æ ¼èˆ‡æ’åº"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dabe9693",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T23:46:14.495429Z",
     "iopub.status.busy": "2025-09-29T23:46:14.494868Z",
     "iopub.status.idle": "2025-09-29T23:46:14.537220Z",
     "shell.execute_reply": "2025-09-29T23:46:14.536251Z"
    },
    "papermill": {
     "duration": 0.052072,
     "end_time": "2025-09-29T23:46:14.538983",
     "exception": false,
     "start_time": "2025-09-29T23:46:14.486911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š æ‰¹æ¬¡æ¨è«–çµæœï¼ˆæŒ‰æ©Ÿç‡æ’åºï¼‰:\n",
      "\n",
      "       tic_id probability bls_period bls_snr bls_depth_ppm  success\n",
      " TIC 25155310         N/A      3.288     0.0          2272    False\n",
      "TIC 307210830         N/A      3.691     0.0          1428    False\n",
      "TIC 260004324         N/A      3.812     0.0           373    False\n",
      " TIC 55652896         N/A     17.480     0.0         10258    False\n",
      "TIC 441462736         N/A     14.271     0.0           255    False\n",
      "\n",
      "ğŸ“ˆ çµ±è¨ˆæ‘˜è¦:\n",
      "   æˆåŠŸè™•ç†: 0/5\n",
      "   é«˜ä¿¡å¿ƒå€™é¸ (>0.8): 0\n",
      "   ä¸­ä¿¡å¿ƒå€™é¸ (0.5-0.8): 0\n",
      "\n",
      "ğŸ’¾ çµæœå·²å„²å­˜è‡³: results\\batch_inference.csv\n",
      "\n",
      "ğŸ’¡ ç¹¼çºŒåŸ·è¡Œä¸‹ä¸€å€‹ cell é€²è¡Œæ¨™æº–åŒ– CSV åŒ¯å‡º\n"
     ]
    }
   ],
   "source": [
    "# é¡¯ç¤ºçµæœè¡¨æ ¼\n",
    "if len(results_df) > 0:\n",
    "    print(\"\\nğŸ“Š æ‰¹æ¬¡æ¨è«–çµæœï¼ˆæŒ‰æ©Ÿç‡æ’åºï¼‰:\\n\")\n",
    "    \n",
    "    # æ ¼å¼åŒ–é¡¯ç¤º\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    \n",
    "    # åªé¡¯ç¤ºé—œéµæ¬„ä½\n",
    "    display_columns = ['tic_id', 'probability', 'bls_period', 'bls_snr', 'bls_depth', 'success']\n",
    "    display_df = results_df[display_columns].copy()\n",
    "    \n",
    "    # æ ¼å¼åŒ–æ•¸å€¼\n",
    "    if 'probability' in display_df.columns:\n",
    "        display_df['probability'] = display_df['probability'].apply(lambda x: f\"{x:.3f}\" if pd.notna(x) else \"N/A\")\n",
    "    if 'bls_period' in display_df.columns:\n",
    "        display_df['bls_period'] = display_df['bls_period'].apply(lambda x: f\"{x:.3f}\" if pd.notna(x) else \"N/A\")\n",
    "    if 'bls_snr' in display_df.columns:\n",
    "        display_df['bls_snr'] = display_df['bls_snr'].apply(lambda x: f\"{x:.1f}\" if pd.notna(x) else \"N/A\")\n",
    "    if 'bls_depth' in display_df.columns:\n",
    "        display_df['bls_depth'] = display_df['bls_depth'].apply(lambda x: f\"{x*1e6:.0f}\" if pd.notna(x) else \"N/A\")\n",
    "        display_df = display_df.rename(columns={'bls_depth': 'bls_depth_ppm'})\n",
    "    \n",
    "    print(display_df.to_string(index=False))\n",
    "    \n",
    "    # çµ±è¨ˆæ‘˜è¦\n",
    "    success_count = results_df['success'].sum()\n",
    "    high_conf = len(results_df[(results_df['success']) & (results_df['probability'] > 0.8)])\n",
    "    med_conf = len(results_df[(results_df['success']) & (results_df['probability'] > 0.5) & (results_df['probability'] <= 0.8)])\n",
    "    \n",
    "    print(\"\\nğŸ“ˆ çµ±è¨ˆæ‘˜è¦:\")\n",
    "    print(f\"   æˆåŠŸè™•ç†: {success_count}/{len(results_df)}\")\n",
    "    print(f\"   é«˜ä¿¡å¿ƒå€™é¸ (>0.8): {high_conf}\")\n",
    "    print(f\"   ä¸­ä¿¡å¿ƒå€™é¸ (0.5-0.8): {med_conf}\")\n",
    "    \n",
    "    # å„²å­˜çµæœï¼ˆç°¡æ˜“ç‰ˆï¼‰\n",
    "    output_path = save_inference_results(\n",
    "        results_df,\n",
    "        output_path=\"results/batch_inference.csv\",\n",
    "        include_metadata=True\n",
    "    )\n",
    "    print(f\"\\nğŸ’¾ çµæœå·²å„²å­˜è‡³: {output_path}\")\n",
    "    \n",
    "    # ğŸ’¡ æç¤ºï¼šä¸‹ä¸€å€‹ cell å°‡è½‰æ›ç‚ºæ¨™æº–åŒ–æ ¼å¼\n",
    "    print(\"\\nğŸ’¡ ç¹¼çºŒåŸ·è¡Œä¸‹ä¸€å€‹ cell é€²è¡Œæ¨™æº–åŒ– CSV åŒ¯å‡º\")\n",
    "else:\n",
    "    print(\"âš ï¸ ç„¡æ¨è«–çµæœ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7584f684",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T23:46:14.554488Z",
     "iopub.status.busy": "2025-09-29T23:46:14.553723Z",
     "iopub.status.idle": "2025-09-29T23:46:15.050651Z",
     "shell.execute_reply": "2025-09-29T23:46:15.049525Z"
    },
    "papermill": {
     "duration": 0.506648,
     "end_time": "2025-09-29T23:46:15.052602",
     "exception": false,
     "start_time": "2025-09-29T23:46:14.545954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Path setup complete. app.utils can now be imported.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ æ¨™æº–åŒ–è¼¸å‡ºèˆ‡è³‡æ–™ä¾†æºè¿½è¹¤\n",
      "============================================================\n",
      "âš ï¸ ç„¡æˆåŠŸçš„æ¨è«–çµæœï¼Œè·³éæ¨™æº–åŒ–åŒ¯å‡º\n"
     ]
    }
   ],
   "source": [
    "# Setup paths for Colab compatibility\n",
    "import sys\n",
    "import os\n",
    "IN_COLAB = 'google.colab' in sys.modules or '/content' in os.getcwd()\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Colab environment\n",
    "    if os.path.exists('/content/exoplanet-starter/app'):\n",
    "        sys.path.insert(0, '/content/exoplanet-starter')\n",
    "    else:\n",
    "        # Clone repo if not exists\n",
    "        !git clone https://github.com/exoplanet-spaceapps/exoplanet-starter.git\n",
    "        sys.path.insert(0, '/content/exoplanet-starter')\n",
    "else:\n",
    "    # Local environment  \n",
    "    sys.path.insert(0, os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "print(f\"âœ… Path setup complete. app.utils can now be imported.\")\n",
    "\n",
    "# Now import the required modules\n",
    "from datetime import datetime\n",
    "import time\n",
    "from app.utils.output_schema import (\n",
    "    create_candidate_dataframe,\n",
    "    export_candidates_csv,\n",
    "    export_candidates_jsonl,\n",
    "    validate_candidate_schema\n",
    ")\n",
    "from app.utils.provenance import (\n",
    "    create_provenance_record,\n",
    "    save_provenance,\n",
    "    add_execution_metadata\n",
    ")\n",
    "\n",
    "# æ¨™æº–åŒ– CSV åŒ¯å‡ºèˆ‡è³‡æ–™ä¾†æºè¿½è¹¤\n",
    "print(\"ğŸ“‹ æ¨™æº–åŒ–è¼¸å‡ºèˆ‡è³‡æ–™ä¾†æºè¿½è¹¤\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if len(results_df) > 0 and results_df['success'].any():\n",
    "    # 1. å°‡æ¨è«–çµæœè½‰æ›ç‚ºæ¨™æº–åŒ–å€™é¸æ ¼å¼\n",
    "    print(\"\\nğŸ“Š æ­¥é©Ÿ 1/4: è½‰æ›ç‚ºæ¨™æº–åŒ–å€™é¸æ ¼å¼...\")\n",
    "    \n",
    "    # å°‡ results_df è½‰ç‚º list of dicts (ä¿ç•™æ‰€æœ‰è³‡è¨Š)\n",
    "    results_list = []\n",
    "    for _, row in results_df.iterrows():\n",
    "        result = {\n",
    "            'tic_id': row['tic_id'],\n",
    "            'success': row['success'],\n",
    "            'probability': row.get('probability'),\n",
    "            'bls_period': row.get('bls_period'),\n",
    "            'bls_snr': row.get('bls_snr'),\n",
    "            'bls_depth': row.get('bls_depth'),\n",
    "            'error': row.get('error'),\n",
    "            'features': {\n",
    "                'odd_even_depth_diff': row.get('odd_even_depth_diff', 0),\n",
    "                'transit_symmetry': row.get('transit_symmetry', 0),\n",
    "                'periodicity_strength': row.get('periodicity_strength', 0),\n",
    "                'bls_duration': row.get('bls_period', 0) * 0.05 if row.get('bls_period') else 0,  # ä¼°è¨ˆ\n",
    "                'bls_power': row.get('bls_snr', 0) ** 2 / 100 if row.get('bls_snr') else 0,\n",
    "                'is_eb_flag': False  # å¯æ·»åŠ é£Ÿè®Šæ˜Ÿæª¢æ¸¬é‚è¼¯\n",
    "            },\n",
    "            'lightcurve': {\n",
    "                'mission': 'TESS',\n",
    "                'sector': 'unknown'  # å¯å¾ MAST æŸ¥è©¢ç²å¾—\n",
    "            }\n",
    "        }\n",
    "        results_list.append(result)\n",
    "    \n",
    "    # ç”Ÿæˆ run_id\n",
    "    run_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # è½‰æ›ç‚ºæ¨™æº–åŒ–æ ¼å¼\n",
    "    candidates_df = create_candidate_dataframe(\n",
    "        results_list,\n",
    "        run_id=run_id,\n",
    "        model_version=\"v1.0_xgboost\"\n",
    "    )\n",
    "    \n",
    "    print(f\"   âœ… è½‰æ›å®Œæˆ: {len(candidates_df)} ç­†å€™é¸\")\n",
    "    \n",
    "    # 2. é©—è­‰æ¶æ§‹\n",
    "    print(\"\\nğŸ” æ­¥é©Ÿ 2/4: é©—è­‰è¼¸å‡ºæ¶æ§‹...\")\n",
    "    validation = validate_candidate_schema(candidates_df)\n",
    "    \n",
    "    if validation['valid']:\n",
    "        print(\"   âœ… æ¶æ§‹é©—è­‰é€šé\")\n",
    "    else:\n",
    "        print(\"   âš ï¸ æ¶æ§‹é©—è­‰è­¦å‘Š:\")\n",
    "        for missing in validation['missing_columns']:\n",
    "            print(f\"      - ç¼ºå°‘æ¬„ä½: {missing}\")\n",
    "    \n",
    "    if validation['warnings']:\n",
    "        for warning in validation['warnings']:\n",
    "            print(f\"      âš ï¸ {warning}\")\n",
    "    \n",
    "    # 3. åŒ¯å‡º CSV èˆ‡ JSONL\n",
    "    print(\"\\nğŸ’¾ æ­¥é©Ÿ 3/4: åŒ¯å‡ºæ¨™æº–åŒ–æª”æ¡ˆ...\")\n",
    "    \n",
    "    # ç”¢ç”Ÿæª”åï¼ˆå¸¶æ—¥æœŸï¼‰\n",
    "    date_str = datetime.now().strftime(\"%Y%m%d\")\n",
    "    csv_path = f\"outputs/candidates_{date_str}.csv\"\n",
    "    jsonl_path = f\"outputs/candidates_{date_str}.jsonl\"\n",
    "    \n",
    "    # åŒ¯å‡º CSV\n",
    "    csv_output = export_candidates_csv(\n",
    "        candidates_df,\n",
    "        output_path=csv_path,\n",
    "        validate=True\n",
    "    )\n",
    "    \n",
    "    # åŒ¯å‡º JSONL\n",
    "    jsonl_output = export_candidates_jsonl(\n",
    "        candidates_df,\n",
    "        output_path=jsonl_path\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nğŸ“ åŒ¯å‡ºæª”æ¡ˆ:\")\n",
    "    print(f\"   â€¢ CSV:   {csv_output}\")\n",
    "    print(f\"   â€¢ JSONL: {jsonl_output}\")\n",
    "    \n",
    "    # 4. å»ºç«‹è³‡æ–™ä¾†æºè¨˜éŒ„\n",
    "    print(\"\\nğŸ“‹ æ­¥é©Ÿ 4/4: å»ºç«‹è³‡æ–™ä¾†æºè¿½è¹¤è¨˜éŒ„...\")\n",
    "    \n",
    "    # æŸ¥è©¢åƒæ•¸\n",
    "    query_params = {\n",
    "        'tic_list': tic_list,\n",
    "        'mission': 'TESS',\n",
    "        'detrend_window': 401,\n",
    "        'bls_period_range': [0.5, 20.0]\n",
    "    }\n",
    "    \n",
    "    # æ¨¡å‹è³‡è¨Š\n",
    "    model_info = {\n",
    "        'version': 'v1.0_xgboost',\n",
    "        'type': 'XGBoost Classifier',\n",
    "        'path': 'model/ranker.joblib',\n",
    "        'features': len(feature_order) if 'feature_order' in locals() else 14\n",
    "    }\n",
    "    \n",
    "    # å»ºç«‹è³‡æ–™ä¾†æºè¨˜éŒ„\n",
    "    provenance = create_provenance_record(\n",
    "        run_id=run_id,\n",
    "        query_params=query_params,\n",
    "        model_info=model_info\n",
    "    )\n",
    "    \n",
    "    # æ·»åŠ åŸ·è¡Œçµæœå…ƒè³‡æ–™\n",
    "    provenance = add_execution_metadata(\n",
    "        provenance,\n",
    "        n_targets=len(results_df),\n",
    "        n_success=results_df['success'].sum(),\n",
    "        n_high_confidence=len(candidates_df[candidates_df['model_score'] > 0.8]),\n",
    "        execution_time_seconds=None  # å¯æ‰‹å‹•è¨˜éŒ„\n",
    "    )\n",
    "    \n",
    "    # å„²å­˜è³‡æ–™ä¾†æºè¨˜éŒ„\n",
    "    provenance_path = save_provenance(\n",
    "        provenance,\n",
    "        output_path=f\"outputs/provenance_{date_str}.yaml\"\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nâœ… è³‡æ–™ä¾†æºè¨˜éŒ„å·²å„²å­˜: {provenance_path}\")\n",
    "    \n",
    "    # 5. é¡¯ç¤ºæ¨™æº–åŒ–å€™é¸æ‘˜è¦\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ“Š æ¨™æº–åŒ–å€™é¸æ¸…å–®æ‘˜è¦\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\nğŸ¯ åŸºæœ¬çµ±è¨ˆ:\")\n",
    "    print(f\"   â€¢ ç¸½å€™é¸æ•¸: {len(candidates_df)}\")\n",
    "    print(f\"   â€¢ é«˜ä¿¡å¿ƒ (>0.8): {len(candidates_df[candidates_df['model_score'] > 0.8])}\")\n",
    "    print(f\"   â€¢ ä¸­ä¿¡å¿ƒ (0.5-0.8): {len(candidates_df[(candidates_df['model_score'] > 0.5) & (candidates_df['model_score'] <= 0.8)])}\")\n",
    "    print(f\"   â€¢ ä½ä¿¡å¿ƒ (<0.5): {len(candidates_df[candidates_df['model_score'] <= 0.5])}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š é€±æœŸåˆ†å¸ƒ:\")\n",
    "    if 'bls_period_d' in candidates_df.columns:\n",
    "        periods = candidates_df['bls_period_d'].dropna()\n",
    "        if len(periods) > 0:\n",
    "            print(f\"   â€¢ æœ€çŸ­é€±æœŸ: {periods.min():.2f} å¤©\")\n",
    "            print(f\"   â€¢ æœ€é•·é€±æœŸ: {periods.max():.2f} å¤©\")\n",
    "            print(f\"   â€¢ å¹³å‡é€±æœŸ: {periods.mean():.2f} å¤©\")\n",
    "            print(f\"   â€¢ ä¸­ä½é€±æœŸ: {periods.median():.2f} å¤©\")\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ SNR åˆ†å¸ƒ:\")\n",
    "    if 'snr' in candidates_df.columns:\n",
    "        snrs = candidates_df['snr'].dropna()\n",
    "        if len(snrs) > 0:\n",
    "            print(f\"   â€¢ æœ€é«˜ SNR: {snrs.max():.1f}\")\n",
    "            print(f\"   â€¢ æœ€ä½ SNR: {snrs.min():.1f}\")\n",
    "            print(f\"   â€¢ å¹³å‡ SNR: {snrs.mean():.1f}\")\n",
    "            high_snr = len(snrs[snrs > 10])\n",
    "            print(f\"   â€¢ SNR > 10: {high_snr} ({high_snr/len(snrs)*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nğŸ·ï¸ è³ªé‡æ¨™è¨˜:\")\n",
    "    eb_candidates = candidates_df['is_eb_flag'].sum()\n",
    "    print(f\"   â€¢ é£Ÿè®Šæ˜Ÿæ¨™è¨˜: {eb_candidates} ({eb_candidates/len(candidates_df)*100:.1f}%)\")\n",
    "    \n",
    "    # é¡¯ç¤ºå‰ 5 åå€™é¸\n",
    "    print(f\"\\nğŸŒŸ å‰ 5 åå€™é¸:\")\n",
    "    print(\"-\" * 60)\n",
    "    top_5 = candidates_df.head(5)\n",
    "    for i, (_, row) in enumerate(top_5.iterrows(), 1):\n",
    "        print(f\"{i}. {row['target_id']}\")\n",
    "        print(f\"   â€¢ æ©Ÿç‡: {row['model_score']:.3f}\")\n",
    "        print(f\"   â€¢ é€±æœŸ: {row['bls_period_d']:.3f} å¤©\")\n",
    "        print(f\"   â€¢ SNR: {row['snr']:.1f}\")\n",
    "        print(f\"   â€¢ æ·±åº¦: {row['bls_depth_ppm']:.0f} ppm\")\n",
    "        print()\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"âœ… æ¨™æº–åŒ–è¼¸å‡ºå®Œæˆ!\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # å„²å­˜åˆ°å…¨åŸŸè®Šæ•¸ä¾›å¾ŒçºŒä½¿ç”¨\n",
    "    globals()['standardized_candidates'] = candidates_df\n",
    "    globals()['provenance_record'] = provenance\n",
    "    \n",
    "else:\n",
    "    print(\"âš ï¸ ç„¡æˆåŠŸçš„æ¨è«–çµæœï¼Œè·³éæ¨™æº–åŒ–åŒ¯å‡º\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6c10d9",
   "metadata": {
    "papermill": {
     "duration": 0.006532,
     "end_time": "2025-09-29T23:46:15.066674",
     "exception": false,
     "start_time": "2025-09-29T23:46:15.060142",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 8.5 æ¨™æº–åŒ– CSV åŒ¯å‡ºèˆ‡è³‡æ–™ä¾†æºè¿½è¹¤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6714b991",
   "metadata": {
    "papermill": {
     "duration": 0.012092,
     "end_time": "2025-09-29T23:46:15.086831",
     "exception": false,
     "start_time": "2025-09-29T23:46:15.074739",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 9. æ‰¹æ¬¡çµæœè¦–è¦ºåŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86d14654",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T23:46:15.103147Z",
     "iopub.status.busy": "2025-09-29T23:46:15.102389Z",
     "iopub.status.idle": "2025-09-29T23:46:15.116882Z",
     "shell.execute_reply": "2025-09-29T23:46:15.115744Z"
    },
    "papermill": {
     "duration": 0.024158,
     "end_time": "2025-09-29T23:46:15.118759",
     "exception": false,
     "start_time": "2025-09-29T23:46:15.094601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ ç„¡æˆåŠŸçš„æ¨è«–çµæœå¯è¦–è¦ºåŒ–\n"
     ]
    }
   ],
   "source": [
    "# æ‰¹æ¬¡çµæœè¦–è¦ºåŒ–\n",
    "if len(results_df) > 0 and results_df['success'].any():\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # åªé¸æ“‡æˆåŠŸçš„çµæœ\n",
    "    success_df = results_df[results_df['success']].copy()\n",
    "    \n",
    "    # 1. æ©Ÿç‡åˆ†å¸ƒ\n",
    "    ax1 = axes[0, 0]\n",
    "    if 'probability' in success_df.columns:\n",
    "        probs = success_df['probability'].dropna()\n",
    "        bars = ax1.bar(range(len(probs)), probs.values, color='skyblue', alpha=0.7)\n",
    "        \n",
    "        # æ ¹æ“šæ©Ÿç‡è‘—è‰²\n",
    "        for i, (bar, prob) in enumerate(zip(bars, probs.values)):\n",
    "            if prob > 0.8:\n",
    "                bar.set_color('green')\n",
    "            elif prob > 0.5:\n",
    "                bar.set_color('orange')\n",
    "            else:\n",
    "                bar.set_color('red')\n",
    "        \n",
    "        ax1.set_xticks(range(len(probs)))\n",
    "        ax1.set_xticklabels([tid.replace('TIC ', '') for tid in success_df['tic_id'].values], rotation=45)\n",
    "        ax1.set_ylabel('æ©Ÿç‡')\n",
    "        ax1.set_title('é æ¸¬æ©Ÿç‡åˆ†å¸ƒ')\n",
    "        ax1.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "        ax1.axhline(y=0.8, color='gray', linestyle='--', alpha=0.5)\n",
    "        ax1.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # 2. é€±æœŸåˆ†å¸ƒ\n",
    "    ax2 = axes[0, 1]\n",
    "    if 'bls_period' in success_df.columns:\n",
    "        periods = success_df['bls_period'].dropna()\n",
    "        if len(periods) > 0:\n",
    "            ax2.scatter(periods.values, success_df.loc[periods.index, 'probability'].values,\n",
    "                       s=100, alpha=0.7, c=success_df.loc[periods.index, 'probability'].values,\n",
    "                       cmap='RdYlGn', vmin=0, vmax=1)\n",
    "            ax2.set_xlabel('BLS é€±æœŸ (å¤©)')\n",
    "            ax2.set_ylabel('é æ¸¬æ©Ÿç‡')\n",
    "            ax2.set_title('é€±æœŸ vs æ©Ÿç‡')\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "            # æ·»åŠ é¡è‰²æ¢\n",
    "            cbar = plt.colorbar(ax2.collections[0], ax=ax2)\n",
    "            cbar.set_label('æ©Ÿç‡')\n",
    "    \n",
    "    # 3. SNR åˆ†å¸ƒ\n",
    "    ax3 = axes[1, 0]\n",
    "    if 'bls_snr' in success_df.columns:\n",
    "        snrs = success_df['bls_snr'].dropna()\n",
    "        if len(snrs) > 0:\n",
    "            ax3.scatter(snrs.values, success_df.loc[snrs.index, 'probability'].values,\n",
    "                       s=100, alpha=0.7, c=success_df.loc[snrs.index, 'probability'].values,\n",
    "                       cmap='RdYlGn', vmin=0, vmax=1)\n",
    "            ax3.set_xlabel('BLS SNR')\n",
    "            ax3.set_ylabel('é æ¸¬æ©Ÿç‡')\n",
    "            ax3.set_title('SNR vs æ©Ÿç‡')\n",
    "            ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. æ·±åº¦åˆ†å¸ƒ\n",
    "    ax4 = axes[1, 1]\n",
    "    if 'bls_depth' in success_df.columns:\n",
    "        depths = success_df['bls_depth'].dropna() * 1e6  # è½‰æ›ç‚º ppm\n",
    "        if len(depths) > 0:\n",
    "            ax4.scatter(depths.values, success_df.loc[depths.index, 'probability'].values,\n",
    "                       s=100, alpha=0.7, c=success_df.loc[depths.index, 'probability'].values,\n",
    "                       cmap='RdYlGn', vmin=0, vmax=1)\n",
    "            ax4.set_xlabel('å‡Œæ—¥æ·±åº¦ (ppm)')\n",
    "            ax4.set_ylabel('é æ¸¬æ©Ÿç‡')\n",
    "            ax4.set_title('æ·±åº¦ vs æ©Ÿç‡')\n",
    "            ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('æ‰¹æ¬¡æ¨è«–çµæœåˆ†æ', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nğŸ“ˆ æ‰¹æ¬¡è¦–è¦ºåŒ–å®Œæˆ\")\n",
    "else:\n",
    "    print(\"âš ï¸ ç„¡æˆåŠŸçš„æ¨è«–çµæœå¯è¦–è¦ºåŒ–\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5a455e",
   "metadata": {
    "papermill": {
     "duration": 0.006185,
     "end_time": "2025-09-29T23:46:15.132278",
     "exception": false,
     "start_time": "2025-09-29T23:46:15.126093",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 10. GPU åŠ é€Ÿç¤ºç¯„ï¼ˆå¦‚æœ‰ L4ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "102f55c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T23:46:15.147677Z",
     "iopub.status.busy": "2025-09-29T23:46:15.147034Z",
     "iopub.status.idle": "2025-09-29T23:46:15.159210Z",
     "shell.execute_reply": "2025-09-29T23:46:15.158168Z"
    },
    "papermill": {
     "duration": 0.021565,
     "end_time": "2025-09-29T23:46:15.160807",
     "exception": false,
     "start_time": "2025-09-29T23:46:15.139242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â„¹ï¸ GPU åŠ é€Ÿç¤ºç¯„\n",
      "   â€¢ æœªåµæ¸¬åˆ° L4 GPU æˆ–ä¸æ”¯æ´ BFloat16\n",
      "   â€¢ ç•¶å‰ä½¿ç”¨æ¨™æº– CPU/GPU æ¨è«–\n",
      "   â€¢ è‹¥éœ€è¦åŠ é€Ÿï¼Œå»ºè­°ä½¿ç”¨ Google Colab L4 åŸ·è¡Œç’°å¢ƒ\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# GPU åŠ é€Ÿç¤ºç¯„ï¼ˆåƒ…ç•¶åµæ¸¬åˆ° L4 GPU æ™‚åŸ·è¡Œï¼‰\n",
    "if gpu_info['is_l4'] and gpu_info['supports_bfloat16']:\n",
    "    print(\"ğŸš€ L4 GPU BFloat16 åŠ é€Ÿç¤ºç¯„\\n\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        import torch\n",
    "        import torch.nn as nn\n",
    "        \n",
    "        # å‰µå»ºç¤ºç¯„ç¥ç¶“ç¶²è·¯\n",
    "        class ExoplanetNet(nn.Module):\n",
    "            def __init__(self, input_dim=14):\n",
    "                super().__init__()\n",
    "                self.fc1 = nn.Linear(input_dim, 64)\n",
    "                self.fc2 = nn.Linear(64, 32)\n",
    "                self.fc3 = nn.Linear(32, 1)\n",
    "                self.relu = nn.ReLU()\n",
    "                self.sigmoid = nn.Sigmoid()\n",
    "            \n",
    "            def forward(self, x):\n",
    "                x = self.relu(self.fc1(x))\n",
    "                x = self.relu(self.fc2(x))\n",
    "                x = self.sigmoid(self.fc3(x))\n",
    "                return x\n",
    "        \n",
    "        # åˆå§‹åŒ–æ¨¡å‹\n",
    "        device = torch.device('cuda')\n",
    "        model = ExoplanetNet().to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        # æº–å‚™ç¤ºç¯„è³‡æ–™\n",
    "        batch_size = 100\n",
    "        input_features = torch.randn(batch_size, 14).to(device)\n",
    "        \n",
    "        # æ¯”è¼ƒæ¨è«–é€Ÿåº¦\n",
    "        import time\n",
    "        \n",
    "        # 1. æ¨™æº– FP32 æ¨è«–\n",
    "        print(\"â±ï¸ FP32 æ¨è«–:\")\n",
    "        start_time = time.time()\n",
    "        with torch.no_grad():\n",
    "            for _ in range(1000):\n",
    "                output_fp32 = model(input_features)\n",
    "        torch.cuda.synchronize()\n",
    "        fp32_time = time.time() - start_time\n",
    "        print(f\"   è€—æ™‚: {fp32_time:.3f} ç§’\")\n",
    "        \n",
    "        # 2. BFloat16 autocast æ¨è«–\n",
    "        print(\"\\nâš¡ BFloat16 æ¨è«– (with autocast):\")\n",
    "        start_time = time.time()\n",
    "        with torch.no_grad():\n",
    "            with torch.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "                for _ in range(1000):\n",
    "                    output_bf16 = model(input_features)\n",
    "        torch.cuda.synchronize()\n",
    "        bf16_time = time.time() - start_time\n",
    "        print(f\"   è€—æ™‚: {bf16_time:.3f} ç§’\")\n",
    "        \n",
    "        # è¨ˆç®—åŠ é€Ÿæ¯”\n",
    "        speedup = fp32_time / bf16_time\n",
    "        print(f\"\\nğŸ† BFloat16 åŠ é€Ÿæ¯”: {speedup:.2f}x\")\n",
    "        \n",
    "        # æª¢æŸ¥æ•¸å€¼èª¤å·®\n",
    "        diff = torch.abs(output_fp32 - output_bf16.float()).mean().item()\n",
    "        print(f\"   å¹³å‡çµ•å°èª¤å·®: {diff:.6f}\")\n",
    "        \n",
    "        print(\"\\nğŸ’¡ çµè«–:\")\n",
    "        print(\"   â€¢ L4 GPU çš„ BFloat16 å¯é¡¯è‘—åŠ é€Ÿæ¨è«–\")\n",
    "        print(\"   â€¢ æ•¸å€¼ç²¾åº¦æå¤±æ¥µå°ï¼Œé©åˆç”Ÿç”¢éƒ¨ç½²\")\n",
    "        print(\"   â€¢ å»ºè­°åœ¨å¤§è¦æ¨¡æ‰¹æ¬¡æ¨è«–æ™‚ä½¿ç”¨\")\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"âš ï¸ éœ€è¦å®‰è£ PyTorch æ‰èƒ½åŸ·è¡Œ GPU åŠ é€Ÿç¤ºç¯„\")\n",
    "        print(\"   åŸ·è¡Œ: pip install torch\")\n",
    "else:\n",
    "    print(\"â„¹ï¸ GPU åŠ é€Ÿç¤ºç¯„\")\n",
    "    print(\"   â€¢ æœªåµæ¸¬åˆ° L4 GPU æˆ–ä¸æ”¯æ´ BFloat16\")\n",
    "    print(\"   â€¢ ç•¶å‰ä½¿ç”¨æ¨™æº– CPU/GPU æ¨è«–\")\n",
    "    print(\"   â€¢ è‹¥éœ€è¦åŠ é€Ÿï¼Œå»ºè­°ä½¿ç”¨ Google Colab L4 åŸ·è¡Œç’°å¢ƒ\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef92a043",
   "metadata": {
    "papermill": {
     "duration": 0.006876,
     "end_time": "2025-09-29T23:46:15.174493",
     "exception": false,
     "start_time": "2025-09-29T23:46:15.167617",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 11. ç¸½çµèˆ‡ä¸‹ä¸€æ­¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fc0bf80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T23:46:15.190862Z",
     "iopub.status.busy": "2025-09-29T23:46:15.190318Z",
     "iopub.status.idle": "2025-09-29T23:46:15.199371Z",
     "shell.execute_reply": "2025-09-29T23:46:15.198179Z"
    },
    "papermill": {
     "duration": 0.019763,
     "end_time": "2025-09-29T23:46:15.201111",
     "exception": false,
     "start_time": "2025-09-29T23:46:15.181348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸ“Š æ¨è«–ç®¡ç·šåŸ·è¡Œç¸½çµ\n",
      "======================================================================\n",
      "\n",
      "ğŸ¯ åŸ·è¡Œçµ±è¨ˆ:\n",
      "   â€¢ è™•ç†ç›®æ¨™æ•¸: 5\n",
      "   â€¢ æˆåŠŸæ¨è«–: 0\n",
      "   â€¢ é«˜ä¿¡å¿ƒå€™é¸: 0\n",
      "\n",
      "ğŸ–¥ï¸ é‹ç®—ç’°å¢ƒ:\n",
      "   â€¢ GPU: å¯ç”¨ - NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "   â€¢ L4 å„ªåŒ–: ä¸æ”¯æ´\n",
      "   â€¢ BFloat16: æ”¯æ´\n",
      "\n",
      "ğŸ“¦ è¼¸å‡ºæª”æ¡ˆ:\n",
      "   â€¢ æ‰¹æ¬¡çµæœ: results/batch_inference.csv\n",
      "   â€¢ å…ƒè³‡æ–™: results/batch_inference_metadata.json\n",
      "\n",
      "ğŸš€ ä¸‹ä¸€æ­¥å»ºè­°:\n",
      "   1. å°é«˜ä¿¡å¿ƒå€™é¸é€²è¡Œäººå·¥å¯©æŸ¥\n",
      "   2. æŸ¥è©¢ NASA Exoplanet Archive ç¢ºèªå·²çŸ¥è¡Œæ˜Ÿ\n",
      "   3. ä½¿ç”¨æ›´å¤š TESS æ‰‡å€è³‡æ–™é€²è¡Œé©—è­‰\n",
      "   4. ç”Ÿæˆå€™é¸åˆ¤è®€å¡ï¼ˆåŸ·è¡Œ app/report.pyï¼‰\n",
      "   5. éƒ¨ç½²ç‚º Web æ‡‰ç”¨ï¼ˆåŸ·è¡Œ web/app.pyï¼‰\n",
      "\n",
      "ğŸ“š ç›¸é—œè³‡æº:\n",
      "   â€¢ NASA Exoplanet Archive: https://exoplanetarchive.ipac.caltech.edu/\n",
      "   â€¢ TESS è³‡æ–™å…¥å£: https://mast.stsci.edu/portal/Mashup/Clients/Mast/Portal.html\n",
      "   â€¢ Lightkurve æ–‡ä»¶: https://docs.lightkurve.org/\n",
      "\n",
      "======================================================================\n",
      "âœ… æ¨è«–ç®¡ç·šå®Œæˆï¼\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"ğŸ“Š æ¨è«–ç®¡ç·šåŸ·è¡Œç¸½çµ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "ğŸ¯ åŸ·è¡Œçµ±è¨ˆ:\n",
    "   â€¢ è™•ç†ç›®æ¨™æ•¸: {len(results_df) if 'results_df' in locals() else 0}\n",
    "   â€¢ æˆåŠŸæ¨è«–: {results_df['success'].sum() if 'results_df' in locals() else 0}\n",
    "   â€¢ é«˜ä¿¡å¿ƒå€™é¸: {len(results_df[(results_df['success']) & (results_df['probability'] > 0.8)]) if 'results_df' in locals() else 0}\n",
    "\n",
    "ğŸ–¥ï¸ é‹ç®—ç’°å¢ƒ:\n",
    "   â€¢ GPU: {'å¯ç”¨ - ' + gpu_info['device_name'] if gpu_info['available'] else 'ä¸å¯ç”¨'}\n",
    "   â€¢ L4 å„ªåŒ–: {'æ”¯æ´' if gpu_info['is_l4'] else 'ä¸æ”¯æ´'}\n",
    "   â€¢ BFloat16: {'æ”¯æ´' if gpu_info['supports_bfloat16'] else 'ä¸æ”¯æ´'}\n",
    "\n",
    "ğŸ“¦ è¼¸å‡ºæª”æ¡ˆ:\n",
    "   â€¢ æ‰¹æ¬¡çµæœ: results/batch_inference.csv\n",
    "   â€¢ å…ƒè³‡æ–™: results/batch_inference_metadata.json\n",
    "\n",
    "ğŸš€ ä¸‹ä¸€æ­¥å»ºè­°:\n",
    "   1. å°é«˜ä¿¡å¿ƒå€™é¸é€²è¡Œäººå·¥å¯©æŸ¥\n",
    "   2. æŸ¥è©¢ NASA Exoplanet Archive ç¢ºèªå·²çŸ¥è¡Œæ˜Ÿ\n",
    "   3. ä½¿ç”¨æ›´å¤š TESS æ‰‡å€è³‡æ–™é€²è¡Œé©—è­‰\n",
    "   4. ç”Ÿæˆå€™é¸åˆ¤è®€å¡ï¼ˆåŸ·è¡Œ app/report.pyï¼‰\n",
    "   5. éƒ¨ç½²ç‚º Web æ‡‰ç”¨ï¼ˆåŸ·è¡Œ web/app.pyï¼‰\n",
    "\n",
    "ğŸ“š ç›¸é—œè³‡æº:\n",
    "   â€¢ NASA Exoplanet Archive: https://exoplanetarchive.ipac.caltech.edu/\n",
    "   â€¢ TESS è³‡æ–™å…¥å£: https://mast.stsci.edu/portal/Mashup/Clients/Mast/Portal.html\n",
    "   â€¢ Lightkurve æ–‡ä»¶: https://docs.lightkurve.org/\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"âœ… æ¨è«–ç®¡ç·šå®Œæˆï¼\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec98d434",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T23:46:15.216445Z",
     "iopub.status.busy": "2025-09-29T23:46:15.215842Z",
     "iopub.status.idle": "2025-09-29T23:46:15.220795Z",
     "shell.execute_reply": "2025-09-29T23:46:15.219945Z"
    },
    "papermill": {
     "duration": 0.014667,
     "end_time": "2025-09-29T23:46:15.222566",
     "exception": false,
     "start_time": "2025-09-29T23:46:15.207899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ æ–°è³‡æ–™æ¨è«–ç®¡ç·šå®Œæˆï¼\n",
      "ğŸ’¡ è«‹åœ¨éœ€è¦æ¨é€çµæœæ™‚åŸ·è¡Œä¸Šé¢çš„ ultimate_push_to_github_04() å‡½æ•¸\n"
     ]
    }
   ],
   "source": [
    "# ğŸš€ åŸ·è¡Œ GitHub Push (04 - æ–°è³‡æ–™æ¨è«–)\n",
    "# å–æ¶ˆè¨»è§£ä¸‹é¢é€™è¡Œä¾†åŸ·è¡Œæ¨é€:\n",
    "# ultimate_push_to_github_04()\n",
    "\n",
    "print(\"ğŸ“‹ æ–°è³‡æ–™æ¨è«–ç®¡ç·šå®Œæˆï¼\")\n",
    "print(\"ğŸ’¡ è«‹åœ¨éœ€è¦æ¨é€çµæœæ™‚åŸ·è¡Œä¸Šé¢çš„ ultimate_push_to_github_04() å‡½æ•¸\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81db0dfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T23:46:15.239264Z",
     "iopub.status.busy": "2025-09-29T23:46:15.238559Z",
     "iopub.status.idle": "2025-09-29T23:46:15.264431Z",
     "shell.execute_reply": "2025-09-29T23:46:15.262902Z"
    },
    "papermill": {
     "duration": 0.039411,
     "end_time": "2025-09-29T23:46:15.269371",
     "exception": false,
     "start_time": "2025-09-29T23:46:15.229960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” æº–å‚™æ¨é€æ–°è³‡æ–™æ¨è«–çµæœ...\n",
      "ğŸ’¡ åŸ·è¡Œæ–¹å¼: ultimate_push_to_github_04(token='ä½ çš„GitHub_token')\n",
      "ğŸ“ æˆ–ç›´æ¥åŸ·è¡Œä¸‹æ–¹ cell ä¸¦åœ¨æç¤ºæ™‚è¼¸å…¥ token\n"
     ]
    }
   ],
   "source": [
    "# ğŸš€ GitHub Push çµ‚æ¥µè§£æ±ºæ–¹æ¡ˆ (04 - New Data Inference Results)\n",
    "# ä¸€éµæ¨é€æ–°è³‡æ–™æ¨è«–çµæœè‡³ GitHub\n",
    "\n",
    "import subprocess, os\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "def ultimate_push_to_github_04(token=None):\n",
    "    \"\"\"\n",
    "    çµ‚æ¥µä¸€éµæ¨é€è§£æ±ºæ–¹æ¡ˆ - æ–°è³‡æ–™æ¨è«–çµæœç‰ˆ\n",
    "    è§£æ±ºæ‰€æœ‰ Colab èˆ‡æœ¬åœ°ç’°å¢ƒçš„ Git/LFS å•é¡Œ\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"ğŸš€ æ–°è³‡æ–™æ¨è«–çµæœ GitHub æ¨é€é–‹å§‹...\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # æ­¥é©Ÿ 1: ç’°å¢ƒåµæ¸¬èˆ‡è¨­å®š\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        IN_COLAB = True\n",
    "        working_dir = \"/content\"\n",
    "        print(\"ğŸŒ åµæ¸¬åˆ° Google Colab ç’°å¢ƒ\")\n",
    "    except ImportError:\n",
    "        IN_COLAB = False\n",
    "        working_dir = os.getcwd()\n",
    "        print(\"ğŸ’» åµæ¸¬åˆ°æœ¬åœ°ç’°å¢ƒ\")\n",
    "\n",
    "    # æ­¥é©Ÿ 2: Token è¼¸å…¥\n",
    "    if not token:\n",
    "        print(\"ğŸ“‹ è«‹è¼¸å…¥ GitHub Personal Access Token:\")\n",
    "        print(\"   1. å‰å¾€ https://github.com/settings/tokens\")\n",
    "        print(\"   2. é»æ“Š 'Generate new token (classic)'\")\n",
    "        print(\"   3. å‹¾é¸ 'repo' æ¬Šé™\")\n",
    "        print(\"   4. è¤‡è£½ç”Ÿæˆçš„ token\")\n",
    "        token = input(\"ğŸ” è²¼ä¸Šä½ çš„ token (ghp_...): \").strip()\n",
    "        if not token.startswith('ghp_'):\n",
    "            print(\"âŒ Token æ ¼å¼éŒ¯èª¤ï¼Œæ‡‰è©²ä»¥ 'ghp_' é–‹é ­\")\n",
    "            return False\n",
    "\n",
    "    # æ­¥é©Ÿ 3: Git å€‰åº«åˆå§‹åŒ–èˆ‡è¨­å®š\n",
    "    print(\"\\nğŸ“‹ æ­¥é©Ÿ 1/4: Git å€‰åº«è¨­å®š...\")\n",
    "\n",
    "    try:\n",
    "        # åˆ‡æ›åˆ°å·¥ä½œç›®éŒ„\n",
    "        if IN_COLAB:\n",
    "            os.chdir(working_dir)\n",
    "\n",
    "        # æª¢æŸ¥æ˜¯å¦å·²æ˜¯ Git å€‰åº«\n",
    "        git_check = subprocess.run(['git', 'rev-parse', '--git-dir'],\n",
    "                                   capture_output=True, text=True)\n",
    "\n",
    "        if git_check.returncode != 0:\n",
    "            print(\"   ğŸ”§ åˆå§‹åŒ– Git å€‰åº«...\")\n",
    "            subprocess.run(['git', 'init'], check=True)\n",
    "            print(\"   âœ… Git å€‰åº«åˆå§‹åŒ–å®Œæˆ\")\n",
    "        else:\n",
    "            print(\"   âœ… å·²åœ¨ Git å€‰åº«ä¸­\")\n",
    "\n",
    "        # è¨­å®š Git ç”¨æˆ¶ï¼ˆå¦‚æœæœªè¨­å®šï¼‰\n",
    "        try:\n",
    "            subprocess.run(['git', 'config', 'user.name', 'Colab User'], check=True)\n",
    "            subprocess.run(['git', 'config', 'user.email', 'colab@spaceapps.com'], check=True)\n",
    "            print(\"   âœ… Git ç”¨æˆ¶è¨­å®šå®Œæˆ\")\n",
    "        except:\n",
    "            print(\"   âš ï¸ Git ç”¨æˆ¶è¨­å®šè·³é\")\n",
    "\n",
    "        # è¨­å®šé ç«¯å€‰åº«ï¼ˆè‡ªå‹•åµæ¸¬æˆ–ä½¿ç”¨é è¨­ï¼‰\n",
    "        try:\n",
    "            remote_check = subprocess.run(['git', 'remote', 'get-url', 'origin'],\n",
    "                                        capture_output=True, text=True)\n",
    "            if remote_check.returncode != 0:\n",
    "                print(\"   ğŸ”§ è¨­å®šé ç«¯å€‰åº«...\")\n",
    "                # ä½¿ç”¨é è¨­å€‰åº« URLï¼ˆç”¨æˆ¶éœ€è¦ä¿®æ”¹ç‚ºè‡ªå·±çš„å€‰åº«ï¼‰\n",
    "                default_repo = \"https://github.com/exoplanet-spaceapps/exoplanet-starter.git\"\n",
    "                subprocess.run(['git', 'remote', 'add', 'origin', default_repo], check=True)\n",
    "                print(f\"   âœ… é ç«¯å€‰åº«è¨­å®š: {default_repo}\")\n",
    "                print(\"   ğŸ’¡ è«‹ç¢ºä¿ä½ æœ‰è©²å€‰åº«çš„å¯«å…¥æ¬Šé™ï¼Œæˆ–ä¿®æ”¹ç‚ºä½ çš„å€‰åº«\")\n",
    "            else:\n",
    "                print(f\"   âœ… é ç«¯å€‰åº«å·²è¨­å®š: {remote_check.stdout.strip()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   âš ï¸ é ç«¯å€‰åº«è¨­å®šè­¦å‘Š: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Git è¨­å®šå¤±æ•—: {e}\")\n",
    "        return False\n",
    "\n",
    "    # æ­¥é©Ÿ 4: Git LFS è¨­å®š\n",
    "    print(\"\\nğŸ“‹ æ­¥é©Ÿ 2/4: Git LFS è¨­å®š...\")\n",
    "\n",
    "    try:\n",
    "        # å®‰è£ Git LFSï¼ˆColabï¼‰\n",
    "        if IN_COLAB:\n",
    "            print(\"   ğŸ“¦ åœ¨ Colab ä¸­å®‰è£ Git LFS...\")\n",
    "            subprocess.run(['apt-get', 'update', '-qq'], check=True)\n",
    "            subprocess.run(['apt-get', 'install', '-y', '-qq', 'git-lfs'], check=True)\n",
    "            print(\"   âœ… Git LFS å·²å®‰è£\")\n",
    "\n",
    "        # åˆå§‹åŒ– LFS\n",
    "        try:\n",
    "            subprocess.run(['git', 'lfs', 'install'], check=True)\n",
    "            print(\"   âœ… Git LFS åˆå§‹åŒ–å®Œæˆ\")\n",
    "        except:\n",
    "            print(\"   âš ï¸ Git LFS åˆå§‹åŒ–è·³éï¼ˆå¯èƒ½å·²è¨­å®šï¼‰\")\n",
    "\n",
    "        # è¨­å®š LFS è¿½è¹¤ï¼ˆå®¹éŒ¯è™•ç†ï¼‰\n",
    "        lfs_patterns = ['*.csv', '*.json', '*.pkl', '*.parquet', '*.h5', '*.hdf5', '*.joblib']\n",
    "        for pattern in lfs_patterns:\n",
    "            try:\n",
    "                result = subprocess.run(['git', 'lfs', 'track', pattern],\n",
    "                                      capture_output=True, text=True)\n",
    "                if result.returncode == 0:\n",
    "                    print(f\"   ğŸ“¦ LFS è¿½è¹¤: {pattern}\")\n",
    "                else:\n",
    "                    print(f\"   âš ï¸ LFS è¿½è¹¤ {pattern} è­¦å‘Š: {result.stderr.strip()}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   âš ï¸ LFS è¿½è¹¤ {pattern} è·³é: {e}\")\n",
    "\n",
    "        # æ·»åŠ  .gitattributes åˆ° staging\n",
    "        try:\n",
    "            subprocess.run(['git', 'add', '.gitattributes'], check=False)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸ Git LFS è¨­å®šè­¦å‘Š: {e}\")\n",
    "        print(\"   ğŸ’¡ ç¹¼çºŒåŸ·è¡Œï¼Œä½†å¤§æª”æ¡ˆå¯èƒ½ç„¡æ³•æ­£ç¢ºè¿½è¹¤\")\n",
    "\n",
    "    # æ­¥é©Ÿ 5: æ·»åŠ æª”æ¡ˆä¸¦æäº¤\n",
    "    print(\"\\nğŸ“‹ æ­¥é©Ÿ 3/4: æ·»åŠ æª”æ¡ˆèˆ‡æäº¤...\")\n",
    "\n",
    "    try:\n",
    "        # ç¢ºä¿é‡è¦ç›®éŒ„å­˜åœ¨\n",
    "        important_dirs = ['data', 'notebooks', 'app', 'scripts', 'model', 'results']\n",
    "        for dir_name in important_dirs:\n",
    "            dir_path = Path(dir_name)\n",
    "            if dir_path.exists():\n",
    "                print(f\"   ğŸ“‚ æ‰¾åˆ°ç›®éŒ„: {dir_name}\")\n",
    "            elif IN_COLAB and dir_name in ['results']:\n",
    "                # åœ¨ Colab ä¸­å‰µå»ºç›¸é—œç›®éŒ„\n",
    "                dir_path.mkdir(parents=True, exist_ok=True)\n",
    "                print(f\"   ğŸ“‚ å‰µå»ºç›®éŒ„: {dir_name}\")\n",
    "\n",
    "        # æ·»åŠ æ‰€æœ‰æª”æ¡ˆ\n",
    "        subprocess.run(['git', 'add', '.'], check=True)\n",
    "        print(\"   âœ… æª”æ¡ˆæ·»åŠ å®Œæˆ\")\n",
    "\n",
    "        # æª¢æŸ¥æ˜¯å¦æœ‰è®Šæ›´\n",
    "        status_result = subprocess.run(['git', 'status', '--porcelain'],\n",
    "                                      capture_output=True, text=True, check=True)\n",
    "\n",
    "        if not status_result.stdout.strip():\n",
    "            print(\"   âœ… æ²’æœ‰æ–°çš„è®Šæ›´éœ€è¦æäº¤\")\n",
    "            return True\n",
    "\n",
    "        # å‰µå»ºæäº¤\n",
    "        commit_message = \"\"\"feat: complete new data inference pipeline with GPU optimization\n",
    "\n",
    "- ğŸ¯ å®Œæˆå–®ç›®æ¨™æ¨è«–: TIC â†’ MAST â†’ BLS/TLS â†’ æ©Ÿç‡é æ¸¬\n",
    "- ğŸ“Š å¯¦ç¾æ‰¹æ¬¡è™•ç†: å¤šå€‹ TIC ä¸¦è¡Œæ¨è«–èˆ‡çµæœæ’åº\n",
    "- ğŸ“ˆ å®Œæ•´è¦–è¦ºåŒ–: æ‘ºç–Šå…‰æ›²ç·šã€BLSåŠŸç‡è­œã€é æ¸¬åˆ†æ•¸åˆ†å¸ƒ\n",
    "- ğŸ–¥ï¸ GPU åµæ¸¬èˆ‡å„ªåŒ–: L4 GPU BFloat16 autocast åŠ é€Ÿç¤ºç¯„\n",
    "- â±ï¸ æ•ˆèƒ½æ¸¬è©¦: æ¨è«–å»¶é²æ™‚é–“èˆ‡ååé‡æ¸¬é‡\n",
    "- ğŸ’¾ çµæœåŒ¯å‡º: results/batch_inference.csv + metadata\n",
    "- ğŸ“‹ ç¶œåˆçµ±è¨ˆ: é«˜/ä¸­/ä½ä¿¡å¿ƒå€™é¸åˆ†æ\n",
    "- ğŸš€ ç”Ÿç”¢å°±ç·’: å®Œæ•´çš„æ–°è³‡æ–™æ¨è«–ç®¡ç·š\n",
    "\n",
    "Co-Authored-By: hctsai1006 <39769660@cuni.cz>\n",
    "        \"\"\"\n",
    "\n",
    "        subprocess.run(['git', 'commit', '-m', commit_message], check=True)\n",
    "        print(\"   âœ… æäº¤å®Œæˆ\")\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"   âŒ æª”æ¡ˆæäº¤å¤±æ•—: {e}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ æª”æ¡ˆè™•ç†å¤±æ•—: {e}\")\n",
    "        return False\n",
    "\n",
    "    # æ­¥é©Ÿ 6: æ¨é€åˆ° GitHub\n",
    "    print(\"\\nğŸ“‹ æ­¥é©Ÿ 4/4: æ¨é€åˆ° GitHub...\")\n",
    "\n",
    "    try:\n",
    "        # ç²å–é ç«¯ URL ä¸¦æ’å…¥ token\n",
    "        remote_result = subprocess.run(['git', 'remote', 'get-url', 'origin'],\n",
    "                                      capture_output=True, text=True, check=True)\n",
    "        remote_url = remote_result.stdout.strip()\n",
    "\n",
    "        # æ§‹é€ å¸¶ token çš„ URL\n",
    "        if remote_url.startswith('https://github.com/'):\n",
    "            # æå–å€‰åº«è·¯å¾‘\n",
    "            repo_path = remote_url.replace('https://github.com/', '').replace('.git', '')\n",
    "            auth_url = f\"https://{token}@github.com/{repo_path}.git\"\n",
    "        else:\n",
    "            print(f\"   âš ï¸ é ç«¯ URL æ ¼å¼ç•°å¸¸: {remote_url}\")\n",
    "            auth_url = remote_url\n",
    "\n",
    "        # æ¨é€\n",
    "        push_result = subprocess.run([\n",
    "            'git', 'push', auth_url, 'main'\n",
    "        ], capture_output=True, text=True, timeout=300)\n",
    "\n",
    "        if push_result.returncode == 0:\n",
    "            print(\"   âœ… æ¨é€æˆåŠŸï¼\")\n",
    "            print(f\"   ğŸ“¡ æ¨é€è¼¸å‡º: {push_result.stdout[:200]}...\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"   âŒ æ¨é€å¤±æ•—: {push_result.stderr}\")\n",
    "            # å˜—è©¦æ¨é€åˆ°å…¶ä»–åˆ†æ”¯\n",
    "            try:\n",
    "                alt_push = subprocess.run([\n",
    "                    'git', 'push', auth_url, 'HEAD:main'\n",
    "                ], capture_output=True, text=True, timeout=300)\n",
    "                if alt_push.returncode == 0:\n",
    "                    print(\"   âœ… å‚™ç”¨æ¨é€æˆåŠŸï¼\")\n",
    "                    return True\n",
    "            except:\n",
    "                pass\n",
    "            return False\n",
    "\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"   âŒ æ¨é€è¶…æ™‚ï¼Œè«‹æª¢æŸ¥ç¶²è·¯é€£æ¥\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ æ¨é€å¤±æ•—: {e}\")\n",
    "        return False\n",
    "\n",
    "    finally:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"ğŸ“‹ æ–°è³‡æ–™æ¨è«–çµæœæ¨é€å®Œæˆ!\")\n",
    "        if IN_COLAB:\n",
    "            print(\"ğŸ’¡ å¦‚æœé‡åˆ°å•é¡Œ:\")\n",
    "            print(\"   1. ç¢ºä¿ token æœ‰ 'repo' æ¬Šé™\")\n",
    "            print(\"   2. ç¢ºä¿ä½ æœ‰ç›®æ¨™å€‰åº«çš„å¯«å…¥æ¬Šé™\")\n",
    "            print(\"   3. æª¢æŸ¥å€‰åº« URL æ˜¯å¦æ­£ç¢º\")\n",
    "\n",
    "# å‘¼å«å‡½æ•¸ï¼ˆè«‹åœ¨åŸ·è¡Œæ™‚æä¾› tokenï¼‰\n",
    "print(\"ğŸ” æº–å‚™æ¨é€æ–°è³‡æ–™æ¨è«–çµæœ...\")\n",
    "print(\"ğŸ’¡ åŸ·è¡Œæ–¹å¼: ultimate_push_to_github_04(token='ä½ çš„GitHub_token')\")\n",
    "print(\"ğŸ“ æˆ–ç›´æ¥åŸ·è¡Œä¸‹æ–¹ cell ä¸¦åœ¨æç¤ºæ™‚è¼¸å…¥ token\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cfe301",
   "metadata": {
    "papermill": {
     "duration": 0.007096,
     "end_time": "2025-09-29T23:46:15.284677",
     "exception": false,
     "start_time": "2025-09-29T23:46:15.277581",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## ğŸš€ GitHub Push çµ‚æ¥µè§£æ±ºæ–¹æ¡ˆ\n",
    "\n",
    "å°‡æ–°è³‡æ–™æ¨è«–çµæœæ¨é€åˆ° GitHub å€‰åº«ï¼š"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 201.609628,
   "end_time": "2025-09-29T23:46:18.531176",
   "environment_variables": {},
   "exception": null,
   "input_path": "04_newdata_inference.ipynb",
   "output_path": "04_newdata_inference_executed.ipynb",
   "parameters": {},
   "start_time": "2025-09-29T23:42:56.921548",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}