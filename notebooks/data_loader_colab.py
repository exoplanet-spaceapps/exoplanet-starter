"""
Universal Data Loader for 02_bls_baseline.ipynb
é€‚ç”¨äº Google Colab å’Œæœ¬åœ°ç¯å¢ƒçš„æ•°æ®åŠ è½½æ¨¡å—
"""

# Fix UTF-8 encoding for Windows environment
import sys
import io
if sys.platform == 'win32':
    # Reconfigure stdout/stderr to use UTF-8 encoding
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

import pandas as pd
from pathlib import Path
import subprocess
import os

def setup_data_directory():
    """
    è®¾ç½®æ•°æ®ç›®å½•ï¼Œåœ¨ Colab ä¸­è‡ªåŠ¨ä» GitHub å…‹éš†
    """
    # æ£€æŸ¥æ˜¯å¦åœ¨ Colab ç¯å¢ƒ
    try:
        from google.colab import drive
        IN_COLAB = True
        print("ğŸŒ ç¯å¢ƒ: Google Colab")

        # åœ¨ Colab ä¸­ï¼Œé¦–å…ˆæ£€æŸ¥æ˜¯å¦å·²å…‹éš†å€‰åº«
        project_dir = Path('/content/exoplanet-starter')

        if not project_dir.exists():
            print("ğŸ“¥ æ­£åœ¨ä» GitHub å…‹éš†ä¸“æ¡ˆ...")
            result = subprocess.run([
                'git', 'clone',
                'https://github.com/exoplanet-spaceapps/exoplanet-starter.git',
                str(project_dir)
            ], capture_output=True, text=True)

            if result.returncode == 0:
                print("âœ… ä¸“æ¡ˆå…‹éš†å®Œæˆ")
            else:
                print(f"âš ï¸ å…‹éš†è­¦å‘Š: {result.stderr}")
                print("å°è¯•ä½¿ç”¨æµ…å…‹éš†...")
                subprocess.run([
                    'git', 'clone', '--depth', '1',
                    'https://github.com/exoplanet-spaceapps/exoplanet-starter.git',
                    str(project_dir)
                ], check=True)
                print("âœ… æµ…å…‹éš†å®Œæˆ")

        # åˆ‡æ¢åˆ°ä¸“æ¡ˆç›®å½•
        os.chdir(str(project_dir))
        data_dir = project_dir / 'data'

    except ImportError:
        IN_COLAB = False
        data_dir = Path('../data')
        print("ğŸŒ ç¯å¢ƒ: æœ¬åœ°ç¯å¢ƒ")

    print(f"ğŸ“‚ èµ„æ–™ç›®å½•: {data_dir}")

    return data_dir, IN_COLAB


def load_datasets(data_dir):
    """
    è½½å…¥æ‰€æœ‰æ•°æ®é›†
    """
    # éªŒè¯æ•°æ®ç›®å½•æ˜¯å¦å­˜åœ¨
    if not data_dir.exists():
        print(f"âŒ èµ„æ–™ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        print("ğŸ’¡ è¯·ç¡®ä¿å·²æ‰§è¡Œ 01_tap_download.ipynb ä¸‹è½½èµ„æ–™")
        return {}

    # åˆ—å‡ºå¯ç”¨çš„èµ„æ–™æ–‡ä»¶
    csv_files = list(data_dir.glob('*.csv'))
    if not csv_files:
        print("âš ï¸ èµ„æ–™ç›®å½•ä¸ºç©ºï¼Œè¯·å…ˆæ‰§è¡Œèµ„æ–™ä¸‹è½½")
        return {}

    print(f"âœ… æ‰¾åˆ° {len(csv_files)} ä¸ªèµ„æ–™æ–‡ä»¶:")
    for f in csv_files:
        size_mb = f.stat().st_size / 1024 / 1024
        print(f"   â€¢ {f.name} ({size_mb:.2f} MB)")

    # è½½å…¥æ•°æ®é›†
    datasets = {}
    data_files = {
        'supervised_dataset': 'supervised_dataset.csv',
        'toi_positive': 'toi_positive.csv',
        'toi_negative': 'toi_negative.csv',
        'koi_false_positives': 'koi_false_positives.csv'
    }

    for name, filename in data_files.items():
        file_path = data_dir / filename
        if file_path.exists():
            try:
                datasets[name] = pd.read_csv(file_path)
                print(f"âœ… è½½å…¥ {name}: {len(datasets[name])} ç¬”èµ„æ–™")
            except Exception as e:
                print(f"âš ï¸ è½½å…¥ {name} å¤±è´¥: {e}")
        else:
            print(f"âš ï¸ æ‰¾ä¸åˆ°æ¡£æ¡ˆ: {file_path}")

    return datasets


def create_sample_targets(datasets, n_positive=3, n_negative=2):
    """
    ä»æ•°æ®é›†ä¸­åˆ›å»ºåˆ†ææ ·æœ¬
    """
    sample_targets = pd.DataFrame()

    if 'supervised_dataset' in datasets and len(datasets['supervised_dataset']) > 0:
        # ä»åˆå¹¶èµ„æ–™é›†ä¸­é€‰å–æ ·æœ¬
        df = datasets['supervised_dataset']

        # é€‰å–æœ‰å®Œæ•´èµ„æ–™çš„ç›®æ ‡
        complete_data = df.dropna(subset=['period', 'depth'])

        # æŒ‰æ ‡ç­¾é€‰å–æ ·æœ¬
        positive_samples = complete_data[complete_data['label'] == 1].head(n_positive)
        negative_samples = complete_data[complete_data['label'] == 0].head(n_negative)

        sample_targets = pd.concat([positive_samples, negative_samples], ignore_index=True)

        print(f"\nğŸ“Š é€‰å–åˆ†ææ ·æœ¬: {len(sample_targets)} ä¸ªç›®æ ‡")
        print(f"   æ­£æ ·æœ¬: {(sample_targets['label'] == 1).sum()}")
        print(f"   è´Ÿæ ·æœ¬: {(sample_targets['label'] == 0).sum()}")

        # æ˜¾ç¤ºæ ·æœ¬èµ„è®¯
        print("\nğŸ¯ æ ·æœ¬ç›®æ ‡:")
        for idx, row in sample_targets.iterrows():
            target_id = row.get('target_id', f"Target_{idx}")
            period = row.get('period', 'N/A')
            depth = row.get('depth', 'N/A')
            source = row.get('source', 'Unknown')
            label = 'æ­£æ ·æœ¬' if row['label'] == 1 else 'è´Ÿæ ·æœ¬'

            period_str = f"P={period:.3f}d" if period != 'N/A' else "P=N/A"
            depth_str = f", depth={depth:.0f}ppm" if depth != 'N/A' else ""

            print(f"   â€¢ {target_id}: {label}, {period_str}{depth_str} ({source})")

    else:
        print("âš ï¸ æ— æ³•è½½å…¥èµ„æ–™é›†ï¼Œå°†ä½¿ç”¨é¢„è®¾ç›®æ ‡")

        # å»ºç«‹é¢„è®¾æ ·æœ¬ï¼ˆå¦‚æœæ— æ³•è½½å…¥èµ„æ–™ï¼‰
        sample_targets = pd.DataFrame([
            {'target_id': 'TIC25155310', 'label': 1, 'period': 4.2, 'depth': 2800, 'source': 'default'},
            {'target_id': 'TIC307210830', 'label': 1, 'period': 3.4, 'depth': 1500, 'source': 'default'},
            {'target_id': 'KIC11904151', 'label': 1, 'period': 0.84, 'depth': 152, 'source': 'default'}
        ])

    print(f"\nâœ… èµ„æ–™è½½å…¥å®Œæˆï¼Œå‡†å¤‡åˆ†æ {len(sample_targets)} ä¸ªç›®æ ‡")

    return sample_targets


def main():
    """
    ä¸»æ‰§è¡Œå‡½æ•° - å®Œæ•´çš„æ•°æ®åŠ è½½æµç¨‹
    """
    print("="*60)
    print("ğŸ”§ è½½å…¥å·²ä¸‹è½½çš„èµ„æ–™é›†")
    print("ä» GitHub è‡ªåŠ¨è½½å…¥èµ„æ–™ï¼ˆé€‚ç”¨äº Colabï¼‰")
    print("="*60)

    # 1. è®¾ç½®æ•°æ®ç›®å½•
    data_dir, IN_COLAB = setup_data_directory()

    # 2. è½½å…¥æ•°æ®é›†
    datasets = load_datasets(data_dir)

    # 3. åˆ›å»ºæ ·æœ¬ç›®æ ‡
    sample_targets = create_sample_targets(datasets)

    return sample_targets, datasets, data_dir, IN_COLAB


# å¦‚æœç›´æ¥æ‰§è¡Œæ­¤è„šæœ¬
if __name__ == "__main__":
    sample_targets, datasets, data_dir, IN_COLAB = main()
    print(f"\nâœ… æ•°æ®åŠ è½½å®Œæˆï¼")
    print(f"   - æ•°æ®ç›®å½•: {data_dir}")
    print(f"   - ç¯å¢ƒ: {'Google Colab' if IN_COLAB else 'æœ¬åœ°ç¯å¢ƒ'}")
    print(f"   - æ ·æœ¬æ•°: {len(sample_targets)}")