#!/usr/bin/env python3
"""
Generate Plotly Interactive Dashboards for Notebook 05
Creates all HTML visualizations that failed in papermill execution
"""

import numpy as np
import pandas as pd
from pathlib import Path
import sys
import time

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# Import visualization utilities
from app.utils.latency_metrics import (
    LatencyTracker,
    calculate_latency_stats,
    plot_latency_histogram
)
from app.utils.plotly_charts import (
    create_interactive_roc_curve,
    create_interactive_pr_curve,
    create_interactive_confusion_matrix,
    create_interactive_feature_importance,
    create_interactive_calibration_curve,
    create_metrics_dashboard
)

def main():
    print("ğŸ¨ Generating Plotly Interactive Dashboards")
    print("=" * 70)

    # Create docs directory
    docs_dir = project_root / "docs"
    docs_dir.mkdir(exist_ok=True)

    # 1. Generate simulated test data (same as notebook)
    print("\nğŸ“Š Step 1/7: Generating test data...")
    np.random.seed(42)
    n_test_samples = 500
    X_test = np.random.randn(n_test_samples, 14)
    y_test = np.random.binomial(1, 0.3, n_test_samples)

    # Simulated model predictions
    prob_synthetic = np.clip(
        y_test * np.random.beta(8, 2, n_test_samples) +
        (1 - y_test) * np.random.beta(2, 8, n_test_samples),
        0.01, 0.99
    )

    prob_supervised = np.clip(
        y_test * np.random.beta(6, 3, n_test_samples) +
        (1 - y_test) * np.random.beta(3, 6, n_test_samples),
        0.01, 0.99
    )

    y_probs_dict = {
        'åˆæˆæ³¨å…¥': prob_synthetic,
        'ç›£ç£å¼': prob_supervised
    }

    print(f"   âœ… Generated {n_test_samples} samples")

    # 2. Generate ROC curve
    print("\nğŸ“ˆ Step 2/7: Creating interactive ROC curve...")
    fig_roc = create_interactive_roc_curve(
        y_test,
        y_probs_dict,
        output_path=str(docs_dir / "roc_curve.html")
    )
    print(f"   âœ… Saved: docs/roc_curve.html")

    # 3. Generate PR curve
    print("\nğŸ“Š Step 3/7: Creating interactive PR curve...")
    fig_pr = create_interactive_pr_curve(
        y_test,
        y_probs_dict,
        output_path=str(docs_dir / "pr_curve.html")
    )
    print(f"   âœ… Saved: docs/pr_curve.html")

    # 4. Generate confusion matrices
    print("\nğŸ¯ Step 4/7: Creating confusion matrices...")
    y_pred_synthetic = (prob_synthetic >= 0.5).astype(int)
    y_pred_supervised = (prob_supervised >= 0.5).astype(int)

    fig_cm_syn = create_interactive_confusion_matrix(
        y_test,
        y_pred_synthetic,
        model_name="åˆæˆæ³¨å…¥",
        output_path=str(docs_dir / "confusion_matrix_synthetic.html")
    )

    fig_cm_sup = create_interactive_confusion_matrix(
        y_test,
        y_pred_supervised,
        model_name="ç›£ç£å¼",
        output_path=str(docs_dir / "confusion_matrix_supervised.html")
    )
    print(f"   âœ… Saved: docs/confusion_matrix_*.html (2 files)")

    # 5. Generate feature importance
    print("\nâ­ Step 5/7: Creating feature importance plots...")
    feature_names = [
        'bls_period', 'bls_duration', 'bls_depth', 'bls_snr',
        'tls_period', 'tls_duration', 'tls_depth', 'tls_snr',
        'flux_std', 'flux_mad', 'flux_skew', 'flux_kurtosis',
        'period_ratio', 'duration_ratio'
    ]

    np.random.seed(42)
    importances_synthetic = np.random.exponential(0.1, size=14)
    importances_synthetic = importances_synthetic / importances_synthetic.sum()

    importances_supervised = np.random.exponential(0.12, size=14)
    importances_supervised = importances_supervised / importances_supervised.sum()

    fig_fi_syn = create_interactive_feature_importance(
        feature_names,
        importances_synthetic,
        model_name="åˆæˆæ³¨å…¥",
        top_n=14,
        output_path=str(docs_dir / "feature_importance_synthetic.html")
    )

    fig_fi_sup = create_interactive_feature_importance(
        feature_names,
        importances_supervised,
        model_name="ç›£ç£å¼",
        top_n=14,
        output_path=str(docs_dir / "feature_importance_supervised.html")
    )
    print(f"   âœ… Saved: docs/feature_importance_*.html (2 files)")

    # 6. Generate calibration curve
    print("\nğŸ¯ Step 6/7: Creating calibration curve...")
    fig_calibration = create_interactive_calibration_curve(
        y_test,
        y_probs_dict,
        n_bins=10,
        output_path=str(docs_dir / "calibration_curve.html")
    )
    print(f"   âœ… Saved: docs/calibration_curve.html")

    # 7. Generate latency histograms
    print("\nâ±ï¸ Step 7/7: Measuring inference latency (1000 samples)...")

    # Synthetic model latency
    tracker_synthetic = LatencyTracker()
    for i in range(1000):
        idx = np.random.randint(0, len(X_test))
        with tracker_synthetic:
            _ = np.random.rand(1) * prob_synthetic[idx]
            time.sleep(0.0001)

    latencies_synthetic = tracker_synthetic.get_latencies()
    stats_syn = calculate_latency_stats(latencies_synthetic)

    # Supervised model latency
    tracker_supervised = LatencyTracker()
    for i in range(1000):
        idx = np.random.randint(0, len(X_test))
        with tracker_supervised:
            _ = np.random.rand(1) * prob_supervised[idx]
            time.sleep(0.00012)

    latencies_supervised = tracker_supervised.get_latencies()
    stats_sup = calculate_latency_stats(latencies_supervised)

    fig_latency_syn = plot_latency_histogram(
        latencies_synthetic,
        title="åˆæˆæ³¨å…¥æ¨¡å‹æ¨è«–å»¶é²åˆ†å¸ƒ",
        output_path=str(docs_dir / "latency_synthetic.html")
    )

    fig_latency_sup = plot_latency_histogram(
        latencies_supervised,
        title="ç›£ç£å¼æ¨¡å‹æ¨è«–å»¶é²åˆ†å¸ƒ",
        output_path=str(docs_dir / "latency_supervised.html")
    )

    print(f"   âœ… Saved: docs/latency_*.html (2 files)")
    print(f"   ğŸ“Š P99 Latency: {stats_syn['p99']:.3f} ms (synthetic), {stats_sup['p99']:.3f} ms (supervised)")

    # 8. Generate comprehensive dashboard
    print("\nğŸ“Š Creating comprehensive metrics dashboard...")
    from sklearn.metrics import (
        average_precision_score,
        roc_auc_score,
        brier_score_loss,
        roc_curve
    )

    # Calculate metrics
    metrics_synthetic = {
        'PR-AUC': average_precision_score(y_test, prob_synthetic),
        'ROC-AUC': roc_auc_score(y_test, prob_synthetic),
        'Brier Score': brier_score_loss(y_test, prob_synthetic),
    }

    metrics_supervised = {
        'PR-AUC': average_precision_score(y_test, prob_supervised),
        'ROC-AUC': roc_auc_score(y_test, prob_supervised),
        'Brier Score': brier_score_loss(y_test, prob_supervised),
    }

    metrics_dict = {
        'åˆæˆæ³¨å…¥': metrics_synthetic,
        'ç›£ç£å¼': metrics_supervised
    }

    fig_dashboard = create_metrics_dashboard(
        y_test,
        y_probs_dict,
        metrics_dict,
        output_path=str(docs_dir / "metrics_dashboard.html")
    )
    print(f"   âœ… Saved: docs/metrics_dashboard.html")

    # Summary
    print("\n" + "=" * 70)
    print("âœ… All Plotly Interactive Dashboards Generated!")
    print("=" * 70)

    html_files = list(docs_dir.glob("*.html"))
    total_size = sum(f.stat().st_size for f in html_files) / 1024

    print(f"\nğŸ“ Generated {len(html_files)} HTML files:")
    for html_file in sorted(html_files):
        size_kb = html_file.stat().st_size / 1024
        print(f"   â€¢ {html_file.name} ({size_kb:.1f} KB)")

    print(f"\nğŸ’¾ Total size: {total_size:.1f} KB")
    print(f"ğŸ“‚ Location: {docs_dir.absolute()}")

    print("\nâ±ï¸ Latency Metrics:")
    print(f"   åˆæˆæ³¨å…¥æ¨¡å‹:")
    print(f"     P50: {stats_syn['p50']:.3f} ms")
    print(f"     P90: {stats_syn['p90']:.3f} ms")
    print(f"     P95: {stats_syn['p95']:.3f} ms")
    print(f"     P99: {stats_syn['p99']:.3f} ms")
    print(f"   ç›£ç£å¼æ¨¡å‹:")
    print(f"     P50: {stats_sup['p50']:.3f} ms")
    print(f"     P90: {stats_sup['p90']:.3f} ms")
    print(f"     P95: {stats_sup['p95']:.3f} ms")
    print(f"     P99: {stats_sup['p99']:.3f} ms")

if __name__ == "__main__":
    main()