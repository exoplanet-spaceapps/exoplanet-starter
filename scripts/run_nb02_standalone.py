# Standalone execution of Notebook 02
# Auto-generated script to process all 11,979 samples

import sys
import os

# Add notebooks folder to path for module imports
notebooks_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'notebooks')
if notebooks_path not in sys.path:
    sys.path.insert(0, notebooks_path)

# Ensure UTF-8 output
import io
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding="utf-8", errors="replace")


# ===== CELL 3 =====
# ç’°å¢ƒè¨­å®šèˆ‡ä¾è³´å®‰è£ï¼ˆColabï¼‰
import sys, subprocess, pkgutil
import warnings
warnings.filterwarnings('ignore')

def pipi(*pkgs):
    """å®‰è£å¥—ä»¶çš„è¼”åŠ©å‡½å¼"""
    subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", *pkgs])

# å®‰è£å¿…è¦å¥—ä»¶ï¼ˆé¿å… numpy 2.0 ç›¸å®¹æ€§å•é¡Œï¼‰
print("ğŸš€ æ­£åœ¨å®‰è£ä¾è³´å¥—ä»¶...")
try:
    import numpy as np
    import lightkurve as lk
    import transitleastsquares as tls
    print("âœ… åŸºç¤å¥—ä»¶å·²å®‰è£")
except Exception:
    pipi("numpy<2", "lightkurve", "astroquery", "scikit-learn", 
         "matplotlib", "wotan", "transitleastsquares")
    print("âœ… ä¾è³´å¥—ä»¶å®‰è£å®Œæˆ")

# æª¢æŸ¥ GPU è³‡è¨Š
# æª¢æŸ¥ GPU è³‡è¨Šï¼ˆå˜—è©¦å°å…¥ torchï¼‰
try:
    import torch
except ImportError:
    torch = None

if torch is not None and torch.cuda.is_available():
    gpu_name = torch.cuda.get_device_name(0)
    print(f"ğŸ–¥ï¸ GPU å‹è™Ÿ: {gpu_name}")
    print(f"   è¨˜æ†¶é«”: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
    
    # å¦‚æœæ˜¯ NVIDIA L4ï¼Œæä¾› BF16 å„ªåŒ–å»ºè­°
    if "L4" in gpu_name:
        print("ğŸ’¡ åµæ¸¬åˆ° NVIDIA L4 GPU - æ”¯æ´é«˜æ•ˆèƒ½ BF16 é‹ç®—")
        print("   å»ºè­°åœ¨è¨“ç·´æ™‚ä½¿ç”¨ torch.autocast('cuda', dtype=torch.bfloat16)")
else:
    try:
        # ä½¿ç”¨ nvidia-smi æª¢æŸ¥ GPU
        result = subprocess.run(['nvidia-smi', '--query-gpu=name', '--format=csv,noheader'], 
                              capture_output=True, text=True, check=False)
        if result.returncode == 0:
            gpu_name = result.stdout.strip()
            print(f"ğŸ–¥ï¸ GPU å‹è™Ÿ: {gpu_name}")
            if "L4" in gpu_name:
                print("ğŸ’¡ åµæ¸¬åˆ° NVIDIA L4 GPU - æ”¯æ´é«˜æ•ˆèƒ½ BF16 é‹ç®—")
    except:
        print("âš ï¸ æœªåµæ¸¬åˆ° GPUï¼Œå°‡ä½¿ç”¨ CPU é‹ç®—")

print("\nç’°å¢ƒè¨­å®šå®Œæˆï¼")
# ===== CELL 4 =====
# ğŸ”§ è¨­å®šå¯é‡ç¾æ€§èˆ‡æ—¥èªŒè¨˜éŒ„ (2025 Best Practices)"""Phase 1: Critical Infrastructure- è¨­å®šéš¨æ©Ÿç¨®å­ç¢ºä¿å¯é‡ç¾æ€§- åˆå§‹åŒ–æ—¥èªŒè¨˜éŒ„ç³»çµ±- è¨˜éŒ„ç³»çµ±ç’°å¢ƒè³‡è¨Š"""import sysimport osfrom pathlib import Path# ç¢ºä¿ src ç›®éŒ„åœ¨ Python è·¯å¾‘ä¸­if IN_COLAB:    # Colab ç’°å¢ƒï¼šå°ˆæ¡ˆåœ¨ /content/exoplanet-starter    src_path = Path('/content/exoplanet-starter/src')else:    # æœ¬åœ°ç’°å¢ƒï¼šå‘ä¸Šä¸€å±¤æ‰¾åˆ°å°ˆæ¡ˆæ ¹ç›®éŒ„    src_path = Path(__file__).parent.parent / 'src' if '__file__' in globals() else Path('../src').resolve()if src_path.exists() and str(src_path) not in sys.path:    sys.path.insert(0, str(src_path))    print(f"ğŸ“‚ å·²æ·»åŠ  src è·¯å¾‘: {src_path}")# å°å…¥å·¥å…·æ¨¡çµ„try:    from utils import set_random_seeds, setup_logger, get_log_file_path, log_system_info    # 1ï¸âƒ£ è¨­å®šéš¨æ©Ÿç¨®å­ (ç¢ºä¿å¯é‡ç¾æ€§)    set_random_seeds(42)    # 2ï¸âƒ£ è¨­å®šæ—¥èªŒè¨˜éŒ„    log_file = get_log_file_path("02_bls_baseline", results_dir=Path("../results") if not IN_COLAB else Path("/content/exoplanet-starter/results"))    logger = setup_logger("02_bls_baseline", log_file=log_file, verbose=True)    # 3ï¸âƒ£ è¨˜éŒ„ç³»çµ±è³‡è¨Š    logger.info("="*60)    logger.info("ğŸš€ 02_bls_baseline.ipynb é–‹å§‹åŸ·è¡Œ")    logger.info("="*60)    log_system_info(logger)    print("âœ… å¯é‡ç¾æ€§èˆ‡æ—¥èªŒè¨˜éŒ„è¨­å®šå®Œæˆ")    print(f"   ğŸ“ æ—¥èªŒæª”æ¡ˆ: {log_file}")    print(f"   ğŸ² éš¨æ©Ÿç¨®å­: 42")except ImportError as e:    print(f"âš ï¸ ç„¡æ³•å°å…¥å·¥å…·æ¨¡çµ„: {e}")    print("   è·³éå¯é‡ç¾æ€§è¨­å®šï¼Œç¹¼çºŒåŸ·è¡Œ...")    # å¦‚æœå°å…¥å¤±æ•—ï¼Œå‰µå»ºä¸€å€‹ç°¡å–®çš„ logger fallback    import logging    logger = logging.getLogger("02_bls_baseline")    logger.addHandler(logging.StreamHandler(sys.stdout))    logger.setLevel(logging.INFO)
# ===== CELL 6 =====
import lightkurve as lk
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.gridspec import GridSpec
import pandas as pd
from transitleastsquares import transitleastsquares
from typing import Dict, Any, Tuple, Optional
import time

# è¨­å®šåœ–è¡¨é¢¨æ ¼
plt.style.use('seaborn-v0_8-darkgrid')
plt.rcParams['figure.figsize'] = (12, 6)
plt.rcParams['font.size'] = 10

print("ğŸ“š å¥—ä»¶å°å…¥å®Œæˆ")
print(f"   Lightkurve ç‰ˆæœ¬: {lk.__version__}")
print(f"   NumPy ç‰ˆæœ¬: {np.__version__}")
# ===== CELL 8 =====
# ğŸ”§ è¼‰å…¥å·²ä¸‹è¼‰çš„è³‡æ–™é›†
"""
å¾ 01_tap_download.ipynb è¼‰å…¥å·²è™•ç†çš„è³‡æ–™
ä½¿ç”¨ data_loader_colab.py æ¨¡çµ„é€²è¡Œçµ±ä¸€çš„è³‡æ–™è¼‰å…¥
"""

# å°å…¥è³‡æ–™è¼‰å…¥æ¨¡çµ„
import data_loader_colab

# åŸ·è¡Œå®Œæ•´çš„è³‡æ–™è¼‰å…¥æµç¨‹
# è‡ªå‹•è™•ç† Colab/æœ¬åœ°ç’°å¢ƒå·®ç•°ï¼Œå¾ GitHub å…‹éš†è³‡æ–™ï¼ˆå¦‚éœ€è¦ï¼‰
sample_targets, datasets, data_dir, IN_COLAB = data_loader_colab.main()

# è³‡æ–™è¼‰å…¥å®Œæˆï¼Œå¯ä»¥é–‹å§‹åˆ†æ
print(f"\nâœ… è³‡æ–™è¼‰å…¥å®Œæˆï¼")
print(f"   ğŸ“‚ è³‡æ–™ç›®éŒ„: {data_dir}")
print(f"   ğŸŒ ç’°å¢ƒ: {'Google Colab' if IN_COLAB else 'æœ¬åœ°ç’°å¢ƒ'}")
print(f"   ğŸ“Š è¼‰å…¥è³‡æ–™é›†: {len(datasets)} å€‹")
print(f"   ğŸ¯ åˆ†ææ¨£æœ¬: {len(sample_targets)} å€‹ç›®æ¨™")
print(f"\næº–å‚™é–‹å§‹ BLS/TLS åŸºç·šåˆ†æ...")
# ===== CELL 9 =====
# ğŸ¯ å»ºç«‹åˆ†æç›®æ¨™åˆ—è¡¨
"""
å¾è¼‰å…¥çš„è³‡æ–™å»ºç«‹ç›®æ¨™å¤©é«”åˆ—è¡¨ä¾› BLS/TLS åˆ†æ
"""

targets = []

# å¾æ¨£æœ¬ä¸­å»ºç«‹ç›®æ¨™åˆ—è¡¨
for idx, row in sample_targets.iterrows():
    # æå– TIC/KIC ID
    target_id = row.get('target_id', f'Unknown_{idx}')
    
    # æ¸…ç†ä¸¦æ ¼å¼åŒ– ID
    if 'TIC' in str(target_id):
        clean_id = str(target_id).replace('TIC', '').strip()
        formatted_id = f"TIC {clean_id}"
        mission = "TESS"
    elif 'KIC' in str(target_id):
        clean_id = str(target_id).replace('KIC', '').strip() 
        formatted_id = f"KIC {clean_id}"
        mission = "Kepler"
    else:
        # å¦‚æœæ²’æœ‰æ˜ç¢ºæ¨™ç¤ºï¼Œæ ¹æ“š ID ç¯„åœåˆ¤æ–·
        try:
            id_num = int(''.join(filter(str.isdigit, str(target_id))))
            if id_num > 100000000:  # å¤§æ–¼1å„„é€šå¸¸æ˜¯TIC
                formatted_id = f"TIC {id_num}"
                mission = "TESS"
            else:  # å¦å‰‡å‡è¨­æ˜¯KIC
                formatted_id = f"KIC {id_num}"
                mission = "Kepler"
        except:
            formatted_id = str(target_id)
            mission = "Unknown"
    
    # å»ºç«‹ç›®æ¨™å­—å…¸
    target_dict = {
        "id": formatted_id,
        "mission": mission,
        "name": row.get('toi', row.get('target_name', target_id)),
        "description": f"{'æ­£æ¨£æœ¬ (è¡Œæ˜Ÿå€™é¸)' if row['label'] == 1 else 'è² æ¨£æœ¬ (False Positive)'}",
        "label": row['label'],
        "source": row.get('source', 'Unknown')
    }
    
    # æ·»åŠ ç‰©ç†åƒæ•¸ï¼ˆå¦‚æœæœ‰ï¼‰
    if 'period' in row and pd.notna(row['period']):
        target_dict['known_period'] = float(row['period'])
    if 'depth' in row and pd.notna(row['depth']):
        target_dict['known_depth'] = float(row['depth'])
    
    targets.append(target_dict)

# å¦‚æœæ²’æœ‰å¾è³‡æ–™è¼‰å…¥ç›®æ¨™ï¼Œä½¿ç”¨é è¨­ç›®æ¨™
if len(targets) == 0:
    print("âš ï¸ ç„¡æ³•å¾è³‡æ–™é›†è¼‰å…¥ç›®æ¨™ï¼Œä½¿ç”¨é è¨­ç›®æ¨™")
    targets = [
        {"id": "TIC 25155310", "mission": "TESS", "name": "TOI-431", 
         "description": "æ“æœ‰3é¡†å·²ç¢ºèªè¡Œæ˜Ÿçš„Kå‹çŸ®æ˜Ÿ", "label": 1, "source": "default"},
        {"id": "TIC 307210830", "mission": "TESS", "name": "TOI-270",
         "description": "æ“æœ‰3é¡†å°å‹è¡Œæ˜Ÿçš„Må‹çŸ®æ˜Ÿ", "label": 1, "source": "default"},
        {"id": "KIC 11904151", "mission": "Kepler", "name": "Kepler-10",
         "description": "ç¬¬ä¸€å€‹è¢«ç¢ºèªçš„å²©çŸ³ç³»å¤–è¡Œæ˜Ÿå®¿ä¸»æ†æ˜Ÿ", "label": 1, "source": "default"}
    ]

print("ğŸ¯ åˆ†æç›®æ¨™ï¼š")
for i, target in enumerate(targets, 1):
    print(f"   {i}. {target['name']} ({target['id']}) - {target['mission']}")
    print(f"      {target['description']}")
    if 'known_period' in target:
        print(f"      å·²çŸ¥é€±æœŸ: {target['known_period']:.3f} å¤©")
    if 'known_depth' in target:
        print(f"      å·²çŸ¥æ·±åº¦: {target['known_depth']:.0f} ppm")
    print()

print(f"âœ… å»ºç«‹å®Œæˆï¼Œå…± {len(targets)} å€‹åˆ†æç›®æ¨™")
# ===== CELL 11 =====
def download_and_process_lightcurve(
    target_id: str, 
    mission: str, 
    author: str = "SPOC",
    cadence: str = "short"
) -> Tuple[lk.LightCurve, lk.LightCurve, Dict[str, Any]]:
    """
    ä¸‹è¼‰ä¸¦è™•ç†å…‰æ›²ç·šè³‡æ–™
    
    Parameters:
    -----------
    target_id : str
        ç›®æ¨™å¤©é«”è­˜åˆ¥ç¢¼ï¼ˆTIC/KICï¼‰
    mission : str
        ä»»å‹™åç¨±ï¼ˆTESS/Keplerï¼‰
    author : str
        è³‡æ–™æä¾›è€…ï¼ˆSPOC/PDCSAPï¼‰
    cadence : str
        è§€æ¸¬é »ç‡ï¼ˆshort/longï¼‰
    
    Returns:
    --------
    tuple : (åŸå§‹å…‰æ›²ç·š, å»è¶¨å‹¢å…‰æ›²ç·š, metadataå­—å…¸)
    """
    print(f"\nğŸ“¡ æ­£åœ¨ä¸‹è¼‰ {target_id} çš„å…‰æ›²ç·š...")
    
    # æœå°‹ä¸¦ä¸‹è¼‰å…‰æ›²ç·š
    search_result = lk.search_lightcurve(
        target_id, 
        mission=mission, 
        author=author if mission == "TESS" else None,
        cadence=cadence
    )
    
    if len(search_result) == 0:
        raise ValueError(f"æœªæ‰¾åˆ° {target_id} çš„å…‰æ›²ç·šè³‡æ–™")
    
    print(f"   æ‰¾åˆ° {len(search_result)} å€‹å…‰æ›²ç·šæª”æ¡ˆ")
    
    # ä¸‹è¼‰ç¬¬ä¸€å€‹sector/quarterçš„è³‡æ–™
    lc_collection = search_result[0].download()
    
    # å¦‚æœæ˜¯collectionï¼Œå–ç¬¬ä¸€å€‹å…‰æ›²ç·š
    if hasattr(lc_collection, '__iter__'):
        lc_raw = lc_collection[0]
    else:
        lc_raw = lc_collection
        
    # è¨˜éŒ„metadata
    metadata = {
        "target_id": target_id,
        "mission": mission,
        "sector" if mission == "TESS" else "quarter": lc_raw.meta.get('SECTOR', lc_raw.meta.get('QUARTER', 'N/A')),
        "exposure_time": lc_raw.meta.get('EXPOSURE', 'N/A'),
        "n_points_raw": len(lc_raw.time),
    }
    
    print(f"   âœ… ä¸‹è¼‰å®Œæˆï¼š{metadata['n_points_raw']} å€‹è³‡æ–™é»")
    
    # æ¸…ç†è³‡æ–™ï¼šç§»é™¤NaNå€¼
    lc_clean = lc_raw.remove_nans()
    
    # å»è¶¨å‹¢è™•ç†
    print(f"   ğŸ”§ æ­£åœ¨é€²è¡Œå»è¶¨å‹¢è™•ç†...")
    lc_flat = lc_clean.flatten(window_length=401)
    
    metadata['n_points_clean'] = len(lc_clean.time)
    metadata['n_points_flat'] = len(lc_flat.time)
    metadata['removed_points'] = metadata['n_points_raw'] - metadata['n_points_clean']
    
    print(f"   âœ… å»è¶¨å‹¢å®Œæˆï¼šä¿ç•™ {metadata['n_points_flat']} å€‹è³‡æ–™é»")
    
    return lc_clean, lc_flat, metadata
# ===== CELL 13 =====
# å„²å­˜è™•ç†çµæœ
processed_data = {}

for target in targets:
    try:
        lc_clean, lc_flat, metadata = download_and_process_lightcurve(
            target["id"],
            target["mission"],
            author="SPOC" if target["mission"] == "TESS" else None
        )
        
        processed_data[target["id"]] = {
            "target": target,
            "lc_clean": lc_clean,
            "lc_flat": lc_flat,
            "metadata": metadata
        }
        
    except Exception as e:
        print(f"   âŒ è™•ç† {target['id']} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        continue

print(f"\nâœ… æˆåŠŸè™•ç† {len(processed_data)} å€‹ç›®æ¨™")
# ===== CELL 15 =====
def plot_raw_vs_detrended(data_dict: Dict[str, Any]):
    """
    ç¹ªè£½åŸå§‹èˆ‡å»è¶¨å‹¢å…‰æ›²ç·šå°æ¯”åœ–
    """
    target = data_dict["target"]
    lc_clean = data_dict["lc_clean"]
    lc_flat = data_dict["lc_flat"]
    metadata = data_dict["metadata"]
    
    fig = plt.figure(figsize=(14, 8))
    gs = GridSpec(3, 1, height_ratios=[1, 1, 0.8], hspace=0.3)
    
    # åŸå§‹å…‰æ›²ç·š
    ax1 = fig.add_subplot(gs[0])
    lc_clean.plot(ax=ax1, color='blue', alpha=0.7, label='åŸå§‹å…‰æ›²ç·š')
    ax1.set_title(f"{target['name']} ({target['id']}) - åŸå§‹å…‰æ›²ç·š", fontsize=12, fontweight='bold')
    ax1.set_ylabel('ç›¸å°æµé‡ (eâ»/s)', fontsize=10)
    ax1.legend(loc='upper right')
    ax1.grid(True, alpha=0.3)
    
    # å»è¶¨å‹¢å…‰æ›²ç·š
    ax2 = fig.add_subplot(gs[1])
    lc_flat.plot(ax=ax2, color='green', alpha=0.7, label='å»è¶¨å‹¢å…‰æ›²ç·š')
    ax2.set_title('å»è¶¨å‹¢å¾Œå…‰æ›²ç·šï¼ˆwindow_length=401ï¼‰', fontsize=12, fontweight='bold')
    ax2.set_ylabel('æ¨™æº–åŒ–æµé‡', fontsize=10)
    ax2.set_xlabel('æ™‚é–“ (BTJD)', fontsize=10)
    ax2.legend(loc='upper right')
    ax2.grid(True, alpha=0.3)
    
    # ç›´æ–¹åœ–æ¯”è¼ƒ
    ax3 = fig.add_subplot(gs[2])
    
    # è¨ˆç®—æ¨™æº–åŒ–çš„æµé‡å€¼
    flux_clean_norm = (lc_clean.flux - np.nanmean(lc_clean.flux)) / np.nanstd(lc_clean.flux)
    flux_flat_norm = (lc_flat.flux - np.nanmean(lc_flat.flux)) / np.nanstd(lc_flat.flux)
    
    ax3.hist(flux_clean_norm, bins=50, alpha=0.5, color='blue', label='åŸå§‹', density=True)
    ax3.hist(flux_flat_norm, bins=50, alpha=0.5, color='green', label='å»è¶¨å‹¢', density=True)
    ax3.set_xlabel('æ¨™æº–åŒ–æµé‡', fontsize=10)
    ax3.set_ylabel('æ©Ÿç‡å¯†åº¦', fontsize=10)
    ax3.set_title('æµé‡åˆ†ä½ˆæ¯”è¼ƒ', fontsize=12)
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # æ·»åŠ æ–‡å­—èªªæ˜
    textstr = f"""è³‡æ–™çµ±è¨ˆ:
åŸå§‹è³‡æ–™é»: {metadata['n_points_raw']:,}
æ¸…ç†å¾Œ: {metadata['n_points_clean']:,}
ç§»é™¤NaN: {metadata['removed_points']:,}
{'Sector' if metadata['mission'] == 'TESS' else 'Quarter'}: {metadata.get('sector', metadata.get('quarter', 'N/A'))}
"""
    ax3.text(0.02, 0.98, textstr, transform=ax3.transAxes, fontsize=9,
            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
    
    plt.suptitle(f"{target['description']}", fontsize=11, y=1.02)
    plt.tight_layout()
    plt.show()
    
    return fig
# ===== CELL 16 =====
# ç¹ªè£½æ‰€æœ‰ç›®æ¨™çš„å°æ¯”åœ–
for target_id, data in processed_data.items():
    print(f"\nğŸ“Š ç¹ªè£½ {data['target']['name']} çš„å…‰æ›²ç·šå°æ¯”åœ–...")
    fig = plot_raw_vs_detrended(data)
    
    # èªªæ˜æ–‡å­—
    print(f"""
    ğŸ’¡ èªªæ˜ï¼š
    - åŸå§‹å…‰æ›²ç·šé¡¯ç¤ºäº†å„€å™¨æ•ˆæ‡‰é€ æˆçš„é•·æœŸè¶¨å‹¢
    - å»è¶¨å‹¢è™•ç†ä¿ç•™äº†çŸ­é€±æœŸè®ŠåŒ–ï¼ˆå¦‚è¡Œæ˜Ÿå‡Œæ—¥ï¼‰
    - æµé‡åˆ†ä½ˆåœ–é¡¯ç¤ºå»è¶¨å‹¢å¾Œçš„è³‡æ–™æ›´æ¥è¿‘å¸¸æ…‹åˆ†ä½ˆ
    """)
# ===== CELL 18 =====
def run_bls_search(
    lc: lk.LightCurve,
    min_period: float = 0.5,
    max_period: float = 20.0,
    frequency_factor: float = 5.0
) -> Dict[str, Any]:
    """
    åŸ·è¡Œ BLS é€±æœŸæœå°‹
    
    Parameters:
    -----------
    lc : lightkurve.LightCurve
        è¼¸å…¥å…‰æ›²ç·š
    min_period : float
        æœ€å°æœå°‹é€±æœŸï¼ˆå¤©ï¼‰
    max_period : float
        æœ€å¤§æœå°‹é€±æœŸï¼ˆå¤©ï¼‰
    frequency_factor : float
        é »ç‡è§£æåº¦å› å­
    
    Returns:
    --------
    dict : BLS çµæœå­—å…¸
    """
    print(f"   ğŸ” åŸ·è¡Œ BLS æœå°‹ ({min_period:.1f} - {max_period:.1f} å¤©)...")
    
    start_time = time.time()
    
    # åŸ·è¡Œ BLS
    bls = lc.to_periodogram(
        method="bls",
        minimum_period=min_period,
        maximum_period=max_period,
        frequency_factor=frequency_factor
    )
    
    # æå–æœ€å¼·å³°å€¼çš„åƒæ•¸
    period = bls.period_at_max_power
    t0 = bls.transit_time_at_max_power
    duration = bls.duration_at_max_power
    depth = bls.depth_at_max_power
    snr = bls.max_power
    
    elapsed_time = time.time() - start_time
    
    results = {
        "periodogram": bls,
        "period": period.value if hasattr(period, 'value') else period,
        "t0": t0.value if hasattr(t0, 'value') else t0,
        "duration": duration.value if hasattr(duration, 'value') else duration,
        "depth": depth.value if hasattr(depth, 'value') else depth,
        "snr": snr.value if hasattr(snr, 'value') else snr,
        "elapsed_time": elapsed_time
    }
    
    print(f"   âœ… BLS å®Œæˆï¼ˆè€—æ™‚ {elapsed_time:.2f} ç§’ï¼‰")
    print(f"      æœ€ä½³é€±æœŸ: {results['period']:.4f} å¤©")
    print(f"      SNR: {results['snr']:.2f}")
    print(f"      æ·±åº¦: {results['depth']*1e6:.0f} ppm")
    
    return results
# ===== CELL 20 =====
def run_tls_search(
    lc: lk.LightCurve,
    min_period: float = 0.5,
    max_period: float = 20.0
) -> Dict[str, Any]:
    """
    åŸ·è¡Œ TLS é€±æœŸæœå°‹
    
    Parameters:
    -----------
    lc : lightkurve.LightCurve
        è¼¸å…¥å…‰æ›²ç·š
    min_period : float
        æœ€å°æœå°‹é€±æœŸï¼ˆå¤©ï¼‰
    max_period : float
        æœ€å¤§æœå°‹é€±æœŸï¼ˆå¤©ï¼‰
    
    Returns:
    --------
    dict : TLS çµæœå­—å…¸
    """
    print(f"   ğŸ” åŸ·è¡Œ TLS æœå°‹ ({min_period:.1f} - {max_period:.1f} å¤©)...")
    
    start_time = time.time()
    
    # æº–å‚™ TLS è¼¸å…¥
    time_array = lc.time.value if hasattr(lc.time, 'value') else np.array(lc.time)
    flux_array = lc.flux.value if hasattr(lc.flux, 'value') else np.array(lc.flux)
    
    # åˆå§‹åŒ– TLS
    model = transitleastsquares(time_array, flux_array)
    
    # åŸ·è¡Œæœå°‹
    tls_results = model.power(
        period_min=min_period,
        period_max=max_period,
        show_progress_bar=False,
        use_threads=4
    )
    
    elapsed_time = time.time() - start_time
    
    results = {
        "tls_object": tls_results,
        "period": tls_results.period,
        "t0": tls_results.T0,
        "duration": tls_results.duration,
        "depth": tls_results.depth,
        "snr": tls_results.SDE,  # Signal Detection Efficiency
        "elapsed_time": elapsed_time,
        "periods": tls_results.periods,
        "power": tls_results.power
    }
    
    print(f"   âœ… TLS å®Œæˆï¼ˆè€—æ™‚ {elapsed_time:.2f} ç§’ï¼‰")
    print(f"      æœ€ä½³é€±æœŸ: {results['period']:.4f} å¤©")
    print(f"      SDE: {results['snr']:.2f}")
    print(f"      æ·±åº¦: {results['depth']*1e6:.0f} ppm")
    
    return results
# ===== CELL 22 =====
# å„²å­˜æ‰€æœ‰æœå°‹çµæœ
search_results = {}

for target_id, data in processed_data.items():
    print(f"\nğŸš€ åˆ†æ {data['target']['name']} ({target_id})...")
    
    # åŸ·è¡Œ BLS
    bls_results = run_bls_search(
        data['lc_flat'],
        min_period=0.5,
        max_period=20.0
    )
    
    # åŸ·è¡Œ TLS
    tls_results = run_tls_search(
        data['lc_flat'],
        min_period=0.5,
        max_period=20.0
    )
    
    search_results[target_id] = {
        "bls": bls_results,
        "tls": tls_results,
        "target": data['target'],
        "lc_flat": data['lc_flat']
    }
    
print("\nâœ… æ‰€æœ‰ç›®æ¨™çš„ BLS/TLS æœå°‹å®Œæˆï¼")
# ===== CELL 24 =====
def plot_bls_tls_comparison(search_result: Dict[str, Any]):
    """
    ç¹ªè£½ BLS èˆ‡ TLS çµæœå°æ¯”åœ–
    """
    target = search_result['target']
    bls_result = search_result['bls']
    tls_result = search_result['tls']
    lc_flat = search_result['lc_flat']
    
    fig = plt.figure(figsize=(16, 10))
    gs = GridSpec(3, 2, height_ratios=[1.2, 1, 1], hspace=0.3, wspace=0.25)
    
    # BLS åŠŸç‡è­œ
    ax1 = fig.add_subplot(gs[0, 0])
    bls_result['periodogram'].plot(ax=ax1, color='blue')
    ax1.set_title('BLS åŠŸç‡è­œ', fontsize=12, fontweight='bold')
    ax1.axvline(bls_result['period'], color='red', linestyle='--', alpha=0.7, 
               label=f"P = {bls_result['period']:.3f} d")
    ax1.legend()
    ax1.set_ylabel('BLS Power')
    ax1.grid(True, alpha=0.3)
    
    # TLS åŠŸç‡è­œ
    ax2 = fig.add_subplot(gs[0, 1])
    ax2.plot(tls_result['periods'], tls_result['power'], 'g-', lw=1)
    ax2.set_title('TLS åŠŸç‡è­œ', fontsize=12, fontweight='bold')
    ax2.axvline(tls_result['period'], color='red', linestyle='--', alpha=0.7,
               label=f"P = {tls_result['period']:.3f} d")
    ax2.legend()
    ax2.set_xlabel('é€±æœŸ (å¤©)')
    ax2.set_ylabel('SDE (Signal Detection Efficiency)')
    ax2.set_xlim(0.5, 20)
    ax2.grid(True, alpha=0.3)
    
    # BLS æ‘ºç–Šå…‰æ›²ç·š
    ax3 = fig.add_subplot(gs[1, 0])
    folded_bls = lc_flat.fold(period=bls_result['period'], epoch_time=bls_result['t0'])
    folded_bls.scatter(ax=ax3, s=1, color='blue', alpha=0.3)
    folded_bls.bin(time_bin_size=0.001).plot(
        ax=ax3, color='darkblue', markersize=4, label='Binned'
    )
    ax3.set_title(f"BLS æ‘ºç–Šå…‰æ›²ç·š (P={bls_result['period']:.3f} d)", fontsize=12)
    ax3.set_xlabel('ç›¸ä½')
    ax3.set_ylabel('æ¨™æº–åŒ–æµé‡')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # TLS æ‘ºç–Šå…‰æ›²ç·š
    ax4 = fig.add_subplot(gs[1, 1])
    folded_tls = lc_flat.fold(period=tls_result['period'], epoch_time=tls_result['t0'])
    folded_tls.scatter(ax=ax4, s=1, color='green', alpha=0.3)
    folded_tls.bin(time_bin_size=0.001).plot(
        ax=ax4, color='darkgreen', markersize=4, label='Binned'
    )
    ax4.set_title(f"TLS æ‘ºç–Šå…‰æ›²ç·š (P={tls_result['period']:.3f} d)", fontsize=12)
    ax4.set_xlabel('ç›¸ä½')
    ax4.set_ylabel('æ¨™æº–åŒ–æµé‡')
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    
    # åƒæ•¸æ¯”è¼ƒè¡¨
    ax5 = fig.add_subplot(gs[2, :])
    ax5.axis('off')
    
    # å»ºç«‹æ¯”è¼ƒè¡¨æ ¼
    comparison_data = [
        ['åƒæ•¸', 'BLS', 'TLS', 'å·®ç•° (%)'],
        ['é€±æœŸ (å¤©)', f"{bls_result['period']:.4f}", f"{tls_result['period']:.4f}", 
         f"{100*(tls_result['period']-bls_result['period'])/bls_result['period']:.1f}%"],
        ['SNR/SDE', f"{bls_result['snr']:.2f}", f"{tls_result['snr']:.2f}",
         f"{100*(tls_result['snr']-bls_result['snr'])/bls_result['snr']:.1f}%"],
        ['æ·±åº¦ (ppm)', f"{bls_result['depth']*1e6:.0f}", f"{tls_result['depth']*1e6:.0f}",
         f"{100*(tls_result['depth']-bls_result['depth'])/bls_result['depth']:.1f}%"],
        ['æŒçºŒæ™‚é–“ (å°æ™‚)', f"{bls_result['duration']*24:.2f}", f"{tls_result['duration']*24:.2f}",
         f"{100*(tls_result['duration']-bls_result['duration'])/bls_result['duration']:.1f}%"],
        ['é‹ç®—æ™‚é–“ (ç§’)', f"{bls_result['elapsed_time']:.2f}", f"{tls_result['elapsed_time']:.2f}",
         f"{100*(tls_result['elapsed_time']-bls_result['elapsed_time'])/bls_result['elapsed_time']:.1f}%"]
    ]
    
    table = ax5.table(cellText=comparison_data, loc='center', cellLoc='center')
    table.auto_set_font_size(False)
    table.set_fontsize(10)
    table.scale(1, 2)
    
    # è¨­å®šè¡¨æ ¼æ¨£å¼
    for i in range(len(comparison_data)):
        for j in range(len(comparison_data[0])):
            cell = table[(i, j)]
            if i == 0:
                cell.set_facecolor('#40466e')
                cell.set_text_props(weight='bold', color='white')
            else:
                cell.set_facecolor('#f1f1f2')
            cell.set_edgecolor('white')
    
    plt.suptitle(f"{target['name']} ({target['id']}) - BLS vs TLS æ¯”è¼ƒ", 
                fontsize=14, fontweight='bold', y=0.98)
    
    plt.tight_layout()
    plt.show()
    
    return fig
# ===== CELL 25 =====
# ç¹ªè£½æ‰€æœ‰ç›®æ¨™çš„ BLS vs TLS æ¯”è¼ƒåœ–
for target_id, result in search_results.items():
    print(f"\nğŸ“Š ç¹ªè£½ {result['target']['name']} çš„ BLS vs TLS æ¯”è¼ƒåœ–...")
    fig = plot_bls_tls_comparison(result)
# ===== CELL 27 =====
# ç”Ÿæˆç¸½çµå ±å‘Š
print("="*80)
print("ğŸ“‹ BLS vs TLS ç¸½çµå ±å‘Š")
print("="*80)

summary_data = []

for target_id, result in search_results.items():
    target = result['target']
    bls = result['bls']
    tls = result['tls']
    
    print(f"\nğŸ¯ {target['name']} ({target_id})")
    print(f"   {target['description']}")
    print("\n   æ–¹æ³•æ¯”è¼ƒï¼š")
    print(f"   {'æ–¹æ³•':<10} {'é€±æœŸ(å¤©)':<12} {'SNR/SDE':<10} {'æ·±åº¦(ppm)':<12} {'æ™‚é–“(ç§’)':<10}")
    print("   " + "-"*60)
    print(f"   {'BLS':<10} {bls['period']:<12.4f} {bls['snr']:<10.2f} "
          f"{bls['depth']*1e6:<12.1f} {bls['elapsed_time']:<10.2f}")
    print(f"   {'TLS':<10} {tls['period']:<12.4f} {tls['snr']:<10.2f} "
          f"{tls['depth']*1e6:<12.1f} {tls['elapsed_time']:<10.2f}")
    
    # è¨ˆç®—å·®ç•°
    period_diff = abs(tls['period'] - bls['period']) / bls['period'] * 100
    snr_diff = (tls['snr'] - bls['snr']) / bls['snr'] * 100
    
    print(f"\n   é—œéµå·®ç•°ï¼š")
    print(f"   â€¢ é€±æœŸå·®ç•°: {period_diff:.2f}%")
    print(f"   â€¢ SNR æ”¹å–„: {snr_diff:+.1f}%")
    print(f"   â€¢ TLS é‹ç®—æ™‚é–“: {tls['elapsed_time']/bls['elapsed_time']:.1f}x BLS")
    
    summary_data.append({
        'target': target['name'],
        'period_diff_%': period_diff,
        'snr_improvement_%': snr_diff,
        'time_ratio': tls['elapsed_time']/bls['elapsed_time']
    })
# ===== CELL 28 =====
# ç¸½é«”çµ±è¨ˆ
print("\n" + "="*80)
print("ğŸ“Š ç¸½é«”çµ±è¨ˆåˆ†æ")
print("="*80)

if summary_data:
    avg_period_diff = np.mean([d['period_diff_%'] for d in summary_data])
    avg_snr_improvement = np.mean([d['snr_improvement_%'] for d in summary_data])
    avg_time_ratio = np.mean([d['time_ratio'] for d in summary_data])
    
    print(f"""
ğŸ“Œ ä¸»è¦ç™¼ç¾ï¼š

1. **é€±æœŸä¼°è¨ˆç²¾åº¦**ï¼š
   - BLS èˆ‡ TLS çš„é€±æœŸä¼°è¨ˆå¹³å‡å·®ç•°: {avg_period_diff:.2f}%
   - å…©ç¨®æ–¹æ³•å°é€±æœŸçš„ä¼°è¨ˆé«˜åº¦ä¸€è‡´

2. **åµæ¸¬éˆæ•åº¦**ï¼š
   - TLS ç›¸å° BLS çš„å¹³å‡ SNR æ”¹å–„: {avg_snr_improvement:+.1f}%
   - TLS ä½¿ç”¨æ›´çœŸå¯¦çš„å‡Œæ—¥æ¨¡å‹ï¼Œé€šå¸¸èƒ½ç²å¾—æ›´é«˜çš„åµæ¸¬éˆæ•åº¦

3. **é‹ç®—æ•ˆç‡**ï¼š
   - TLS å¹³å‡é‹ç®—æ™‚é–“æ˜¯ BLS çš„ {avg_time_ratio:.1f} å€
   - BLS æ›´å¿«é€Ÿï¼Œé©åˆåˆæ­¥ç¯©é¸
   - TLS æ›´ç²¾ç¢ºï¼Œé©åˆç¢ºèªå€™é¸é«”

4. **æ–¹æ³•é¸æ“‡å»ºè­°**ï¼š
   - **BLS**ï¼šå¿«é€Ÿæœå°‹ã€å¤§é‡è³‡æ–™åˆæ­¥ç¯©é¸ã€å³æ™‚åˆ†æ
   - **TLS**ï¼šç²¾ç¢ºæ¸¬é‡ã€å€™é¸é«”ç¢ºèªã€å°å‹è¡Œæ˜Ÿåµæ¸¬
   - **çµ„åˆç­–ç•¥**ï¼šå…ˆç”¨ BLS å¿«é€Ÿç¯©é¸ï¼Œå†ç”¨ TLS ç²¾ç¢ºåˆ†æ

5. **æŠ€è¡“å·®ç•°**ï¼š
   - **BLS**ï¼šå‡è¨­ç®±å‹ï¼ˆæ–¹å½¢ï¼‰å‡Œæ—¥æ¨¡å‹ï¼Œè¨ˆç®—ç°¡å–®å¿«é€Ÿ
   - **TLS**ï¼šä½¿ç”¨çœŸå¯¦å‡Œæ—¥æ¨¡å‹ï¼ˆå«é‚Šç·£è®Šæš—ï¼‰ï¼Œè€ƒæ…®æ†æ˜Ÿç‰©ç†
    """)
# ===== CELL 31 =====
def extract_bls_tls_features(search_results):
    """
    å¾ BLS/TLS æœå°‹çµæœæå–æ©Ÿå™¨å­¸ç¿’ç‰¹å¾µ
    
    Parameters:
    -----------
    search_results : dict
        åŒ…å« BLS å’Œ TLS çµæœçš„å­—å…¸
    
    Returns:
    --------
    dict : ç‰¹å¾µå­—å…¸
    """
    features = {}
    
    # æå–ç›®æ¨™è³‡è¨Š
    if 'target' in search_results:
        target = search_results['target']
        features['target_id'] = target.get('id', '')
        features['target_name'] = target.get('name', '')
        features['label'] = target.get('label', -1)
        features['source'] = target.get('source', '')
        features['known_period'] = target.get('known_period', np.nan)
        features['known_depth'] = target.get('known_depth', np.nan)
    
    # BLS ç‰¹å¾µ
    if 'bls' in search_results:
        bls = search_results['bls']
        features['bls_period'] = bls['period']
        features['bls_t0'] = bls['t0']
        features['bls_duration_hours'] = bls['duration'] * 24
        features['bls_depth_ppm'] = bls['depth'] * 1e6
        features['bls_snr'] = bls['snr']
        
        # è¨ˆç®—é¡å¤–çš„ BLS ç‰¹å¾µ
        if bls['period'] > 0:
            features['bls_duration_phase'] = bls['duration'] / bls['period']  # ç›¸ä½æŒçºŒæ™‚é–“
    
    # TLS ç‰¹å¾µ
    if 'tls' in search_results:
        tls = search_results['tls']
        features['tls_period'] = tls['period']
        features['tls_t0'] = tls['t0']
        features['tls_duration_hours'] = tls['duration'] * 24
        features['tls_depth_ppm'] = tls['depth'] * 1e6
        features['tls_sde'] = tls['snr']  # Signal Detection Efficiency
        
        # è¨ˆç®—é¡å¤–çš„ TLS ç‰¹å¾µ
        if tls['period'] > 0:
            features['tls_duration_phase'] = tls['duration'] / tls['period']
    
    # è¨ˆç®— BLS vs TLS æ¯”è¼ƒç‰¹å¾µ
    if 'bls' in search_results and 'tls' in search_results:
        bls = search_results['bls']
        tls = search_results['tls']
        
        # é€±æœŸä¸€è‡´æ€§
        if bls['period'] > 0:
            features['period_ratio'] = tls['period'] / bls['period']
            features['period_diff_pct'] = abs(tls['period'] - bls['period']) / bls['period'] * 100
        
        # æ·±åº¦ä¸€è‡´æ€§
        if bls['depth'] > 0:
            features['depth_ratio'] = tls['depth'] / bls['depth']
            features['depth_diff_pct'] = abs(tls['depth'] - bls['depth']) / bls['depth'] * 100
        
        # SNR æ¯”è¼ƒ
        if bls['snr'] > 0:
            features['snr_ratio'] = tls['snr'] / bls['snr']
            features['snr_improvement'] = (tls['snr'] - bls['snr']) / bls['snr'] * 100
    
    # æ·»åŠ è³‡æ–™å“è³ªæ¨™è¨˜
    features['has_bls'] = 1 if 'bls' in search_results else 0
    features['has_tls'] = 1 if 'tls' in search_results else 0
    
    return features

# æå–æ‰€æœ‰ç›®æ¨™çš„ç‰¹å¾µ
all_features = []

for target_id, result in search_results.items():
    features = extract_bls_tls_features(result)
    all_features.append(features)

# è½‰æ›ç‚º DataFrame
features_df = pd.DataFrame(all_features)

print("ğŸ“Š æå–çš„ç‰¹å¾µçµ±è¨ˆï¼š")
print(f"   æ¨£æœ¬æ•¸: {len(features_df)}")
print(f"   ç‰¹å¾µæ•¸: {len(features_df.columns)}")
print(f"   æ­£æ¨£æœ¬: {(features_df['label'] == 1).sum()}")
print(f"   è² æ¨£æœ¬: {(features_df['label'] == 0).sum()}")

# é¡¯ç¤ºç‰¹å¾µåˆ—è¡¨
print("\nğŸ“ ç‰¹å¾µåˆ—è¡¨ï¼š")
feature_cols = [col for col in features_df.columns if col not in ['target_id', 'target_name', 'source']]
for i, col in enumerate(feature_cols, 1):
    if not features_df[col].isna().all():
        print(f"   {i:2}. {col}: {features_df[col].dtype}, "
              f"éç©ºå€¼: {features_df[col].notna().sum()}/{len(features_df)}")

# é¡¯ç¤ºå‰å¹¾ç­†è³‡æ–™
print("\nğŸ” ç‰¹å¾µæ¨£æœ¬ï¼ˆå‰3ç­†ï¼‰ï¼š")
display_cols = ['target_name', 'label', 'bls_period', 'bls_snr', 'tls_period', 'tls_sde']
available_cols = [col for col in display_cols if col in features_df.columns]
print(features_df[available_cols].head(3).to_string(index=False))
# ===== CELL 32 =====
# å„²å­˜ç‰¹å¾µåˆ°æª”æ¡ˆ
output_dir = Path("../data")
output_dir.mkdir(parents=True, exist_ok=True)

# å„²å­˜ç‰¹å¾µ CSV
features_file = output_dir / "bls_tls_features.csv"
features_df.to_csv(features_file, index=False)
print(f"\nğŸ’¾ ç‰¹å¾µå·²å„²å­˜è‡³: {features_file}")

# å„²å­˜ç‰¹å¾µçµ±è¨ˆ
stats = {
    'n_samples': len(features_df),
    'n_features': len(features_df.columns),
    'n_positive': int((features_df['label'] == 1).sum()),
    'n_negative': int((features_df['label'] == 0).sum()),
    'features': list(features_df.columns),
    'bls_features': [col for col in features_df.columns if col.startswith('bls_')],
    'tls_features': [col for col in features_df.columns if col.startswith('tls_')],
    'comparison_features': ['period_ratio', 'depth_ratio', 'snr_ratio', 'period_diff_pct', 'depth_diff_pct', 'snr_improvement']
}

# å„²å­˜çµ±è¨ˆè³‡è¨Š
import json
stats_file = output_dir / "bls_tls_features_stats.json"
with open(stats_file, 'w') as f:
    json.dump(stats, f, indent=2)
print(f"ğŸ“Š çµ±è¨ˆè³‡è¨Šå·²å„²å­˜è‡³: {stats_file}")

# å»ºç«‹ç‰¹å¾µé‡è¦æ€§åˆæ­¥åˆ†æï¼ˆå¦‚æœæœ‰è¶³å¤ æ¨£æœ¬ï¼‰
if len(features_df) >= 10 and features_df['label'].nunique() == 2:
    print("\nğŸ”¬ ç‰¹å¾µé‡è¦æ€§åˆæ­¥åˆ†æï¼š")
    
    # è¨ˆç®—å„ç‰¹å¾µèˆ‡æ¨™ç±¤çš„ç›¸é—œæ€§
    numerical_features = features_df.select_dtypes(include=[np.number]).columns
    correlations = {}
    
    for col in numerical_features:
        if col != 'label' and features_df[col].notna().sum() > 5:
            corr = features_df[[col, 'label']].corr()['label'][col]
            if not pd.isna(corr):
                correlations[col] = corr
    
    # æ’åºä¸¦é¡¯ç¤ºå‰10å€‹æœ€ç›¸é—œçš„ç‰¹å¾µ
    sorted_corr = sorted(correlations.items(), key=lambda x: abs(x[1]), reverse=True)[:10]
    
    print("\n   èˆ‡æ¨™ç±¤æœ€ç›¸é—œçš„ç‰¹å¾µï¼ˆç›¸é—œä¿‚æ•¸ï¼‰ï¼š")
    for feat, corr in sorted_corr:
        print(f"   â€¢ {feat}: {corr:+.3f}")
    
    # æ¯”è¼ƒæ­£è² æ¨£æœ¬çš„ç‰¹å¾µå·®ç•°
    print("\n   æ­£è² æ¨£æœ¬ç‰¹å¾µå·®ç•°ï¼š")
    for col in ['bls_snr', 'tls_sde', 'bls_depth_ppm', 'tls_depth_ppm']:
        if col in features_df.columns:
            pos_mean = features_df[features_df['label'] == 1][col].mean()
            neg_mean = features_df[features_df['label'] == 0][col].mean()
            if not pd.isna(pos_mean) and not pd.isna(neg_mean):
                diff_pct = (pos_mean - neg_mean) / abs(neg_mean) * 100 if neg_mean != 0 else 0
                print(f"   â€¢ {col}:")
                print(f"     æ­£æ¨£æœ¬å¹³å‡: {pos_mean:.2f}")
                print(f"     è² æ¨£æœ¬å¹³å‡: {neg_mean:.2f}")
                print(f"     å·®ç•°: {diff_pct:+.1f}%")

print("\nâœ… BLS/TLS ç‰¹å¾µæå–å®Œæˆï¼")
print("   å¯ä½¿ç”¨é€™äº›ç‰¹å¾µé€²è¡Œæ©Ÿå™¨å­¸ç¿’è¨“ç·´ï¼ˆ03_injection_train.ipynbï¼‰")
# ===== CELL 33 =====
# å»ºç«‹çµæœæ‘˜è¦ DataFrame
import pandas as pd

results_list = []
for target_id, result in search_results.items():
    target = result['target']
    bls = result['bls']
    tls = result['tls']
    
    results_list.append({
        'Target': target['name'],
        'ID': target_id,
        'Mission': target['mission'],
        'BLS_Period_days': bls['period'],
        'BLS_SNR': bls['snr'],
        'BLS_Depth_ppm': bls['depth']*1e6,
        'BLS_Duration_hours': bls['duration']*24,
        'TLS_Period_days': tls['period'],
        'TLS_SDE': tls['snr'],
        'TLS_Depth_ppm': tls['depth']*1e6,
        'TLS_Duration_hours': tls['duration']*24,
        'Period_Difference_%': abs(tls['period']-bls['period'])/bls['period']*100,
        'SNR_Improvement_%': (tls['snr']-bls['snr'])/bls['snr']*100
    })

results_df = pd.DataFrame(results_list)

print("\nğŸ“Š çµæœæ‘˜è¦è¡¨ï¼š")
print("\n", results_df.to_string(index=False))

# å¯é¸ï¼šå„²å­˜åˆ° CSV
# results_df.to_csv('bls_tls_results.csv', index=False)
# print("\nğŸ’¾ çµæœå·²å„²å­˜è‡³ bls_tls_results.csv")
# ===== CELL 35 =====
# ğŸš€ åŸ·è¡Œ GitHub Push
# å–æ¶ˆè¨»è§£ä¸‹é¢é€™è¡Œä¾†åŸ·è¡Œæ¨é€:
# ultimate_push_to_github_02()

print("ğŸ“‹ BLS/TLS åŸºç·šåˆ†æå®Œæˆï¼")
print("ğŸ’¡ è«‹åœ¨éœ€è¦æ¨é€çµæœæ™‚åŸ·è¡Œä¸Šé¢çš„ ultimate_push_to_github_02() å‡½æ•¸")
# ===== CELL 39 =====
# å„²å­˜å¢å¼·ç‰¹å¾µåˆ°æª”æ¡ˆ
output_dir = Path("../data")
output_dir.mkdir(parents=True, exist_ok=True)

# å„²å­˜å¢å¼·ç‰¹å¾µ CSV
enhanced_features_file = output_dir / "bls_tls_features_enhanced.csv"
enhanced_features_df.to_csv(enhanced_features_file, index=False)
print(f"\nğŸ’¾ å¢å¼·ç‰¹å¾µå·²å„²å­˜è‡³: {enhanced_features_file}")

# å„²å­˜ç‰¹å¾µçµ±è¨ˆèˆ‡èªªæ˜
enhanced_stats = {
    'n_samples': len(enhanced_features_df),
    'n_features': len(enhanced_features_df.columns),
    'n_positive': int((enhanced_features_df['label'] == 1).sum()),
    'n_negative': int((enhanced_features_df['label'] == 0).sum()),
    'feature_categories': {
        'basic_info': ['target_id', 'target_name', 'label', 'source', 'known_period', 'known_depth'],
        'bls_features': [col for col in enhanced_features_df.columns if col.startswith('bls_')],
        'tls_features': [col for col in enhanced_features_df.columns if col.startswith('tls_')],
        'comparison_features': ['period_ratio', 'depth_ratio', 'snr_ratio', 'period_diff_pct', 'depth_diff_pct', 'snr_improvement'],
        'detrending_features': [col for col in enhanced_features_df.columns if 'detrend' in col or col.endswith('_snr')],
        'odd_even_features': ['odd_depth_ppm', 'even_depth_ppm', 'odd_even_ratio', 'odd_even_diff_ppm'],
        'shape_features': ['transit_curvature', 'transit_symmetry', 'transit_points']
    },
    'phase_5_features': [col for col in enhanced_features_df.columns if 'detrend' in col or (col.endswith('_snr') and 'wotan' in col)],
    'phase_6_features': ['odd_depth_ppm', 'even_depth_ppm', 'odd_even_ratio', 'odd_even_diff_ppm', 
                         'transit_curvature', 'transit_symmetry', 'transit_points']
}

# å„²å­˜çµ±è¨ˆè³‡è¨Š
import json
enhanced_stats_file = output_dir / "bls_tls_features_enhanced_stats.json"
with open(enhanced_stats_file, 'w') as f:
    json.dump(enhanced_stats, f, indent=2)
print(f"ğŸ“Š å¢å¼·ç‰¹å¾µçµ±è¨ˆå·²å„²å­˜è‡³: {enhanced_stats_file}")

# é¡¯ç¤ºå„é¡åˆ¥ç‰¹å¾µæ•¸é‡
print("\nğŸ“‹ ç‰¹å¾µåˆ†é¡çµ±è¨ˆï¼š")
for category, features_list in enhanced_stats['feature_categories'].items():
    print(f"   â€¢ {category}: {len(features_list)} å€‹ç‰¹å¾µ")

print(f"\nğŸŒŸ Phase 5 æ–°å¢ç‰¹å¾µ: {len(enhanced_stats['phase_5_features'])} å€‹")
print(f"   {enhanced_stats['phase_5_features']}")

print(f"\nğŸ¯ Phase 6 æ–°å¢ç‰¹å¾µ: {len(enhanced_stats['phase_6_features'])} å€‹")
print(f"   {enhanced_stats['phase_6_features']}")

print("\nâœ… Phase 5 & 6 å®Œæˆï¼")
print("   æ‰€æœ‰å¢å¼·ç‰¹å¾µå·²æº–å‚™å®Œæˆï¼Œå¯ç”¨æ–¼ Phase 3 ç›£ç£å­¸ç¿’è¨“ç·´")
# ===== CELL 40 =====
# ğŸ¯ Phase 6: Advanced BLS Metrics Extraction
"""
æå–é¡å¤–çš„ BLS æŒ‡æ¨™èˆ‡ç‰¹å¾µ
"""

print("="*60)
print("ğŸ¯ Phase 6: Advanced BLS Metrics Extraction")
print("="*60)

def calculate_odd_even_depth(lc: lk.LightCurve, period: float, t0: float, duration: float) -> Dict[str, float]:
    """
    è¨ˆç®—å¥‡å¶æ¬¡å‡Œæ—¥æ·±åº¦å·®ç•°ï¼ˆç”¨æ–¼æª¢æ¸¬å‡é™½æ€§ï¼Œå¦‚é›™æ˜Ÿç³»çµ±ï¼‰
    
    Parameters:
    -----------
    lc : lightkurve.LightCurve
        å»è¶¨å‹¢å…‰æ›²ç·š
    period : float
        å‡Œæ—¥é€±æœŸ
    t0 : float
        ç¬¬ä¸€æ¬¡å‡Œæ—¥æ™‚é–“
    duration : float
        å‡Œæ—¥æŒçºŒæ™‚é–“
    
    Returns:
    --------
    dict : åŒ…å«å¥‡å¶æ·±åº¦èˆ‡æ¯”ç‡çš„å­—å…¸
    """
    try:
        time_array = lc.time.value if hasattr(lc.time, 'value') else np.array(lc.time)
        flux_array = lc.flux.value if hasattr(lc.flux, 'value') else np.array(lc.flux)
        
        # è¨ˆç®—æ¯å€‹è³‡æ–™é»æ‰€å±¬çš„é€±æœŸç·¨è™Ÿ
        phase = (time_array - t0) / period
        cycle_number = np.floor(phase)
        
        # åˆ†é›¢å¥‡æ•¸å’Œå¶æ•¸é€±æœŸ
        odd_mask = (cycle_number % 2 == 1) & (np.abs(phase - cycle_number) < duration / period)
        even_mask = (cycle_number % 2 == 0) & (np.abs(phase - cycle_number) < duration / period)
        
        # è¨ˆç®—æ·±åº¦ï¼ˆç›¸å°æ–¼ 1.0ï¼‰
        if np.sum(odd_mask) > 0 and np.sum(even_mask) > 0:
            odd_depth = 1.0 - np.median(flux_array[odd_mask])
            even_depth = 1.0 - np.median(flux_array[even_mask])
            
            # è¨ˆç®—å·®ç•°æ¯”ç‡
            if even_depth > 0:
                depth_ratio = odd_depth / even_depth
            else:
                depth_ratio = np.nan
            
            return {
                'odd_depth_ppm': odd_depth * 1e6,
                'even_depth_ppm': even_depth * 1e6,
                'odd_even_ratio': depth_ratio,
                'odd_even_diff_ppm': (odd_depth - even_depth) * 1e6
            }
        else:
            return {
                'odd_depth_ppm': np.nan,
                'even_depth_ppm': np.nan,
                'odd_even_ratio': np.nan,
                'odd_even_diff_ppm': np.nan
            }
    except Exception as e:
        print(f"      âš ï¸ è¨ˆç®—å¥‡å¶æ·±åº¦å¤±æ•—: {e}")
        return {
            'odd_depth_ppm': np.nan,
            'even_depth_ppm': np.nan,
            'odd_even_ratio': np.nan,
            'odd_even_diff_ppm': np.nan
        }

def calculate_transit_shape_metrics(lc: lk.LightCurve, period: float, t0: float, duration: float) -> Dict[str, float]:
    """
    è¨ˆç®—å‡Œæ—¥å½¢ç‹€æŒ‡æ¨™
    
    Parameters:
    -----------
    lc : lightkurve.LightCurve
        å»è¶¨å‹¢å…‰æ›²ç·š
    period : float
        å‡Œæ—¥é€±æœŸ
    t0 : float
        ç¬¬ä¸€æ¬¡å‡Œæ—¥æ™‚é–“
    duration : float
        å‡Œæ—¥æŒçºŒæ™‚é–“
    
    Returns:
    --------
    dict : åŒ…å«å½¢ç‹€æŒ‡æ¨™çš„å­—å…¸
    """
    try:
        # æ‘ºç–Šå…‰æ›²ç·š
        folded_lc = lc.fold(period=period, epoch_time=t0)
        
        time_array = folded_lc.time.value if hasattr(folded_lc.time, 'value') else np.array(folded_lc.time)
        flux_array = folded_lc.flux.value if hasattr(folded_lc.flux, 'value') else np.array(folded_lc.flux)
        
        # é¸æ“‡å‡Œæ—¥å€åŸŸ
        transit_mask = np.abs(time_array) < duration / 2
        
        if np.sum(transit_mask) > 10:  # è‡³å°‘éœ€è¦10å€‹é»
            transit_flux = flux_array[transit_mask]
            transit_time = time_array[transit_mask]
            
            # è¨ˆç®— V-shape vs U-shape (æ›²ç‡)
            # ç°¡åŒ–ç‰ˆï¼šè¨ˆç®—æœ€æ·±é»é™„è¿‘çš„æ›²ç‡
            min_idx = np.argmin(transit_flux)
            if min_idx > 0 and min_idx < len(transit_flux) - 1:
                curvature = (transit_flux[min_idx-1] + transit_flux[min_idx+1] - 2*transit_flux[min_idx])
            else:
                curvature = np.nan
            
            # è¨ˆç®—å°ç¨±æ€§ï¼ˆå·¦å³åŠéƒ¨çš„å·®ç•°ï¼‰
            mid_idx = len(transit_flux) // 2
            left_mean = np.mean(transit_flux[:mid_idx])
            right_mean = np.mean(transit_flux[mid_idx:])
            symmetry = abs(left_mean - right_mean) / np.std(transit_flux)
            
            return {
                'transit_curvature': curvature,
                'transit_symmetry': symmetry,
                'transit_points': int(np.sum(transit_mask))
            }
        else:
            return {
                'transit_curvature': np.nan,
                'transit_symmetry': np.nan,
                'transit_points': int(np.sum(transit_mask))
            }
    except Exception as e:
        print(f"      âš ï¸ è¨ˆç®—å‡Œæ—¥å½¢ç‹€å¤±æ•—: {e}")
        return {
            'transit_curvature': np.nan,
            'transit_symmetry': np.nan,
            'transit_points': 0
        }

def extract_enhanced_bls_features(
    search_result: Dict[str, Any],
    detrending_result: Dict[str, Any]
) -> Dict[str, Any]:
    """
    æå–å¢å¼·çš„ BLS ç‰¹å¾µï¼ˆåŒ…å« Phase 5 å’Œ Phase 6ï¼‰
    
    Parameters:
    -----------
    search_result : dict
        BLS/TLS æœå°‹çµæœ
    detrending_result : dict
        å»è¶¨å‹¢æ–¹æ³•æ¯”è¼ƒçµæœ
    
    Returns:
    --------
    dict : å¢å¼·ç‰¹å¾µå­—å…¸
    """
    features = {}
    
    # åŸºæœ¬è³‡è¨Š
    target = search_result['target']
    features['target_id'] = target.get('id', '')
    features['target_name'] = target.get('name', '')
    features['label'] = target.get('label', -1)
    features['source'] = target.get('source', '')
    features['known_period'] = target.get('known_period', np.nan)
    features['known_depth'] = target.get('known_depth', np.nan)
    
    # BLS åŸºæœ¬ç‰¹å¾µ
    if 'bls' in search_result:
        bls = search_result['bls']
        features['bls_period'] = bls['period']
        features['bls_t0'] = bls['t0']
        features['bls_duration_hours'] = bls['duration'] * 24
        features['bls_depth_ppm'] = bls['depth'] * 1e6
        features['bls_snr'] = bls['snr']
        features['bls_duration_phase'] = bls['duration'] / bls['period'] if bls['period'] > 0 else np.nan
    
    # TLS åŸºæœ¬ç‰¹å¾µ
    if 'tls' in search_result:
        tls = search_result['tls']
        features['tls_period'] = tls['period']
        features['tls_t0'] = tls['t0']
        features['tls_duration_hours'] = tls['duration'] * 24
        features['tls_depth_ppm'] = tls['depth'] * 1e6
        features['tls_sde'] = tls['snr']
        features['tls_duration_phase'] = tls['duration'] / tls['period'] if tls['period'] > 0 else np.nan
    
    # BLS vs TLS æ¯”è¼ƒç‰¹å¾µ
    if 'bls' in search_result and 'tls' in search_result:
        bls = search_result['bls']
        tls = search_result['tls']
        
        features['period_ratio'] = tls['period'] / bls['period'] if bls['period'] > 0 else np.nan
        features['period_diff_pct'] = abs(tls['period'] - bls['period']) / bls['period'] * 100 if bls['period'] > 0 else np.nan
        features['depth_ratio'] = tls['depth'] / bls['depth'] if bls['depth'] > 0 else np.nan
        features['depth_diff_pct'] = abs(tls['depth'] - bls['depth']) / bls['depth'] * 100 if bls['depth'] > 0 else np.nan
        features['snr_ratio'] = tls['snr'] / bls['snr'] if bls['snr'] > 0 else np.nan
        features['snr_improvement'] = (tls['snr'] - bls['snr']) / bls['snr'] * 100 if bls['snr'] > 0 else np.nan
    
    # Phase 5: å»è¶¨å‹¢æ–¹æ³•æ¯”è¼ƒç‰¹å¾µ
    if detrending_result:
        methods = detrending_result['methods']
        features['best_detrend_method'] = detrending_result['best_method']
        features['best_detrend_snr'] = detrending_result['best_snr']
        
        # å„æ–¹æ³•çš„ SNR
        for method_key in ['lightkurve_flatten', 'wotan_biweight', 'wotan_rspline', 'wotan_hspline']:
            if method_key in methods:
                features[f'{method_key}_snr'] = methods[method_key]['snr']
        
        # SNR æ”¹å–„
        if 'lightkurve_flatten' in methods and detrending_result['best_method'] != 'lightkurve_flatten':
            baseline_snr = methods['lightkurve_flatten']['snr']
            best_snr = detrending_result['best_snr']
            if baseline_snr > 0:
                features['snr_improvement_by_wotan'] = (best_snr - baseline_snr) / baseline_snr * 100
    
    # Phase 6: å¥‡å¶æ·±åº¦èˆ‡å½¢ç‹€ç‰¹å¾µ
    if 'bls' in search_result and 'lc_flat' in search_result:
        bls = search_result['bls']
        lc_flat = search_result['lc_flat']
        
        # è¨ˆç®—å¥‡å¶æ·±åº¦
        odd_even = calculate_odd_even_depth(lc_flat, bls['period'], bls['t0'], bls['duration'])
        features.update(odd_even)
        
        # è¨ˆç®—å½¢ç‹€æŒ‡æ¨™
        shape = calculate_transit_shape_metrics(lc_flat, bls['period'], bls['t0'], bls['duration'])
        features.update(shape)
    
    return features

# æå–æ‰€æœ‰ç›®æ¨™çš„å¢å¼·ç‰¹å¾µ
print("\né–‹å§‹æå–å¢å¼· BLS ç‰¹å¾µ...")
enhanced_features_list = []

for target_id in search_results.keys():
    print(f"\nğŸ¯ æå– {search_results[target_id]['target']['name']} çš„å¢å¼·ç‰¹å¾µ...")
    
    # ç²å–å»è¶¨å‹¢çµæœ
    detrend_result = detrending_results.get(target_id, None)
    
    # æå–ç‰¹å¾µ
    enhanced_features = extract_enhanced_bls_features(
        search_results[target_id],
        detrend_result
    )
    
    enhanced_features_list.append(enhanced_features)
    
    print(f"   âœ… ç‰¹å¾µæå–å®Œæˆ")

# è½‰æ›ç‚º DataFrame
enhanced_features_df = pd.DataFrame(enhanced_features_list)

print("\n" + "="*60)
print("ğŸ“Š å¢å¼·ç‰¹å¾µçµ±è¨ˆï¼š")
print(f"   æ¨£æœ¬æ•¸: {len(enhanced_features_df)}")
print(f"   ç‰¹å¾µæ•¸: {len(enhanced_features_df.columns)}")
print(f"   æ­£æ¨£æœ¬: {(enhanced_features_df['label'] == 1).sum()}")
print(f"   è² æ¨£æœ¬: {(enhanced_features_df['label'] == 0).sum()}")

print("\nğŸ“ æ–°å¢ç‰¹å¾µåˆ—è¡¨ï¼š")
new_features = [col for col in enhanced_features_df.columns if col not in features_df.columns]
for i, col in enumerate(new_features, 1):
    print(f"   {i}. {col}")
# ===== CELL 42 =====
# è¦–è¦ºåŒ–ï¼š4ç¨®å»è¶¨å‹¢æ–¹æ³•çš„ä¸¦æ’æ¯”è¼ƒ
def plot_detrending_comparison(detrending_result: Dict[str, Any]):
    """
    ç¹ªè£½4ç¨®å»è¶¨å‹¢æ–¹æ³•çš„ä¸¦æ’æ¯”è¼ƒåœ–
    """
    target = detrending_result['target']
    methods = detrending_result['methods']
    best_method = detrending_result['best_method']
    
    fig, axes = plt.subplots(2, 2, figsize=(16, 10))
    fig.suptitle(f"{target['name']} ({target['id']}) - å»è¶¨å‹¢æ–¹æ³•æ¯”è¼ƒ", 
                 fontsize=14, fontweight='bold')
    
    method_names = ['lightkurve_flatten', 'wotan_biweight', 'wotan_rspline', 'wotan_hspline']
    method_titles = [
        'Lightkurve flatten()',
        'Wotan Biweight',
        'Wotan R-Spline',
        'Wotan H-Spline'
    ]
    
    for idx, (method_key, title) in enumerate(zip(method_names, method_titles)):
        ax = axes[idx // 2, idx % 2]
        
        if method_key in methods:
            lc = methods[method_key]['lc']
            snr = methods[method_key]['snr']
            
            # ç¹ªè£½å…‰æ›²ç·š
            lc.scatter(ax=ax, s=0.5, color='blue', alpha=0.4)
            
            # æ¨™é¡Œï¼ˆæœ€ä½³æ–¹æ³•åŠ æ˜Ÿè™Ÿï¼‰
            is_best = (method_key == best_method)
            title_text = f"{title}\nSNR: {snr:.2f}"
            if is_best:
                title_text = f"ğŸ† {title_text} ğŸ†"
                ax.set_facecolor('#ffffcc')  # æ·¡é»ƒè‰²èƒŒæ™¯
            
            ax.set_title(title_text, fontsize=11, fontweight='bold' if is_best else 'normal')
            ax.set_xlabel('æ™‚é–“ (BTJD)', fontsize=9)
            ax.set_ylabel('æ¨™æº–åŒ–æµé‡', fontsize=9)
            ax.grid(True, alpha=0.3)
            
            # è¨ˆç®—ä¸¦é¡¯ç¤ºçµ±è¨ˆè³‡è¨Š
            flux = lc.flux.value if hasattr(lc.flux, 'value') else np.array(lc.flux)
            flux_clean = flux[~np.isnan(flux)]
            
            textstr = f'Mean: {np.mean(flux_clean):.4f}\nStd: {np.std(flux_clean):.4f}\nPoints: {len(flux_clean):,}'
            ax.text(0.02, 0.98, textstr, transform=ax.transAxes, fontsize=8,
                   verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))
        else:
            ax.text(0.5, 0.5, f'{title}\nè³‡æ–™ä¸å¯ç”¨', 
                   ha='center', va='center', transform=ax.transAxes)
            ax.set_xticks([])
            ax.set_yticks([])
    
    plt.tight_layout()
    plt.show()
    
    return fig

# ç¹ªè£½æ‰€æœ‰ç›®æ¨™çš„å»è¶¨å‹¢æ–¹æ³•æ¯”è¼ƒåœ–
print("\nğŸ“Š ç¹ªè£½å»è¶¨å‹¢æ–¹æ³•æ¯”è¼ƒåœ–...")
print("="*60)

for target_id, result in detrending_results.items():
    print(f"\nğŸ“Š {result['target']['name']} - æœ€ä½³æ–¹æ³•: {result['best_method']}")
    fig = plot_detrending_comparison(result)
# ===== CELL 43 =====
# å°æ¯å€‹ç›®æ¨™åŸ·è¡Œå¤šæ–¹æ³•å»è¶¨å‹¢æ¯”è¼ƒ
for target_id, data in processed_data.items():
    print(f"\nğŸ¯ åˆ†æ {data['target']['name']} ({target_id})...")
    
    lc_clean = data['lc_clean']
    lc_flat_original = data['lc_flat']
    
    # å„²å­˜å„æ–¹æ³•çµæœ
    methods_results = {}
    
    # 1. Lightkurve flatten() - å·²æœ‰çš„çµæœ
    snr_lightkurve = calculate_snr(lc_flat_original)
    methods_results['lightkurve_flatten'] = {
        'lc': lc_flat_original,
        'snr': snr_lightkurve,
        'method': 'lightkurve_flatten'
    }
    print(f"   âœ… Lightkurve flatten() - SNR: {snr_lightkurve:.2f}")
    
    # 2. Wotan biweight
    lc_biweight, snr_biweight, meta_biweight = apply_wotan_detrending(
        lc_clean, method='biweight', window_length=0.5
    )
    methods_results['wotan_biweight'] = {
        'lc': lc_biweight,
        'snr': snr_biweight,
        'method': 'wotan_biweight',
        'metadata': meta_biweight
    }
    
    # 3. Wotan rspline
    lc_rspline, snr_rspline, meta_rspline = apply_wotan_detrending(
        lc_clean, method='rspline', window_length=0.5
    )
    methods_results['wotan_rspline'] = {
        'lc': lc_rspline,
        'snr': snr_rspline,
        'method': 'wotan_rspline',
        'metadata': meta_rspline
    }
    
    # 4. Wotan hspline
    lc_hspline, snr_hspline, meta_hspline = apply_wotan_detrending(
        lc_clean, method='hspline', window_length=0.5
    )
    methods_results['wotan_hspline'] = {
        'lc': lc_hspline,
        'snr': snr_hspline,
        'method': 'wotan_hspline',
        'metadata': meta_hspline
    }
    
    # æ‰¾å‡ºæœ€ä½³ SNR çš„æ–¹æ³•
    best_method = max(methods_results.items(), key=lambda x: x[1]['snr'])
    best_method_name = best_method[0]
    best_snr = best_method[1]['snr']
    
    print(f"\n   ğŸ† æœ€ä½³æ–¹æ³•: {best_method_name} (SNR: {best_snr:.2f})")
    
    # å„²å­˜çµæœ
    detrending_results[target_id] = {
        'target': data['target'],
        'methods': methods_results,
        'best_method': best_method_name,
        'best_snr': best_snr
    }

print("\nâœ… æ‰€æœ‰ç›®æ¨™çš„å»è¶¨å‹¢æ–¹æ³•æ¯”è¼ƒå®Œæˆï¼")
# ===== CELL 44 =====
# ğŸŒŸ Phase 5: Wotan Detrending Comparison
"""
æ¯”è¼ƒä¸åŒå»è¶¨å‹¢æ–¹æ³•çš„æ•ˆèƒ½
- Lightkurve flatten() (å·²ä½¿ç”¨)
- Wotan biweight
- Wotan rspline
- Wotan hspline
"""

print("="*60)
print("ğŸŒŸ Phase 5: Wotan Detrending Method Comparison")
print("="*60)

# å°å…¥ wotan
try:
    from wotan import flatten as wotan_flatten
    print("âœ… Wotan å°å…¥æˆåŠŸ")
except ImportError:
    print("âŒ Wotan æœªå®‰è£ï¼Œæ­£åœ¨å®‰è£...")
    import subprocess, sys
    subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", "wotan"])
    from wotan import flatten as wotan_flatten
    print("âœ… Wotan å®‰è£ä¸¦å°å…¥æˆåŠŸ")

def calculate_snr(lc: lk.LightCurve) -> float:
    """
    è¨ˆç®—å…‰æ›²ç·šçš„ä¿¡å™ªæ¯” (SNR)
    
    Parameters:
    -----------
    lc : lightkurve.LightCurve
        è¼¸å…¥å…‰æ›²ç·š
    
    Returns:
    --------
    float : ä¿¡å™ªæ¯”
    """
    flux = lc.flux.value if hasattr(lc.flux, 'value') else np.array(lc.flux)
    
    # ç§»é™¤ NaN å€¼
    flux_clean = flux[~np.isnan(flux)]
    
    if len(flux_clean) == 0:
        return 0.0
    
    # SNR = mean / std
    mean_flux = np.mean(flux_clean)
    std_flux = np.std(flux_clean)
    
    if std_flux == 0:
        return 0.0
    
    return mean_flux / std_flux

def apply_wotan_detrending(
    lc_clean: lk.LightCurve,
    method: str = 'biweight',
    window_length: float = 0.5
) -> Tuple[lk.LightCurve, float, Dict[str, Any]]:
    """
    ä½¿ç”¨ Wotan é€²è¡Œå»è¶¨å‹¢è™•ç†
    
    Parameters:
    -----------
    lc_clean : lightkurve.LightCurve
        æ¸…ç†éçš„å…‰æ›²ç·š
    method : str
        Wotan æ–¹æ³•: 'biweight', 'rspline', 'hspline'
    window_length : float
        æ»‘å‹•è¦–çª—é•·åº¦ï¼ˆå¤©ï¼‰
    
    Returns:
    --------
    tuple : (å»è¶¨å‹¢å…‰æ›²ç·š, SNR, metadata)
    """
    print(f"   ğŸ”§ æ­£åœ¨ä½¿ç”¨ Wotan {method} æ–¹æ³•å»è¶¨å‹¢...")
    
    start_time = time.time()
    
    # æº–å‚™è³‡æ–™
    time_array = lc_clean.time.value if hasattr(lc_clean.time, 'value') else np.array(lc_clean.time)
    flux_array = lc_clean.flux.value if hasattr(lc_clean.flux, 'value') else np.array(lc_clean.flux)
    
    try:
        # åŸ·è¡Œ Wotan å»è¶¨å‹¢
        flatten_flux, trend_flux = wotan_flatten(
            time_array,
            flux_array,
            method=method,
            window_length=window_length,
            return_trend=True
        )
        
        # å‰µå»ºæ–°çš„ LightCurve ç‰©ä»¶
        lc_wotan = lc_clean.copy()
        lc_wotan.flux = flatten_flux
        
        # è¨ˆç®— SNR
        snr = calculate_snr(lc_wotan)
        
        elapsed_time = time.time() - start_time
        
        metadata = {
            'method': method,
            'window_length': window_length,
            'snr': snr,
            'elapsed_time': elapsed_time,
            'n_points': len(flatten_flux)
        }
        
        print(f"   âœ… Wotan {method} å®Œæˆï¼ˆè€—æ™‚ {elapsed_time:.2f} ç§’ï¼‰")
        print(f"      SNR: {snr:.2f}")
        
        return lc_wotan, snr, metadata
        
    except Exception as e:
        print(f"   âŒ Wotan {method} å¤±æ•—: {e}")
        # è¿”å›åŸå§‹å…‰æ›²ç·šä½œç‚º fallback
        return lc_clean, 0.0, {'method': method, 'error': str(e)}

# å„²å­˜æ‰€æœ‰å»è¶¨å‹¢çµæœ
detrending_results = {}

print("\né–‹å§‹å°æ‰€æœ‰ç›®æ¨™é€²è¡Œå¤šæ–¹æ³•å»è¶¨å‹¢æ¯”è¼ƒ...")
print("="*60)